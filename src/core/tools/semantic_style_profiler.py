"""
è¯­ä¹‰é£æ ¼ç”»åƒæ„å»ºå™¨
æ•´åˆæ‰€æœ‰é‡åŒ–æŒ‡æ ‡ï¼Œæ„å»ºå®Œæ•´çš„è¯­ä¹‰é£æ ¼ç”»åƒ
"""

import numpy as np
import json
import os
from typing import Dict, Any, List, Tuple, Optional
from datetime import datetime

try:
    from sklearn.preprocessing import StandardScaler, MinMaxScaler
    from sklearn.decomposition import PCA
    from sklearn.manifold import TSNE
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    print("Warning: scikit-learn not available for advanced profiling")


class SemanticStyleProfiler:
    """è¯­ä¹‰é£æ ¼ç”»åƒæ„å»ºå™¨"""
    
    def __init__(self, storage_path: str = "src/core/knowledge_base/semantic_profiles"):
        """
        åˆå§‹åŒ–è¯­ä¹‰é£æ ¼ç”»åƒæ„å»ºå™¨
        
        Args:
            storage_path: ç”»åƒå­˜å‚¨è·¯å¾„
        """
        self.storage_path = storage_path
        os.makedirs(storage_path, exist_ok=True)
        
        # ç‰¹å¾æƒé‡é…ç½®
        self.feature_weights = {
            "clustering_features": 0.25,
            "distance_features": 0.20,
            "novelty_features": 0.20,
            "emotional_features": 0.15,
            "vector_features": 0.10,
            "llm_features": 0.10
        }
        
        # é£æ ¼ç»´åº¦å®šä¹‰
        self.style_dimensions = {
            "conceptual_organization": "æ¦‚å¿µç»„ç»‡èƒ½åŠ›",
            "semantic_coherence": "è¯­ä¹‰è¿è´¯æ€§", 
            "creative_association": "åˆ›æ–°è”æƒ³èƒ½åŠ›",
            "emotional_expression": "æƒ…æ„Ÿè¡¨è¾¾åŠ›",
            "cognitive_complexity": "è®¤çŸ¥å¤æ‚åº¦",
            "thematic_focus": "ä¸»é¢˜èšç„¦åº¦"
        }
    
    def build_semantic_style_profile(self, analysis_results: Dict[str, Any],
                                   document_name: str = None) -> Dict[str, Any]:
        """
        æ„å»ºè¯­ä¹‰é£æ ¼ç”»åƒ
        
        Args:
            analysis_results: åŒ…å«æ‰€æœ‰åˆ†æç»“æœçš„å­—å…¸
            document_name: æ–‡æ¡£åç§°
        
        Returns:
            å®Œæ•´çš„è¯­ä¹‰é£æ ¼ç”»åƒ
        """
        profile = {
            "profile_id": self._generate_profile_id(),
            "document_name": document_name or "æœªå‘½åæ–‡æ¡£",
            "creation_time": datetime.now().isoformat(),
            "feature_vector": [],
            "style_scores": {},
            "behavioral_indicators": {},
            "style_classification": {},
            "comparative_metrics": {},
            "profile_summary": {},
            "success": False
        }
        
        try:
            print("ğŸ”„ æ­£åœ¨æ„å»ºè¯­ä¹‰é£æ ¼ç”»åƒ...")
            
            # 1. æå–å’Œæ•´åˆç‰¹å¾
            integrated_features = self._integrate_all_features(analysis_results)
            profile["integrated_features"] = integrated_features
            
            # 2. ç”Ÿæˆç‰¹å¾å‘é‡
            feature_vector = self._generate_feature_vector(integrated_features)
            profile["feature_vector"] = feature_vector
            
            # 3. è®¡ç®—é£æ ¼åˆ†æ•°
            style_scores = self._calculate_style_scores(integrated_features)
            profile["style_scores"] = style_scores
            
            # 4. æå–è¡Œä¸ºæŒ‡æ ‡
            behavioral_indicators = self._extract_behavioral_indicators(analysis_results)
            profile["behavioral_indicators"] = behavioral_indicators
            
            # 5. é£æ ¼åˆ†ç±»
            style_classification = self._classify_writing_style(style_scores, behavioral_indicators)
            profile["style_classification"] = style_classification
            
            # 6. æ¯”è¾ƒæŒ‡æ ‡
            comparative_metrics = self._calculate_comparative_metrics(feature_vector, style_scores)
            profile["comparative_metrics"] = comparative_metrics
            
            # 7. ç”Ÿæˆç”»åƒæ‘˜è¦
            profile_summary = self._generate_profile_summary(profile)
            profile["profile_summary"] = profile_summary
            
            profile["success"] = True
            print("âœ… è¯­ä¹‰é£æ ¼ç”»åƒæ„å»ºå®Œæˆ")
            
        except Exception as e:
            profile["error"] = str(e)
            print(f"âŒ è¯­ä¹‰é£æ ¼ç”»åƒæ„å»ºå¤±è´¥: {str(e)}")
        
        return profile
    
    def _integrate_all_features(self, analysis_results: Dict[str, Any]) -> Dict[str, Any]:
        """æ•´åˆæ‰€æœ‰ç‰¹å¾"""
        integrated = {
            "clustering_features": {},
            "distance_features": {},
            "novelty_features": {},
            "emotional_features": {},
            "vector_features": {},
            "llm_features": {}
        }
        
        try:
            # 1. èšç±»ç‰¹å¾
            clustering_analysis = analysis_results.get("clustering_analysis", {})
            if clustering_analysis.get("success"):
                clustering_metrics = clustering_analysis.get("clustering_metrics", {})
                integrated["clustering_features"] = {
                    "cluster_count": clustering_metrics.get("cluster_count", 0),
                    "avg_cluster_size": clustering_metrics.get("average_cluster_size", 0),
                    "cluster_variance": clustering_metrics.get("cluster_size_variance", 0),
                    "silhouette_score": clustering_metrics.get("silhouette_score", 0) or 0
                }
            
            # 2. è·ç¦»ç‰¹å¾
            distance_analysis = analysis_results.get("distance_analysis", {})
            if distance_analysis.get("success"):
                distance_metrics = distance_analysis.get("distance_metrics", {})
                integrated["distance_features"] = {
                    "avg_similarity": distance_metrics.get("average_similarity", 0),
                    "similarity_variance": distance_metrics.get("similarity_variance", 0),
                    "semantic_span": self._encode_categorical(
                        distance_analysis.get("pattern_analysis", {}).get("semantic_span", "unknown")
                    )
                }
            
            # 3. åˆ›æ–°ç‰¹å¾
            novelty_assessment = analysis_results.get("novelty_assessment", {})
            if novelty_assessment.get("success"):
                creativity_metrics = novelty_assessment.get("creativity_metrics", {})
                integrated["novelty_features"] = {
                    "avg_novelty_score": creativity_metrics.get("average_novelty_score", 0),
                    "high_novelty_count": creativity_metrics.get("high_novelty_count", 0),
                    "creativity_density": creativity_metrics.get("creativity_density", 0)
                }
            
            # 4. æƒ…æ„Ÿç‰¹å¾
            emotional_analysis = analysis_results.get("emotional_analysis", {})
            if emotional_analysis.get("success"):
                emotional_dist = emotional_analysis.get("emotional_distribution", {})
                integrated["emotional_features"] = {
                    "emotional_intensity": emotional_dist.get("emotional_intensity_avg", 0),
                    "positive_ratio": self._calculate_emotion_ratio(emotional_dist, "positive"),
                    "negative_ratio": self._calculate_emotion_ratio(emotional_dist, "negative"),
                    "emotional_balance": self._calculate_emotional_balance(emotional_dist)
                }
            
            # 5. å‘é‡ç‰¹å¾
            vector_result = analysis_results.get("vector_result", {})
            if vector_result.get("success"):
                vector_stats = vector_result.get("vector_statistics", {})
                integrated["vector_features"] = {
                    "total_vectors": vector_stats.get("total_vectors", 0),
                    "vector_density": vector_stats.get("vector_density", 0),
                    "concept_count": vector_stats.get("category_counts", {}).get("concept_vectors", 0)
                }
            
            # 6. LLMç‰¹å¾
            llm_features = self._extract_llm_features(analysis_results)
            integrated["llm_features"] = llm_features
        
        except Exception as e:
            integrated["error"] = str(e)
        
        return integrated
    
    def _generate_feature_vector(self, integrated_features: Dict[str, Any]) -> List[float]:
        """ç”Ÿæˆç‰¹å¾å‘é‡"""
        feature_vector = []
        
        try:
            # æŒ‰ç±»åˆ«æå–ç‰¹å¾å€¼
            for category, weight in self.feature_weights.items():
                category_features = integrated_features.get(category, {})
                
                if category_features and not category_features.get("error"):
                    # æå–æ•°å€¼ç‰¹å¾
                    for key, value in category_features.items():
                        if isinstance(value, (int, float)) and not np.isnan(value):
                            feature_vector.append(float(value))
                        elif isinstance(value, bool):
                            feature_vector.append(float(value))
                        else:
                            feature_vector.append(0.0)
                else:
                    # å¦‚æœç±»åˆ«ç‰¹å¾ç¼ºå¤±ï¼Œç”¨é›¶å¡«å……
                    feature_vector.extend([0.0] * 3)  # æ¯ä¸ªç±»åˆ«å‡è®¾3ä¸ªç‰¹å¾
            
            # æ ‡å‡†åŒ–ç‰¹å¾å‘é‡
            if SKLEARN_AVAILABLE and len(feature_vector) > 0:
                scaler = StandardScaler()
                feature_vector = scaler.fit_transform([feature_vector])[0].tolist()
        
        except Exception as e:
            feature_vector = [0.0] * 18  # é»˜è®¤18ç»´ç‰¹å¾å‘é‡
        
        return feature_vector
    
    def _calculate_style_scores(self, integrated_features: Dict[str, Any]) -> Dict[str, float]:
        """è®¡ç®—é£æ ¼åˆ†æ•°"""
        scores = {}
        
        try:
            # æ¦‚å¿µç»„ç»‡èƒ½åŠ›
            clustering_features = integrated_features.get("clustering_features", {})
            cluster_count = clustering_features.get("cluster_count", 0)
            avg_cluster_size = clustering_features.get("avg_cluster_size", 0)
            
            if cluster_count > 0 and avg_cluster_size > 0:
                scores["conceptual_organization"] = min(5.0, (cluster_count * avg_cluster_size) / 3.0)
            else:
                scores["conceptual_organization"] = 1.0
            
            # è¯­ä¹‰è¿è´¯æ€§
            distance_features = integrated_features.get("distance_features", {})
            avg_similarity = distance_features.get("avg_similarity", 0)
            scores["semantic_coherence"] = avg_similarity * 5.0
            
            # åˆ›æ–°è”æƒ³èƒ½åŠ›
            novelty_features = integrated_features.get("novelty_features", {})
            avg_novelty = novelty_features.get("avg_novelty_score", 0)
            scores["creative_association"] = avg_novelty
            
            # æƒ…æ„Ÿè¡¨è¾¾åŠ›
            emotional_features = integrated_features.get("emotional_features", {})
            emotional_intensity = emotional_features.get("emotional_intensity", 0)
            scores["emotional_expression"] = emotional_intensity
            
            # è®¤çŸ¥å¤æ‚åº¦
            vector_features = integrated_features.get("vector_features", {})
            concept_count = vector_features.get("concept_count", 0)
            vector_density = vector_features.get("vector_density", 0)
            scores["cognitive_complexity"] = min(5.0, (concept_count / 5.0) + (vector_density / 2.0))
            
            # ä¸»é¢˜èšç„¦åº¦
            semantic_span = distance_features.get("semantic_span", 0)
            scores["thematic_focus"] = 5.0 - semantic_span  # è¯­ä¹‰è·¨åº¦è¶Šå°ï¼Œèšç„¦åº¦è¶Šé«˜
            
            # ç¡®ä¿æ‰€æœ‰åˆ†æ•°åœ¨1-5èŒƒå›´å†…
            for key in scores:
                scores[key] = max(1.0, min(5.0, scores[key]))
        
        except Exception as e:
            # é»˜è®¤åˆ†æ•°
            for dimension in self.style_dimensions:
                scores[dimension] = 3.0
        
        return scores
    
    def _extract_behavioral_indicators(self, analysis_results: Dict[str, Any]) -> Dict[str, Any]:
        """æå–è¡Œä¸ºæŒ‡æ ‡"""
        indicators = {
            "writing_patterns": {},
            "cognitive_patterns": {},
            "emotional_patterns": {},
            "structural_patterns": {}
        }
        
        try:
            # å†™ä½œæ¨¡å¼
            clustering_analysis = analysis_results.get("clustering_analysis", {})
            if clustering_analysis.get("success"):
                behavioral_indicators = clustering_analysis.get("behavioral_indicators", {})
                indicators["writing_patterns"] = {
                    "conceptual_organization": behavioral_indicators.get("conceptual_organization", "unknown"),
                    "thematic_coherence": behavioral_indicators.get("thematic_coherence", "unknown")
                }
            
            # è®¤çŸ¥æ¨¡å¼
            distance_analysis = analysis_results.get("distance_analysis", {})
            if distance_analysis.get("success"):
                llm_evaluation = distance_analysis.get("llm_evaluation", {})
                writing_style = llm_evaluation.get("writing_style_implications", {})
                indicators["cognitive_patterns"] = {
                    "style_type": writing_style.get("style_type", "unknown"),
                    "cognitive_pattern": writing_style.get("cognitive_pattern", "unknown")
                }
            
            # æƒ…æ„Ÿæ¨¡å¼
            emotional_analysis = analysis_results.get("emotional_analysis", {})
            if emotional_analysis.get("success"):
                behavioral_patterns = emotional_analysis.get("behavioral_patterns", {})
                indicators["emotional_patterns"] = {
                    "emotional_expressiveness": behavioral_patterns.get("emotional_expressiveness", "unknown"),
                    "emotional_balance": behavioral_patterns.get("emotional_balance", "unknown")
                }
            
            # ç»“æ„æ¨¡å¼
            vector_result = analysis_results.get("vector_result", {})
            if vector_result.get("success"):
                vector_stats = vector_result.get("vector_statistics", {})
                indicators["structural_patterns"] = {
                    "concept_diversity": "é«˜" if vector_stats.get("total_vectors", 0) > 10 else "ä¸­ç­‰",
                    "semantic_density": "é«˜" if vector_stats.get("vector_density", 0) > 1.0 else "ä½"
                }
        
        except Exception as e:
            indicators["error"] = str(e)
        
        return indicators
    
    def _classify_writing_style(self, style_scores: Dict[str, float],
                              behavioral_indicators: Dict[str, Any]) -> Dict[str, Any]:
        """é£æ ¼åˆ†ç±»"""
        classification = {
            "primary_style": "unknown",
            "secondary_styles": [],
            "style_strength": 0.0,
            "style_characteristics": []
        }
        
        try:
            # åŸºäºåˆ†æ•°ç¡®å®šä¸»è¦é£æ ¼
            max_score = 0
            primary_dimension = ""
            
            for dimension, score in style_scores.items():
                if score > max_score:
                    max_score = score
                    primary_dimension = dimension
            
            # é£æ ¼æ˜ å°„
            style_mapping = {
                "conceptual_organization": "ç³»ç»Ÿæ€§æ€ç»´å‹",
                "semantic_coherence": "é€»è¾‘è¿è´¯å‹",
                "creative_association": "åˆ›æ–°è”æƒ³å‹",
                "emotional_expression": "æƒ…æ„Ÿè¡¨è¾¾å‹",
                "cognitive_complexity": "å¤æ‚æ€ç»´å‹",
                "thematic_focus": "ä¸“æ³¨èšç„¦å‹"
            }
            
            classification["primary_style"] = style_mapping.get(primary_dimension, "ç»¼åˆå‹")
            classification["style_strength"] = max_score
            
            # æ¬¡è¦é£æ ¼ï¼ˆåˆ†æ•°>3.5çš„å…¶ä»–ç»´åº¦ï¼‰
            secondary_styles = []
            for dimension, score in style_scores.items():
                if dimension != primary_dimension and score > 3.5:
                    secondary_styles.append(style_mapping.get(dimension, dimension))
            
            classification["secondary_styles"] = secondary_styles
            
            # é£æ ¼ç‰¹å¾
            characteristics = []
            if style_scores.get("conceptual_organization", 0) > 4.0:
                characteristics.append("æ¦‚å¿µç»„ç»‡èƒ½åŠ›å¼º")
            if style_scores.get("creative_association", 0) > 4.0:
                characteristics.append("å¯Œæœ‰åˆ›æ–°æ€§")
            if style_scores.get("emotional_expression", 0) > 4.0:
                characteristics.append("æƒ…æ„Ÿè¡¨è¾¾ä¸°å¯Œ")
            if style_scores.get("semantic_coherence", 0) > 4.0:
                characteristics.append("é€»è¾‘æ€§å¼º")
            
            classification["style_characteristics"] = characteristics
        
        except Exception as e:
            classification["error"] = str(e)
        
        return classification
    
    def _calculate_comparative_metrics(self, feature_vector: List[float],
                                     style_scores: Dict[str, float]) -> Dict[str, Any]:
        """è®¡ç®—æ¯”è¾ƒæŒ‡æ ‡"""
        metrics = {
            "feature_vector_norm": 0.0,
            "style_score_average": 0.0,
            "style_score_variance": 0.0,
            "distinctiveness_index": 0.0,
            "complexity_index": 0.0
        }
        
        try:
            # ç‰¹å¾å‘é‡èŒƒæ•°
            if feature_vector:
                metrics["feature_vector_norm"] = float(np.linalg.norm(feature_vector))
            
            # é£æ ¼åˆ†æ•°ç»Ÿè®¡
            if style_scores:
                scores = list(style_scores.values())
                metrics["style_score_average"] = float(np.mean(scores))
                metrics["style_score_variance"] = float(np.var(scores))
                
                # ç‹¬ç‰¹æ€§æŒ‡æ•°ï¼ˆåŸºäºåˆ†æ•°æ–¹å·®ï¼‰
                metrics["distinctiveness_index"] = min(1.0, metrics["style_score_variance"] / 2.0)
                
                # å¤æ‚åº¦æŒ‡æ•°ï¼ˆåŸºäºé«˜åˆ†ç»´åº¦æ•°é‡ï¼‰
                high_score_count = sum(1 for score in scores if score > 4.0)
                metrics["complexity_index"] = high_score_count / len(scores)
        
        except Exception as e:
            metrics["error"] = str(e)
        
        return metrics
    
    def _generate_profile_summary(self, profile: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆç”»åƒæ‘˜è¦"""
        summary = {
            "profile_type": "unknown",
            "key_strengths": [],
            "potential_improvements": [],
            "style_description": "",
            "uniqueness_score": 0.0
        }
        
        try:
            style_classification = profile.get("style_classification", {})
            style_scores = profile.get("style_scores", {})
            comparative_metrics = profile.get("comparative_metrics", {})
            
            # ç”»åƒç±»å‹
            summary["profile_type"] = style_classification.get("primary_style", "ç»¼åˆå‹")
            
            # å…³é”®ä¼˜åŠ¿ï¼ˆåˆ†æ•°>4.0çš„ç»´åº¦ï¼‰
            strengths = []
            for dimension, score in style_scores.items():
                if score > 4.0:
                    strengths.append(self.style_dimensions.get(dimension, dimension))
            summary["key_strengths"] = strengths
            
            # æ½œåœ¨æ”¹è¿›ï¼ˆåˆ†æ•°<3.0çš„ç»´åº¦ï¼‰
            improvements = []
            for dimension, score in style_scores.items():
                if score < 3.0:
                    improvements.append(self.style_dimensions.get(dimension, dimension))
            summary["potential_improvements"] = improvements
            
            # é£æ ¼æè¿°
            primary_style = style_classification.get("primary_style", "")
            characteristics = style_classification.get("style_characteristics", [])
            summary["style_description"] = f"{primary_style}ï¼Œç‰¹ç‚¹ï¼š{', '.join(characteristics)}"
            
            # ç‹¬ç‰¹æ€§åˆ†æ•°
            summary["uniqueness_score"] = comparative_metrics.get("distinctiveness_index", 0.0)
        
        except Exception as e:
            summary["error"] = str(e)
        
        return summary
    
    def _encode_categorical(self, category: str) -> float:
        """ç¼–ç åˆ†ç±»å˜é‡"""
        encoding_map = {
            "ç´§å¯†": 1.0,
            "é€‚ä¸­": 2.0,
            "åˆ†æ•£": 3.0,
            "unknown": 2.0
        }
        return encoding_map.get(category, 2.0)
    
    def _calculate_emotion_ratio(self, emotional_dist: Dict[str, Any], emotion_type: str) -> float:
        """è®¡ç®—æƒ…æ„Ÿæ¯”ä¾‹"""
        try:
            count_key = f"{emotion_type}_count"
            emotion_count = emotional_dist.get(count_key, 0)
            total_count = (emotional_dist.get("positive_count", 0) + 
                          emotional_dist.get("negative_count", 0) + 
                          emotional_dist.get("neutral_count", 0))
            
            return emotion_count / total_count if total_count > 0 else 0.0
        except:
            return 0.0
    
    def _calculate_emotional_balance(self, emotional_dist: Dict[str, Any]) -> float:
        """è®¡ç®—æƒ…æ„Ÿå¹³è¡¡åº¦"""
        try:
            pos_count = emotional_dist.get("positive_count", 0)
            neg_count = emotional_dist.get("negative_count", 0)
            
            if pos_count + neg_count == 0:
                return 1.0  # å®Œå…¨ä¸­æ€§
            
            # å¹³è¡¡åº¦ = è¾ƒå°å€¼ / è¾ƒå¤§å€¼
            return min(pos_count, neg_count) / max(pos_count, neg_count) if max(pos_count, neg_count) > 0 else 0.0
        except:
            return 0.5
    
    def _extract_llm_features(self, analysis_results: Dict[str, Any]) -> Dict[str, Any]:
        """æå–LLMç‰¹å¾"""
        llm_features = {
            "cluster_coherence": 3.0,
            "novelty_creativity": 3.0,
            "emotional_sophistication": 3.0
        }
        
        try:
            # ä»èšç±»åˆ†æä¸­æå–LLMè¯„ä¼°
            clustering_analysis = analysis_results.get("clustering_analysis", {})
            llm_interpretation = clustering_analysis.get("llm_interpretation", {})
            
            if "overall_assessment" in llm_interpretation:
                assessment = llm_interpretation["overall_assessment"]
                llm_features["cluster_coherence"] = assessment.get("thematic_clarity", 3.0)
            
            # ä»åˆ›æ–°åº¦è¯„ä¼°ä¸­æå–
            novelty_assessment = analysis_results.get("novelty_assessment", {})
            llm_assessments = novelty_assessment.get("llm_assessments", {})
            
            if "overall_creativity" in llm_assessments:
                creativity = llm_assessments["overall_creativity"]
                llm_features["novelty_creativity"] = creativity.get("creative_density", 3.0)
            
            # ä»æƒ…æ„Ÿåˆ†æä¸­æå–
            emotional_analysis = analysis_results.get("emotional_analysis", {})
            llm_analysis = emotional_analysis.get("llm_analysis", {})
            
            if "emotional_patterns" in llm_analysis:
                patterns = llm_analysis["emotional_patterns"]
                llm_features["emotional_sophistication"] = patterns.get("emotional_sophistication", 3.0)
        
        except Exception as e:
            pass  # ä½¿ç”¨é»˜è®¤å€¼
        
        return llm_features
    
    def _generate_profile_id(self) -> str:
        """ç”Ÿæˆç”»åƒID"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
        return f"semantic_profile_{timestamp}"
    
    def save_profile(self, profile: Dict[str, Any], filename: str = None) -> str:
        """ä¿å­˜è¯­ä¹‰é£æ ¼ç”»åƒ"""
        if not filename:
            profile_id = profile.get("profile_id", "unknown")
            filename = f"{profile_id}.json"
        
        filepath = os.path.join(self.storage_path, filename)
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(profile, f, ensure_ascii=False, indent=2)
            return filepath
        except Exception as e:
            return f"ä¿å­˜å¤±è´¥: {str(e)}"
    
    def load_profile(self, filename: str) -> Dict[str, Any]:
        """åŠ è½½è¯­ä¹‰é£æ ¼ç”»åƒ"""
        filepath = os.path.join(self.storage_path, filename)

        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            return {"error": f"åŠ è½½å¤±è´¥: {str(e)}"}

    def compare_profiles(self, profile1: Dict[str, Any], profile2: Dict[str, Any]) -> Dict[str, Any]:
        """æ¯”è¾ƒä¸¤ä¸ªè¯­ä¹‰é£æ ¼ç”»åƒ"""
        comparison = {
            "comparison_time": datetime.now().isoformat(),
            "profile1_name": profile1.get("document_name", "æ–‡æ¡£1"),
            "profile2_name": profile2.get("document_name", "æ–‡æ¡£2"),
            "similarity_score": 0.0,
            "dimension_differences": {},
            "style_compatibility": "unknown",
            "comparison_summary": {}
        }

        try:
            # æ¯”è¾ƒç‰¹å¾å‘é‡
            vector1 = profile1.get("feature_vector", [])
            vector2 = profile2.get("feature_vector", [])

            if vector1 and vector2 and len(vector1) == len(vector2):
                # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
                from sklearn.metrics.pairwise import cosine_similarity
                similarity = cosine_similarity([vector1], [vector2])[0][0]
                comparison["similarity_score"] = float(similarity)

            # æ¯”è¾ƒé£æ ¼åˆ†æ•°
            scores1 = profile1.get("style_scores", {})
            scores2 = profile2.get("style_scores", {})

            dimension_diffs = {}
            for dimension in self.style_dimensions:
                score1 = scores1.get(dimension, 3.0)
                score2 = scores2.get(dimension, 3.0)
                dimension_diffs[dimension] = {
                    "profile1_score": score1,
                    "profile2_score": score2,
                    "difference": abs(score1 - score2),
                    "similarity": 1 - (abs(score1 - score2) / 4.0)  # æ ‡å‡†åŒ–åˆ°0-1
                }

            comparison["dimension_differences"] = dimension_diffs

            # é£æ ¼å…¼å®¹æ€§
            avg_dimension_similarity = np.mean([d["similarity"] for d in dimension_diffs.values()])
            if avg_dimension_similarity > 0.8:
                comparison["style_compatibility"] = "é«˜åº¦å…¼å®¹"
            elif avg_dimension_similarity > 0.6:
                comparison["style_compatibility"] = "è¾ƒä¸ºå…¼å®¹"
            elif avg_dimension_similarity > 0.4:
                comparison["style_compatibility"] = "éƒ¨åˆ†å…¼å®¹"
            else:
                comparison["style_compatibility"] = "å·®å¼‚è¾ƒå¤§"

            # ç”Ÿæˆæ¯”è¾ƒæ‘˜è¦
            comparison["comparison_summary"] = self._generate_comparison_summary(comparison)

        except Exception as e:
            comparison["error"] = str(e)

        return comparison

    def _generate_comparison_summary(self, comparison: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæ¯”è¾ƒæ‘˜è¦"""
        summary = {
            "overall_similarity": comparison.get("similarity_score", 0.0),
            "most_similar_dimensions": [],
            "most_different_dimensions": [],
            "compatibility_assessment": comparison.get("style_compatibility", "unknown")
        }

        try:
            dimension_diffs = comparison.get("dimension_differences", {})

            # æ‰¾å‡ºæœ€ç›¸ä¼¼å’Œæœ€ä¸åŒçš„ç»´åº¦
            similarities = [(dim, data["similarity"]) for dim, data in dimension_diffs.items()]
            similarities.sort(key=lambda x: x[1], reverse=True)

            summary["most_similar_dimensions"] = [dim for dim, sim in similarities[:2]]
            summary["most_different_dimensions"] = [dim for dim, sim in similarities[-2:]]

        except Exception as e:
            summary["error"] = str(e)

        return summary
