#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Style Alignment Engine - æ ¸å¿ƒæ¨¡å—

Author: AI Assistant (Claude)
Created: 2025-01-28
Last Modified: 2025-01-28
Modified By: AI Assistant (Claude)
AI Assisted: æ˜¯ - Claude 3.5 Sonnet
Version: v1.0
License: MIT
"""


import json
import os
import math
from typing import Dict, Any, List, Tuple, Optional
from datetime import datetime

try:
    import numpy as np
    from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances
    from sklearn.cluster import KMeans
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    print("Warning: scikit-learn not available. Some features will be limited.")


class StyleSimilarityCalculator:
    """æ–‡é£ç›¸ä¼¼åº¦è®¡ç®—å™¨"""
    
    def __init__(self):
        self.similarity_methods = ["cosine", "euclidean", "manhattan", "weighted"]
    
    def calculate_similarity(self, features1: List[float], features2: List[float], 
                           method: str = "cosine", weights: List[float] = None) -> Dict[str, Any]:
        """
        è®¡ç®—ä¸¤ä¸ªç‰¹å¾å‘é‡çš„ç›¸ä¼¼åº¦
        
        Args:
            features1: ç¬¬ä¸€ä¸ªç‰¹å¾å‘é‡
            features2: ç¬¬äºŒä¸ªç‰¹å¾å‘é‡
            method: ç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³•
            weights: ç‰¹å¾æƒé‡ï¼ˆç”¨äºåŠ æƒè®¡ç®—ï¼‰
        """
        result = {
            "calculation_time": datetime.now().isoformat(),
            "method": method,
            "similarity_score": 0.0,
            "distance": 0.0,
            "feature_comparison": {},
            "success": False
        }
        
        try:
            if not features1 or not features2:
                raise ValueError("Empty feature vectors")
            
            if len(features1) != len(features2):
                raise ValueError("Feature vectors must have the same length")
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            vec1 = np.array(features1)
            vec2 = np.array(features2)
            
            if method == "cosine":
                similarity = self._cosine_similarity(vec1, vec2)
                distance = 1 - similarity
            elif method == "euclidean":
                distance = self._euclidean_distance(vec1, vec2)
                similarity = 1 / (1 + distance)  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦
            elif method == "manhattan":
                distance = self._manhattan_distance(vec1, vec2)
                similarity = 1 / (1 + distance)
            elif method == "weighted":
                if weights is None:
                    weights = [1.0] * len(features1)
                similarity, distance = self._weighted_similarity(vec1, vec2, weights)
            else:
                raise ValueError(f"Unknown similarity method: {method}")
            
            result.update({
                "similarity_score": float(similarity),
                "distance": float(distance),
                "feature_comparison": self._compare_features(vec1, vec2),
                "success": True
            })
            
        except Exception as e:
            result["error"] = str(e)
        
        return result
    
    def _cosine_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        if SKLEARN_AVAILABLE:
            return cosine_similarity([vec1], [vec2])[0][0]
        else:
            # æ‰‹åŠ¨è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            dot_product = np.dot(vec1, vec2)
            norm1 = np.linalg.norm(vec1)
            norm2 = np.linalg.norm(vec2)
            if norm1 == 0 or norm2 == 0:
                return 0.0
            return dot_product / (norm1 * norm2)
    
    def _euclidean_distance(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
        """è®¡ç®—æ¬§æ°è·ç¦»"""
        if SKLEARN_AVAILABLE:
            return euclidean_distances([vec1], [vec2])[0][0]
        else:
            return np.sqrt(np.sum((vec1 - vec2) ** 2))
    
    def _manhattan_distance(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
        """è®¡ç®—æ›¼å“ˆé¡¿è·ç¦»"""
        return np.sum(np.abs(vec1 - vec2))
    
    def _weighted_similarity(self, vec1: np.ndarray, vec2: np.ndarray, 
                           weights: List[float]) -> Tuple[float, float]:
        """è®¡ç®—åŠ æƒç›¸ä¼¼åº¦"""
        weights = np.array(weights)
        
        # åŠ æƒæ¬§æ°è·ç¦»
        weighted_diff = weights * (vec1 - vec2) ** 2
        weighted_distance = np.sqrt(np.sum(weighted_diff))
        
        # è½¬æ¢ä¸ºç›¸ä¼¼åº¦
        similarity = 1 / (1 + weighted_distance)
        
        return similarity, weighted_distance
    
    def _compare_features(self, vec1: np.ndarray, vec2: np.ndarray) -> Dict[str, Any]:
        """æ¯”è¾ƒç‰¹å¾å‘é‡çš„è¯¦ç»†ä¿¡æ¯"""
        return {
            "mean_difference": float(np.mean(np.abs(vec1 - vec2))),
            "max_difference": float(np.max(np.abs(vec1 - vec2))),
            "correlation": float(np.corrcoef(vec1, vec2)[0, 1]) if len(vec1) > 1 else 0.0,
            "feature_count": len(vec1)
        }


class StyleTransferEngine:
    """æ–‡é£è¿ç§»å¼•æ“"""
    
    def __init__(self, llm_client=None):
        self.llm_client = llm_client
        self.transfer_strategies = ["direct", "gradual", "selective"]
    
    def generate_style_transfer_prompt(self, source_text: str, target_style_features: Dict[str, Any], 
                                     content_to_rewrite: str, strategy: str = "direct") -> str:
        """ç”Ÿæˆæ–‡é£è¿ç§»æç¤ºè¯"""
        
        # è§£æç›®æ ‡é£æ ¼ç‰¹å¾
        style_description = self._features_to_description(target_style_features)
        
        if strategy == "direct":
            return self._direct_transfer_prompt(source_text, style_description, content_to_rewrite)
        elif strategy == "gradual":
            return self._gradual_transfer_prompt(source_text, style_description, content_to_rewrite)
        elif strategy == "selective":
            return self._selective_transfer_prompt(source_text, style_description, content_to_rewrite)
        else:
            raise ValueError(f"Unknown transfer strategy: {strategy}")
    
    def _features_to_description(self, features: Dict[str, Any]) -> str:
        """å°†ç‰¹å¾è½¬æ¢ä¸ºæ–‡å­—æè¿°"""
        descriptions = []
        
        # å¤„ç†LLMç‰¹å¾
        if "llm_features" in features:
            evaluations = features["llm_features"].get("evaluations", {})
            for dimension, eval_data in evaluations.items():
                if isinstance(eval_data, dict) and "score" in eval_data:
                    score = eval_data["score"]
                    reason = eval_data.get("reason", "")
                    if score >= 4:
                        descriptions.append(f"é«˜{dimension}ï¼ˆ{reason}ï¼‰")
                    elif score <= 2:
                        descriptions.append(f"ä½{dimension}ï¼ˆ{reason}ï¼‰")
        
        # å¤„ç†é‡åŒ–ç‰¹å¾
        if "quantitative_features" in features:
            quant = features["quantitative_features"]
            lexical = quant.get("lexical_features", {})
            syntactic = quant.get("syntactic_features", {})
            
            if lexical.get("ttr", 0) > 0.7:
                descriptions.append("è¯æ±‡ä¸°å¯Œå¤šæ ·")
            if syntactic.get("avg_sentence_length", 0) > 20:
                descriptions.append("å¥å­è¾ƒé•¿ï¼Œç»“æ„å¤æ‚")
            elif syntactic.get("avg_sentence_length", 0) < 10:
                descriptions.append("å¥å­ç®€çŸ­ï¼Œè¡¨è¾¾ç®€æ´")
        
        return "ï¼›".join(descriptions) if descriptions else "æ ‡å‡†æ–‡é£"
    
    def _direct_transfer_prompt(self, source_text: str, style_description: str, content: str) -> str:
        """ç›´æ¥è¿ç§»æç¤ºè¯"""
        return f"""è¯·å°†ä»¥ä¸‹å†…å®¹æ”¹å†™ä¸ºæŒ‡å®šçš„æ–‡é£é£æ ¼ã€‚

å‚è€ƒæ–‡æœ¬ï¼ˆç›®æ ‡é£æ ¼ï¼‰ï¼š
{source_text[:500]}...

ç›®æ ‡é£æ ¼ç‰¹å¾ï¼š
{style_description}

éœ€è¦æ”¹å†™çš„å†…å®¹ï¼š
{content}

æ”¹å†™è¦æ±‚ï¼š
1. ä¿æŒåŸæ–‡çš„æ ¸å¿ƒä¿¡æ¯å’Œé€»è¾‘ç»“æ„ä¸å˜
2. è°ƒæ•´è¯æ±‡é€‰æ‹©ï¼Œä½¿å…¶ç¬¦åˆç›®æ ‡é£æ ¼çš„ç”¨è¯ä¹ æƒ¯
3. è°ƒæ•´å¥å¼ç»“æ„ï¼Œä¿æŒä¸ç›®æ ‡é£æ ¼çš„ä¸€è‡´æ€§
4. è°ƒæ•´è¯­æ°”å’Œè¡¨è¾¾æ–¹å¼ï¼ŒåŒ¹é…ç›®æ ‡é£æ ¼çš„æƒ…æ„Ÿè‰²å½©
5. ç¡®ä¿æ”¹å†™åçš„æ–‡æœ¬è‡ªç„¶æµç•…ï¼Œç¬¦åˆä¸­æ–‡è¡¨è¾¾ä¹ æƒ¯

è¯·æä¾›æ”¹å†™ç»“æœï¼š"""
    
    def _gradual_transfer_prompt(self, source_text: str, style_description: str, content: str) -> str:
        """æ¸è¿›å¼è¿ç§»æç¤ºè¯"""
        return f"""è¯·åˆ†æ­¥éª¤å°†ä»¥ä¸‹å†…å®¹é€æ­¥è°ƒæ•´ä¸ºç›®æ ‡æ–‡é£ã€‚

å‚è€ƒæ–‡æœ¬ï¼š{source_text[:300]}...
ç›®æ ‡é£æ ¼ï¼š{style_description}
åŸå§‹å†…å®¹ï¼š{content}

è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤è¿›è¡Œè°ƒæ•´ï¼š

æ­¥éª¤1 - è¯æ±‡è°ƒæ•´ï¼š
[è°ƒæ•´ç”¨è¯ï¼Œæ›¿æ¢ä¸ç¬¦åˆç›®æ ‡é£æ ¼çš„è¯æ±‡]

æ­¥éª¤2 - å¥å¼è°ƒæ•´ï¼š
[è°ƒæ•´å¥å­ç»“æ„ï¼Œä½¿å…¶ç¬¦åˆç›®æ ‡é£æ ¼]

æ­¥éª¤3 - è¯­æ°”è°ƒæ•´ï¼š
[è°ƒæ•´è¯­æ°”å’Œè¡¨è¾¾æ–¹å¼]

æœ€ç»ˆç»“æœï¼š
[æä¾›æœ€ç»ˆçš„å®Œæ•´æ”¹å†™æ–‡æœ¬]"""
    
    def _selective_transfer_prompt(self, source_text: str, style_description: str, content: str) -> str:
        """é€‰æ‹©æ€§è¿ç§»æç¤ºè¯"""
        return f"""è¯·é€‰æ‹©æ€§åœ°è°ƒæ•´ä»¥ä¸‹å†…å®¹çš„æ–‡é£ï¼Œé‡ç‚¹å…³æ³¨æœ€éœ€è¦æ”¹è¿›çš„æ–¹é¢ã€‚

å‚è€ƒæ–‡æœ¬ï¼š{source_text[:300]}...
ç›®æ ‡é£æ ¼ï¼š{style_description}
åŸå§‹å†…å®¹ï¼š{content}

è¯·åˆ†æå¹¶é€‰æ‹©æ€§è°ƒæ•´ï¼š

éœ€è¦é‡ç‚¹è°ƒæ•´çš„æ–¹é¢ï¼š
[è¯†åˆ«æœ€éœ€è¦è°ƒæ•´çš„1-2ä¸ªæ–¹é¢ï¼Œå¦‚è¯æ±‡æ­£å¼åº¦ã€å¥å¼å¤æ‚åº¦ç­‰]

è°ƒæ•´ç­–ç•¥ï¼š
[è¯´æ˜å…·ä½“çš„è°ƒæ•´ç­–ç•¥]

æ”¹å†™ç»“æœï¼š
[æä¾›æ”¹å†™åçš„æ–‡æœ¬]

ä¿æŒä¸å˜çš„æ–¹é¢ï¼š
[è¯´æ˜å“ªäº›æ–¹é¢ä¿æŒåŸæ ·ï¼Œä»¥åŠåŸå› ]"""
    
    def perform_style_transfer(self, source_features: Dict[str, Any], 
                             target_features: Dict[str, Any],
                             content_to_rewrite: str,
                             strategy: str = "direct") -> Dict[str, Any]:
        """æ‰§è¡Œæ–‡é£è¿ç§»"""
        if not self.llm_client:
            return {"error": "LLM client not available"}
        
        result = {
            "transfer_time": datetime.now().isoformat(),
            "strategy": strategy,
            "original_content": content_to_rewrite,
            "rewritten_content": "",
            "transfer_analysis": {},
            "success": False
        }
        
        try:
            # ç”Ÿæˆè¿ç§»æç¤ºè¯
            source_text = source_features.get("text_preview", "")
            prompt = self.generate_style_transfer_prompt(
                source_text, target_features, content_to_rewrite, strategy
            )
            
            # è°ƒç”¨LLMè¿›è¡Œæ–‡é£è¿ç§»
            response = self.llm_client.generate(prompt)
            
            # è§£æå“åº”
            rewritten_content = self._extract_rewritten_content(response)
            
            result.update({
                "rewritten_content": rewritten_content,
                "raw_llm_response": response,
                "transfer_analysis": self._analyze_transfer_result(
                    content_to_rewrite, rewritten_content
                ),
                "success": True
            })
            
        except Exception as e:
            result["error"] = str(e)
        
        return result
    
    def _extract_rewritten_content(self, llm_response: str) -> str:
        """ä»LLMå“åº”ä¸­æå–æ”¹å†™å†…å®¹"""
        # å¯»æ‰¾æ”¹å†™ç»“æœçš„æ ‡è¯†
        markers = ["æ”¹å†™ç»“æœï¼š", "æœ€ç»ˆç»“æœï¼š", "é‡å†™ç»“æœï¼š", "æ”¹å†™åï¼š"]
        
        for marker in markers:
            if marker in llm_response:
                parts = llm_response.split(marker, 1)
                if len(parts) > 1:
                    return parts[1].strip()
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡è¯†ï¼Œè¿”å›æ•´ä¸ªå“åº”
        return llm_response.strip()
    
    def _analyze_transfer_result(self, original: str, rewritten: str) -> Dict[str, Any]:
        """åˆ†æè¿ç§»ç»“æœ"""
        return {
            "original_length": len(original),
            "rewritten_length": len(rewritten),
            "length_change_ratio": len(rewritten) / len(original) if len(original) > 0 else 0,
            "word_overlap": self._calculate_word_overlap(original, rewritten),
            "structure_similarity": self._estimate_structure_similarity(original, rewritten)
        }
    
    def _calculate_word_overlap(self, text1: str, text2: str) -> float:
        """è®¡ç®—è¯æ±‡é‡å åº¦"""
        words1 = set(text1.split())
        words2 = set(text2.split())
        
        if not words1 and not words2:
            return 1.0
        
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        return len(intersection) / len(union) if union else 0.0
    
    def _estimate_structure_similarity(self, text1: str, text2: str) -> float:
        """ä¼°ç®—ç»“æ„ç›¸ä¼¼åº¦"""
        # ç®€å•çš„ç»“æ„ç›¸ä¼¼åº¦ä¼°ç®—ï¼ˆåŸºäºå¥å­æ•°é‡å’Œé•¿åº¦åˆ†å¸ƒï¼‰
        sentences1 = text1.split('ã€‚')
        sentences2 = text2.split('ã€‚')
        
        if len(sentences1) == 0 and len(sentences2) == 0:
            return 1.0
        
        # å¥å­æ•°é‡ç›¸ä¼¼åº¦
        count_similarity = 1 - abs(len(sentences1) - len(sentences2)) / max(len(sentences1), len(sentences2))
        
        return count_similarity


class StyleAlignmentEngine:
    """æ–‡é£å¯¹é½å¼•æ“"""
    
    def __init__(self, llm_client=None, storage_path: str = "src/core/knowledge_base/style_alignments"):
        self.similarity_calculator = StyleSimilarityCalculator()
        self.transfer_engine = StyleTransferEngine(llm_client)
        self.storage_path = storage_path
        os.makedirs(storage_path, exist_ok=True)
    
    def align_style(self, source_features: Dict[str, Any], 
                   target_features: Dict[str, Any],
                   content_to_align: str,
                   alignment_strategy: str = "comprehensive") -> Dict[str, Any]:
        """
        æ‰§è¡Œæ–‡é£å¯¹é½
        
        Args:
            source_features: æºæ–‡æ¡£ç‰¹å¾
            target_features: ç›®æ ‡æ–‡æ¡£ç‰¹å¾
            content_to_align: éœ€è¦å¯¹é½çš„å†…å®¹
            alignment_strategy: å¯¹é½ç­–ç•¥
        """
        result = {
            "alignment_time": datetime.now().isoformat(),
            "strategy": alignment_strategy,
            "similarity_analysis": {},
            "transfer_result": {},
            "alignment_quality": {},
            "success": False
        }
        
        try:
            # 1. è®¡ç®—é£æ ¼ç›¸ä¼¼åº¦
            source_vector = source_features.get("feature_vector", [])
            target_vector = target_features.get("feature_vector", [])
            
            if source_vector and target_vector and len(source_vector) > 0 and len(target_vector) > 0:
                similarity_result = self.similarity_calculator.calculate_similarity(
                    source_vector, target_vector, method="cosine"
                )
                result["similarity_analysis"] = similarity_result
            
            # 2. æ‰§è¡Œæ–‡é£è¿ç§»
            print("ğŸ”„ å¼€å§‹æ–‡é£è¿ç§»...")
            transfer_result = self.transfer_engine.perform_style_transfer(
                source_features, target_features, content_to_align, strategy="direct"
            )
            result["transfer_result"] = transfer_result
            
            # 3. å¦‚æœLLMè¿ç§»å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ä¿å­˜çš„æ–‡é£æç¤ºè¯
            if not transfer_result.get("success") and "error" in transfer_result:
                print("âš ï¸ LLMè¿ç§»å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ä¿å­˜çš„æ–‡é£æç¤ºè¯...")
                fallback_result = self._perform_fallback_style_transfer(
                    source_features, target_features, content_to_align
                )
                if fallback_result.get("success"):
                    transfer_result = fallback_result
                    result["transfer_result"] = transfer_result
                    result["used_fallback"] = True
            
            # 4. è¯„ä¼°å¯¹é½è´¨é‡
            if transfer_result.get("success"):
                quality_assessment = self._assess_alignment_quality(
                    content_to_align, 
                    transfer_result.get("rewritten_content", ""),
                    source_features,
                    target_features
                )
                result["alignment_quality"] = quality_assessment
            
            result["success"] = transfer_result.get("success", False)
            
        except Exception as e:
            result["error"] = str(e)
            print(f"âŒ æ–‡é£å¯¹é½å¤±è´¥: {str(e)}")
        
        return result
    
    def _perform_fallback_style_transfer(self, source_features: Dict[str, Any],
                                       target_features: Dict[str, Any],
                                       content_to_align: str) -> Dict[str, Any]:
        """ä½¿ç”¨ä¿å­˜çš„æ–‡é£æç¤ºè¯è¿›è¡Œå›é€€è¿ç§»"""
        try:
            # è·å–ç›®æ ‡æ–‡é£æ¨¡æ¿ä¸­çš„è¯¦ç»†æç¤ºè¯
            target_style_prompt = target_features.get("style_prompt", "")
            target_style_type = target_features.get("style_type", "business_professional")
            
            if not target_style_prompt:
                # å¦‚æœæ²¡æœ‰ä¿å­˜çš„æç¤ºè¯ï¼Œç”ŸæˆåŸºç¡€æç¤ºè¯
                target_style_prompt = self._generate_basic_style_prompt(target_features)
            
            # æ„å»ºå®Œæ•´çš„è¿ç§»æç¤ºè¯
            full_prompt = self._build_enhanced_style_migration_prompt(
                content_to_align, target_style_prompt, target_style_type, target_features
            )
            
            # å°è¯•è°ƒç”¨LLM
            if self.transfer_engine.llm_client:
                print("ğŸ¤– ä½¿ç”¨LLMè¿›è¡Œå›é€€æ–‡é£è¿ç§»...")
                response = self.transfer_engine.llm_client.generate(full_prompt)
                rewritten_content = self.transfer_engine._extract_rewritten_content(response)
                
                return {
                    "success": True,
                    "rewritten_content": rewritten_content,
                    "raw_llm_response": response,
                    "used_fallback": True,
                    "fallback_method": "saved_style_prompt"
                }
            else:
                # å¦‚æœLLMä¸å¯ç”¨ï¼Œä½¿ç”¨è§„åˆ™åŸºç¡€è¿ç§»
                print("ğŸ“ ä½¿ç”¨è§„åˆ™åŸºç¡€è¿ç§»...")
                rewritten_content = self._rule_based_style_migration(
                    content_to_align, target_style_type, target_features
                )
                
                return {
                    "success": True,
                    "rewritten_content": rewritten_content,
                    "used_fallback": True,
                    "fallback_method": "rule_based"
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": f"å›é€€è¿ç§»å¤±è´¥: {str(e)}",
                "used_fallback": True
            }
    
    def _build_enhanced_style_migration_prompt(self, content: str, style_prompt: str,
                                             style_type: str, style_features: Dict[str, Any]) -> str:
        """æ„å»ºå¢å¼ºçš„æ–‡é£è¿ç§»æç¤ºè¯"""
        
        # è·å–é£æ ¼ç‰¹å¾æè¿°
        style_description = self._extract_style_description(style_features)
        
        prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹è¯¦ç»†çš„æ–‡é£è¦æ±‚ï¼Œå°†å†…å®¹æ”¹å†™ä¸ºç›®æ ‡é£æ ¼ã€‚

## ç›®æ ‡æ–‡é£è¦æ±‚
{style_prompt}

## é£æ ¼ç‰¹å¾è¯¦æƒ…
{style_description}

## éœ€è¦æ”¹å†™çš„å†…å®¹
{content}

## æ”¹å†™è¦æ±‚
1. ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ–‡é£è¦æ±‚è¿›è¡Œæ”¹å†™
2. ä¿æŒåŸæ–‡çš„æ ¸å¿ƒä¿¡æ¯å’Œé€»è¾‘ç»“æ„ä¸å˜
3. è°ƒæ•´è¯æ±‡é€‰æ‹©ã€å¥å¼ç»“æ„ã€è¯­æ°”è¡¨è¾¾ç­‰å„ä¸ªæ–¹é¢
4. ç¡®ä¿æ”¹å†™åçš„æ–‡æœ¬è‡ªç„¶æµç•…ï¼Œç¬¦åˆä¸­æ–‡è¡¨è¾¾ä¹ æƒ¯
5. é¿å…æ˜æ˜¾çš„AIç”Ÿæˆç—•è¿¹

## è¯·æä¾›æ”¹å†™ç»“æœ
è¯·ç›´æ¥è¿”å›æ”¹å†™åçš„å®Œæ•´æ–‡æœ¬ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–æ ‡è®°ã€‚"""
        
        return prompt
    
    def _extract_style_description(self, style_features: Dict[str, Any]) -> str:
        """æå–é£æ ¼ç‰¹å¾æè¿°"""
        descriptions = []
        
        # ä»é‡åŒ–ç‰¹å¾ä¸­æå–æè¿°
        quant_features = style_features.get("quantitative_features", {})
        if quant_features:
            lexical = quant_features.get("lexical_features", {})
            syntactic = quant_features.get("syntactic_features", {})
            
            if lexical.get("ttr", 0) > 0.7:
                descriptions.append("è¯æ±‡ä¸°å¯Œå¤šæ ·")
            if lexical.get("formal_word_density", 0) > 0.1:
                descriptions.append("ä½¿ç”¨è¾ƒå¤šæ­£å¼è¯æ±‡")
            if syntactic.get("avg_sentence_length", 0) > 20:
                descriptions.append("å¥å­è¾ƒé•¿ï¼Œç»“æ„å¤æ‚")
            elif syntactic.get("avg_sentence_length", 0) < 10:
                descriptions.append("å¥å­ç®€çŸ­ï¼Œè¡¨è¾¾ç®€æ´")
        
        # ä»LLMç‰¹å¾ä¸­æå–æè¿°
        llm_features = style_features.get("llm_features", {})
        if llm_features:
            evaluations = llm_features.get("evaluations", {})
            for dimension, eval_data in evaluations.items():
                if isinstance(eval_data, dict) and "score" in eval_data:
                    score = eval_data["score"]
                    reason = eval_data.get("reason", "")
                    if score >= 4:
                        descriptions.append(f"é«˜{dimension}ï¼ˆ{reason}ï¼‰")
                    elif score <= 2:
                        descriptions.append(f"ä½{dimension}ï¼ˆ{reason}ï¼‰")
        
        return "ï¼›".join(descriptions) if descriptions else "æ ‡å‡†æ–‡é£"
    
    def _generate_basic_style_prompt(self, style_features: Dict[str, Any]) -> str:
        """ç”ŸæˆåŸºç¡€æ–‡é£æç¤ºè¯"""
        style_type = style_features.get("style_type", "business_professional")
        
        style_prompts = {
            "business_professional": "è¯·æŒ‰ç…§å•†åŠ¡ä¸“ä¸šé£æ ¼è¿›è¡Œæ”¹å†™ï¼Œè¦æ±‚ï¼šæ­£å¼ã€ç®€æ´ã€é€»è¾‘æ¸…æ™°ã€é‡ç‚¹çªå‡º",
            "academic_research": "è¯·æŒ‰ç…§å­¦æœ¯ç ”ç©¶é£æ ¼è¿›è¡Œæ”¹å†™ï¼Œè¦æ±‚ï¼šä¸¥è°¨ã€å®¢è§‚ã€è®ºè¯å……åˆ†ã€å¼•ç”¨è§„èŒƒ",
            "formal_official": "è¯·æŒ‰ç…§æ­£å¼å…¬æ–‡é£æ ¼è¿›è¡Œæ”¹å†™ï¼Œè¦æ±‚ï¼šè§„èŒƒã€å‡†ç¡®ã€æƒå¨ã€æ­£å¼",
            "narrative_descriptive": "è¯·æŒ‰ç…§å™è¿°æè¿°é£æ ¼è¿›è¡Œæ”¹å†™ï¼Œè¦æ±‚ï¼šç”ŸåŠ¨ã€å½¢è±¡ã€æƒ…æ„ŸçœŸå®ã€ç»†èŠ‚ä¸°å¯Œ",
            "concise_practical": "è¯·æŒ‰ç…§ç®€æ´å®ç”¨é£æ ¼è¿›è¡Œæ”¹å†™ï¼Œè¦æ±‚ï¼šè¨€ç®€æ„èµ…ã€ç›´æ¥æœ‰æ•ˆã€æ“ä½œæ€§å¼º"
        }
        
        return style_prompts.get(style_type, "è¯·ä¿æŒåŸæœ‰çš„å†™ä½œé£æ ¼")
    
    def _rule_based_style_migration(self, content: str, target_style: str, 
                                  style_features: Dict[str, Any]) -> str:
        """åŸºäºè§„åˆ™çš„æ–‡é£è¿ç§»"""
        migrated_content = content
        
        # æ ¹æ®ç›®æ ‡é£æ ¼åº”ç”¨ä¸åŒçš„è§„åˆ™
        if target_style == "business_professional":
            replacements = {
                "æˆ‘è§‰å¾—": "æˆ‘è®¤ä¸º",
                "æŒºå¥½çš„": "è¾ƒä¸ºç†æƒ³",
                "åº”è¯¥å¯ä»¥": "èƒ½å¤Ÿ",
                "è§£å†³é—®é¢˜": "è§£å†³ç›¸å…³é—®é¢˜",
                "ç”¨äº†": "é‡‡ç”¨äº†",
                "ç®—äº†ä¸€ä¸‹": "è¿›è¡Œäº†åˆ†æ",
                "æ€»çš„æ¥è¯´": "ç»¼ä¸Šæ‰€è¿°",
                "ä¸é”™": "è‰¯å¥½",
                "åº”è¯¥èƒ½ç”¨": "å…·å¤‡å¯è¡Œæ€§"
            }
        elif target_style == "academic_research":
            replacements = {
                "æˆ‘è§‰å¾—": "ç ”ç©¶è¡¨æ˜",
                "æŒºå¥½çš„": "å…·æœ‰ç§¯ææ•ˆæœ",
                "åº”è¯¥å¯ä»¥": "èƒ½å¤Ÿæœ‰æ•ˆ",
                "è§£å†³é—®é¢˜": "è§£å†³ç›¸å…³é—®é¢˜",
                "ç”¨äº†": "é‡‡ç”¨äº†",
                "ç®—äº†ä¸€ä¸‹": "è¿›è¡Œäº†ç»Ÿè®¡åˆ†æ",
                "æ€»çš„æ¥è¯´": "ç»¼ä¸Šæ‰€è¿°",
                "ä¸é”™": "è¡¨ç°è‰¯å¥½",
                "åº”è¯¥èƒ½ç”¨": "å…·å¤‡åº”ç”¨ä»·å€¼"
            }
        elif target_style == "formal_official":
            replacements = {
                "æˆ‘è§‰å¾—": "ç»åˆ†æè®¤ä¸º",
                "æŒºå¥½çš„": "è¡¨ç°è‰¯å¥½",
                "åº”è¯¥å¯ä»¥": "å…·å¤‡å¯è¡Œæ€§",
                "è§£å†³é—®é¢˜": "è§£å†³ç›¸å…³é—®é¢˜",
                "ç”¨äº†": "é‡‡ç”¨äº†",
                "ç®—äº†ä¸€ä¸‹": "è¿›è¡Œäº†åˆ†æ",
                "æ€»çš„æ¥è¯´": "ç»¼ä¸Šæ‰€è¿°",
                "ä¸é”™": "è¡¨ç°è‰¯å¥½",
                "åº”è¯¥èƒ½ç”¨": "å…·å¤‡å®æ–½æ¡ä»¶"
            }
        else:
            replacements = {}
        
        for old, new in replacements.items():
            migrated_content = migrated_content.replace(old, new)
        
        return migrated_content
    
    def _assess_alignment_quality(self, original: str, aligned: str,
                                source_features: Dict[str, Any],
                                target_features: Dict[str, Any]) -> Dict[str, Any]:
        """è¯„ä¼°å¯¹é½è´¨é‡"""
        assessment = {
            "content_preservation": 0.0,
            "style_alignment": 0.0,
            "fluency": 0.0,
            "overall_quality": 0.0
        }
        
        try:
            # å†…å®¹ä¿æŒåº¦ï¼ˆåŸºäºè¯æ±‡é‡å ï¼‰
            word_overlap = self.transfer_engine._calculate_word_overlap(original, aligned)
            assessment["content_preservation"] = word_overlap
            
            # é£æ ¼å¯¹é½åº¦ï¼ˆåŸºäºç‰¹å¾ç›¸ä¼¼åº¦ï¼‰
            source_vector = source_features.get("feature_vector", [])
            target_vector = target_features.get("feature_vector", [])
            
            if source_vector and target_vector:
                similarity = self.similarity_calculator.calculate_similarity(
                    source_vector, target_vector, method="cosine"
                )
                assessment["style_alignment"] = similarity.get("similarity_score", 0.0)
            
            # æµç•…åº¦ï¼ˆç®€å•ä¼°ç®—ï¼‰
            assessment["fluency"] = self._estimate_fluency(aligned)
            
            # æ•´ä½“è´¨é‡
            assessment["overall_quality"] = (
                assessment["content_preservation"] * 0.4 +
                assessment["style_alignment"] * 0.4 +
                assessment["fluency"] * 0.2
            )
            
        except Exception as e:
            assessment["error"] = str(e)
        
        return assessment
    
    def _estimate_fluency(self, text: str) -> float:
        """ä¼°ç®—æ–‡æœ¬æµç•…åº¦"""
        # ç®€å•çš„æµç•…åº¦ä¼°ç®—
        if not text:
            return 0.0
        
        # åŸºäºå¥å­é•¿åº¦åˆ†å¸ƒå’Œæ ‡ç‚¹ä½¿ç”¨çš„ç®€å•è¯„ä¼°
        sentences = text.split('ã€‚')
        if not sentences:
            return 0.5
        
        # å¥å­é•¿åº¦æ–¹å·®ï¼ˆè¿‡å¤§æˆ–è¿‡å°éƒ½ä¸å¥½ï¼‰
        lengths = [len(s.strip()) for s in sentences if s.strip()]
        if not lengths:
            return 0.5
        
        avg_length = sum(lengths) / len(lengths)
        variance = sum((l - avg_length) ** 2 for l in lengths) / len(lengths)
        
        # ç†æƒ³å¥é•¿åœ¨10-25å­—ä¹‹é—´
        length_score = 1.0 - abs(avg_length - 17.5) / 17.5
        variance_score = 1.0 - min(variance / 100, 1.0)  # æ–¹å·®è¿‡å¤§æ‰£åˆ†
        
        return max(0.0, min(1.0, (length_score + variance_score) / 2))
    
    def save_alignment_result(self, alignment_result: Dict[str, Any], filename: str = None) -> str:
        """ä¿å­˜å¯¹é½ç»“æœ"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"style_alignment_{timestamp}.json"

        filepath = os.path.join(self.storage_path, filename)

        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(alignment_result, f, ensure_ascii=False, indent=2)
            return filepath
        except Exception as e:
            return f"ä¿å­˜å¤±è´¥: {str(e)}"

    def batch_style_alignment(self, source_features: Dict[str, Any],
                            target_features: Dict[str, Any],
                            content_list: List[str]) -> Dict[str, Any]:
        """æ‰¹é‡æ–‡é£å¯¹é½"""
        results = {
            "batch_time": datetime.now().isoformat(),
            "total_items": len(content_list),
            "successful_alignments": 0,
            "failed_alignments": 0,
            "alignment_results": [],
            "batch_summary": {}
        }

        for i, content in enumerate(content_list):
            try:
                alignment_result = self.align_style(
                    source_features, target_features, content
                )

                if alignment_result.get("success"):
                    results["successful_alignments"] += 1
                else:
                    results["failed_alignments"] += 1

                alignment_result["item_index"] = i
                results["alignment_results"].append(alignment_result)

            except Exception as e:
                results["failed_alignments"] += 1
                results["alignment_results"].append({
                    "item_index": i,
                    "success": False,
                    "error": str(e),
                    "original_content": content
                })

        # ç”Ÿæˆæ‰¹é‡æ‘˜è¦
        results["batch_summary"] = {
            "success_rate": results["successful_alignments"] / results["total_items"] if results["total_items"] > 0 else 0,
            "average_quality": self._calculate_average_quality(results["alignment_results"]),
            "processing_time": datetime.now().isoformat()
        }

        return results

    def _calculate_average_quality(self, alignment_results: List[Dict[str, Any]]) -> float:
        """è®¡ç®—å¹³å‡è´¨é‡åˆ†æ•°"""
        quality_scores = []

        for result in alignment_results:
            if result.get("success") and "alignment_quality" in result:
                quality = result["alignment_quality"].get("overall_quality", 0.0)
                quality_scores.append(quality)

        return sum(quality_scores) / len(quality_scores) if quality_scores else 0.0
