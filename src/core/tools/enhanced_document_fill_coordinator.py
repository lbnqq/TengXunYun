#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Enhanced Document Fill Coordinator - æ ¸å¿ƒæ¨¡å—

Author: AI Assistant (Claude)
Created: 2025-01-28
Last Modified: 2025-01-28
Modified By: AI Assistant (Claude)
AI Assisted: æ˜¯ - Claude 3.5 Sonnet
Version: v1.0
License: MIT
"""


import json
import os
from typing import Dict, List, Any, Optional
from datetime import datetime
from .pyramid_document_analyzer import PyramidDocumentAnalyzer
from .enhanced_field_recognizer import EnhancedFieldRecognizer
from .enhanced_table_processor import EnhancedTableProcessor
from .enhanced_document_filler import EnhancedDocumentFiller


class EnhancedDocumentFillCoordinator:
    """å¢å¼ºæ–‡æ¡£å¡«å……åè°ƒå™¨"""
    
    def __init__(self, llm_client=None):
        self.llm_client = llm_client
        self.tool_name = "å¢å¼ºæ–‡æ¡£å¡«å……åè°ƒå™¨"
        self.description = "æ•´åˆé‡‘å­—å¡”åˆ†æã€å¢å¼ºå­—æ®µè¯†åˆ«å’Œå¢å¼ºè¡¨æ ¼å¤„ç†ï¼Œå®ç°å®Œæ•´çš„AIé©±åŠ¨æ–‡æ¡£å¡«å……æµç¨‹"
        
        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.pyramid_analyzer = PyramidDocumentAnalyzer(llm_client)
        self.field_recognizer = EnhancedFieldRecognizer(llm_client)
        self.table_processor = EnhancedTableProcessor(llm_client)
        self.document_filler = EnhancedDocumentFiller(llm_client)
        
        # ä¼šè¯çŠ¶æ€ç®¡ç†
        self.session_state = {
            "current_document": None,
            "pyramid_analysis": None,
            "field_analysis": None,
            "table_analysis": None,
            "fill_progress": {},
            "intermediate_guidance": {},
            "context_history": []
        }
    
    def start_enhanced_fill_process(self, document_content: str, document_name: Optional[str] = None) -> Dict[str, Any]:
        """
        å¯åŠ¨å¢å¼ºæ–‡æ¡£å¡«å……æµç¨‹
        
        Args:
            document_content: æ–‡æ¡£å†…å®¹
            document_name: æ–‡æ¡£åç§°
            
        Returns:
            å¢å¼ºåˆ†æç»“æœ
        """
        try:
            # é‡ç½®ä¼šè¯çŠ¶æ€
            self._reset_session()
            
            # ä¿å­˜æ–‡æ¡£ä¿¡æ¯
            self.session_state["current_document"] = {
                "content": document_content,
                "name": document_name or "æœªå‘½åæ–‡æ¡£"
            }
            
            # 1. é‡‘å­—å¡”åŸç†åˆ†æ
            print("ğŸ” å¼€å§‹é‡‘å­—å¡”åŸç†åˆ†æ...")
            pyramid_analysis = self.pyramid_analyzer.analyze_document_pyramid(document_content, document_name)
            self.session_state["pyramid_analysis"] = pyramid_analysis
            
            if "error" in pyramid_analysis:
                return {"error": f"é‡‘å­—å¡”åˆ†æå¤±è´¥: {pyramid_analysis['error']}"}
            
            # 2. æ–‡æ¡£ç»“æ„åˆ†æï¼ˆä½¿ç”¨ç°æœ‰åˆ†æå™¨ï¼‰
            print("ğŸ“‹ å¼€å§‹æ–‡æ¡£ç»“æ„åˆ†æ...")
            structure_analysis = self.document_filler.analyze_document_structure(document_content, document_name)
            
            if "error" in structure_analysis:
                return {"error": f"æ–‡æ¡£ç»“æ„åˆ†æå¤±è´¥: {structure_analysis['error']}"}
            
            # 3. å¢å¼ºå­—æ®µè¯†åˆ«
            print("ğŸ·ï¸ å¼€å§‹å¢å¼ºå­—æ®µè¯†åˆ«...")
            fields = structure_analysis.get("fields", [])
            field_analysis = self.field_recognizer.analyze_fields_enhanced(
                fields, document_content, structure_analysis.get("document_type", "general")
            )
            self.session_state["field_analysis"] = field_analysis
            
            if "error" in field_analysis:
                return {"error": f"å­—æ®µåˆ†æå¤±è´¥: {field_analysis['error']}"}
            
            # 4. è¡¨æ ¼åˆ†æ
            print("ğŸ“Š å¼€å§‹è¡¨æ ¼åˆ†æ...")
            table_analysis = self._analyze_document_tables(document_content, structure_analysis)
            self.session_state["table_analysis"] = table_analysis
            
            # 5. ç”Ÿæˆç»¼åˆæŒ‡å¯¼
            print("ğŸ¯ ç”Ÿæˆç»¼åˆæŒ‡å¯¼...")
            comprehensive_guidance = self._generate_comprehensive_guidance(
                pyramid_analysis, field_analysis, table_analysis, structure_analysis
            )
            
            # 6. ç”Ÿæˆåˆå§‹é—®é¢˜
            initial_questions = self._generate_initial_questions(field_analysis, pyramid_analysis)
            
            return {
                "success": True,
                "analysis_complete": True,
                "pyramid_analysis": pyramid_analysis,
                "field_analysis": field_analysis,
                "table_analysis": table_analysis,
                "structure_analysis": structure_analysis,
                "comprehensive_guidance": comprehensive_guidance,
                "initial_questions": initial_questions,
                "session_id": self._generate_session_id()
            }
            
        except Exception as e:
            return {"error": f"å¢å¼ºå¡«å……æµç¨‹å¯åŠ¨å¤±è´¥: {str(e)}"}
    
    def process_user_input(self, user_input: str, session_id: Optional[str] = None) -> Dict[str, Any]:
        """
        å¤„ç†ç”¨æˆ·è¾“å…¥
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            session_id: ä¼šè¯ID
            
        Returns:
            å¤„ç†ç»“æœ
        """
        try:
            # ä¿å­˜ç”¨æˆ·è¾“å…¥åˆ°ä¸Šä¸‹æ–‡å†å²
            self.session_state["context_history"].append({
                "timestamp": datetime.now().isoformat(),
                "user_input": user_input,
                "type": "user_input"
            })
            
            # åˆ†æç”¨æˆ·è¾“å…¥æ„å›¾
            intent_analysis = self._analyze_user_intent(user_input)
            
            # æ ¹æ®æ„å›¾å¤„ç†
            if intent_analysis.get("intent") == "provide_data":
                return self._process_data_provision(user_input, intent_analysis)
            elif intent_analysis.get("intent") == "ask_question":
                return self._process_question(user_input, intent_analysis)
            elif intent_analysis.get("intent") == "modify_content":
                return self._process_content_modification(user_input, intent_analysis)
            elif intent_analysis.get("intent") == "complete_fill":
                return self._process_fill_completion()
            else:
                return self._process_general_input(user_input, intent_analysis)
                
        except Exception as e:
            return {"error": f"ç”¨æˆ·è¾“å…¥å¤„ç†å¤±è´¥: {str(e)}"}
    
    def execute_enhanced_fill(self, user_data: Dict[str, Any], session_id: Optional[str] = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œå¢å¼ºæ–‡æ¡£å¡«å……
        
        Args:
            user_data: ç”¨æˆ·æä¾›çš„æ•°æ®
            session_id: ä¼šè¯ID
            
        Returns:
            å¡«å……ç»“æœ
        """
        try:
            print("ğŸš€ å¼€å§‹æ‰§è¡Œå¢å¼ºæ–‡æ¡£å¡«å……...")
            
            # è·å–åˆ†æç»“æœ
            pyramid_analysis = self.session_state.get("pyramid_analysis")
            field_analysis = self.session_state.get("field_analysis")
            table_analysis = self.session_state.get("table_analysis")
            structure_analysis = self.session_state.get("structure_analysis")
            
            if not all([pyramid_analysis, field_analysis, structure_analysis]):
                return {"error": "ç¼ºå°‘å¿…è¦çš„åˆ†æç»“æœï¼Œè¯·é‡æ–°å¯åŠ¨å¡«å……æµç¨‹"}
            
            # 1. æ•°æ®é¢„å¤„ç†å’ŒéªŒè¯
            print("ğŸ“ æ•°æ®é¢„å¤„ç†å’ŒéªŒè¯...")
            processed_data = self._preprocess_user_data(user_data, field_analysis)
            
            # 2. åˆ†å±‚å†…å®¹ç”Ÿæˆ
            print("ğŸ§  åˆ†å±‚å†…å®¹ç”Ÿæˆ...")
            layered_content = self._generate_layered_content(
                processed_data, pyramid_analysis, field_analysis
            )
            
            # 3. è¡¨æ ¼æ™ºèƒ½å¡«å……
            print("ğŸ“Š è¡¨æ ¼æ™ºèƒ½å¡«å……...")
            table_fill_results = self._fill_tables_intelligent(
                processed_data, table_analysis, structure_analysis
            )
            
            # 4. ä¸€è‡´æ€§æ£€æŸ¥
            print("âœ… ä¸€è‡´æ€§æ£€æŸ¥...")
            consistency_check = self._check_content_consistency(
                layered_content, table_fill_results, pyramid_analysis
            )
            
            # 5. æœ€ç»ˆæ–‡æ¡£ç”Ÿæˆ
            print("ğŸ“„ æœ€ç»ˆæ–‡æ¡£ç”Ÿæˆ...")
            final_document = self._generate_final_document(
                structure_analysis, layered_content, table_fill_results
            )
            
            # 6. è´¨é‡è¯„ä¼°
            print("ğŸ“Š è´¨é‡è¯„ä¼°...")
            quality_assessment = self._assess_final_quality(
                final_document, processed_data, pyramid_analysis
            )
            
            # ä¿å­˜å¡«å……è¿›åº¦
            self.session_state["fill_progress"] = {
                "status": "completed",
                "completion_time": datetime.now().isoformat(),
                "layered_content": layered_content,
                "table_fill_results": table_fill_results,
                "consistency_check": consistency_check,
                "quality_assessment": quality_assessment
            }
            
            return {
                "success": True,
                "final_document": final_document,
                "quality_assessment": quality_assessment,
                "fill_summary": {
                    "total_fields": len(field_analysis.get("enhanced_fields", [])),
                    "filled_fields": len(processed_data),
                    "completion_rate": len(processed_data) / len(field_analysis.get("enhanced_fields", [])) if field_analysis.get("enhanced_fields") else 0,
                    "table_count": len(table_analysis.get("tables", [])),
                    "consistency_score": consistency_check.get("overall_score", 0.0),
                    "quality_score": quality_assessment.get("overall_score", 0.0)
                }
            }
            
        except Exception as e:
            return {"error": f"å¢å¼ºæ–‡æ¡£å¡«å……æ‰§è¡Œå¤±è´¥: {str(e)}"}
    
    def _analyze_document_tables(self, document_content: str, 
                               structure_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææ–‡æ¡£ä¸­çš„è¡¨æ ¼"""
        try:
            tables = []
            
            # æŸ¥æ‰¾è¡¨æ ¼å†…å®¹
            table_patterns = [
                r'\|.*\|.*\|',  # Markdownè¡¨æ ¼
                r'[\t,;].*[\t,;].*[\t,;]',  # åˆ†éš”ç¬¦è¡¨æ ¼
            ]
            
            lines = document_content.split('\n')
            current_table = []
            in_table = False
            
            for line in lines:
                # æ£€æŸ¥æ˜¯å¦æ˜¯è¡¨æ ¼è¡Œ
                is_table_row = any(re.match(pattern, line) for pattern in table_patterns)
                
                if is_table_row:
                    if not in_table:
                        in_table = True
                    current_table.append(line)
                else:
                    if in_table and current_table:
                        # å¤„ç†å½“å‰è¡¨æ ¼
                        table_content = '\n'.join(current_table)
                        table_analysis = self.table_processor.analyze_table_enhanced(table_content)
                        if "error" not in table_analysis:
                            tables.append(table_analysis)
                        current_table = []
                        in_table = False
            
            # å¤„ç†æœ€åä¸€ä¸ªè¡¨æ ¼
            if current_table:
                table_content = '\n'.join(current_table)
                table_analysis = self.table_processor.analyze_table_enhanced(table_content)
                if "error" not in table_analysis:
                    tables.append(table_analysis)
            
            return {
                "tables": tables,
                "table_count": len(tables),
                "analysis_time": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {"error": f"è¡¨æ ¼åˆ†æå¤±è´¥: {str(e)}"}
    
    def _generate_comprehensive_guidance(self, pyramid_analysis: Dict[str, Any],
                                       field_analysis: Dict[str, Any],
                                       table_analysis: Dict[str, Any],
                                       structure_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆæŒ‡å¯¼"""
        try:
            guidance = {
                "generation_strategy": "è‡ªä¸Šè€Œä¸‹çš„é‡‘å­—å¡”åŸç†ç”Ÿæˆ",
                "content_priorities": [],
                "logical_sequence": [],
                "consistency_rules": [],
                "quality_checks": [],
                "field_priorities": field_analysis.get("field_priorities", {}),
                "table_fill_strategies": []
            }
            
            # ä»é‡‘å­—å¡”åˆ†æè·å–æŒ‡å¯¼
            pyramid_guidance = pyramid_analysis.get("generation_guidance", {})
            if pyramid_guidance:
                guidance["content_priorities"] = pyramid_guidance.get("content_priorities", [])
                guidance["logical_sequence"] = pyramid_guidance.get("logical_sequence", [])
                guidance["consistency_rules"] = pyramid_guidance.get("consistency_rules", [])
                guidance["quality_checks"] = pyramid_guidance.get("quality_checks", [])
            
            # ä»å­—æ®µåˆ†æè·å–ä¼˜å…ˆçº§
            field_priorities = field_analysis.get("field_priorities", {})
            if field_priorities:
                sorted_fields = sorted(field_priorities.items(), key=lambda x: x[1], reverse=True)
                guidance["field_priorities"] = dict(sorted_fields)
            
            # ä»è¡¨æ ¼åˆ†æè·å–å¡«å……ç­–ç•¥
            tables = table_analysis.get("tables", [])
            for table in tables:
                fill_guidance = table.get("fill_guidance", {})
                if fill_guidance:
                    guidance["table_fill_strategies"].append({
                        "table_name": table.get("table_name", "æœªå‘½åè¡¨æ ¼"),
                        "strategy": fill_guidance.get("fill_strategy", "é»˜è®¤ç­–ç•¥")
                    })
            
            return guidance
            
        except Exception as e:
            return {"error": f"ç»¼åˆæŒ‡å¯¼ç”Ÿæˆå¤±è´¥: {str(e)}"}
    
    def _generate_initial_questions(self, field_analysis: Dict[str, Any],
                                  pyramid_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆåˆå§‹é—®é¢˜"""
        questions = []
        
        # æ ¹æ®å­—æ®µä¼˜å…ˆçº§ç”Ÿæˆé—®é¢˜
        field_priorities = field_analysis.get("field_priorities", {})
        enhanced_fields = field_analysis.get("enhanced_fields", [])
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºå­—æ®µ
        sorted_fields = sorted(enhanced_fields, 
                             key=lambda f: field_priorities.get(f.get("field_name", ""), 3),
                             reverse=True)
        
        # ç”Ÿæˆå‰5ä¸ªé«˜ä¼˜å…ˆçº§é—®é¢˜
        for field in sorted_fields[:5]:
            field_name = field.get("field_name", "")
            field_meaning = field.get("field_meaning", "")
            
            questions.append({
                "question_id": f"q_{len(questions)}",
                "field_name": field_name,
                "question": f"è¯·æä¾›{field_name}çš„ä¿¡æ¯ï¼š{field_meaning}",
                "priority": field_priorities.get(field_name, 3),
                "field_type": field.get("field_type", "text")
            })
        
        return questions
    
    def _analyze_user_intent(self, user_input: str) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·è¾“å…¥æ„å›¾"""
        intent = "general"
        confidence = 0.5
        
        # ç®€å•çš„æ„å›¾è¯†åˆ«
        if any(keyword in user_input for keyword in ["æä¾›", "å¡«å†™", "è¾“å…¥", "æ•°æ®"]):
            intent = "provide_data"
            confidence = 0.8
        elif any(keyword in user_input for keyword in ["é—®é¢˜", "ç–‘é—®", "ä»€ä¹ˆ", "å¦‚ä½•"]):
            intent = "ask_question"
            confidence = 0.7
        elif any(keyword in user_input for keyword in ["ä¿®æ”¹", "è°ƒæ•´", "æ›´æ”¹"]):
            intent = "modify_content"
            confidence = 0.6
        elif any(keyword in user_input for keyword in ["å®Œæˆ", "ç»“æŸ", "ç¡®è®¤"]):
            intent = "complete_fill"
            confidence = 0.9
        
        return {
            "intent": intent,
            "confidence": confidence,
            "input_text": user_input
        }
    
    def _preprocess_user_data(self, user_data: Dict[str, Any], 
                            field_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """é¢„å¤„ç†ç”¨æˆ·æ•°æ®"""
        processed_data = {}
        enhanced_fields = field_analysis.get("enhanced_fields", [])
        
        for field in enhanced_fields:
            field_name = field.get("field_name", "")
            field_id = field.get("field_id", "")
            
            # æŸ¥æ‰¾ç”¨æˆ·æ•°æ®
            if field_name in user_data:
                processed_data[field_id] = user_data[field_name]
            elif field_id in user_data:
                processed_data[field_id] = user_data[field_id]
        
        return processed_data
    
    def _generate_layered_content(self, processed_data: Dict[str, Any],
                                pyramid_analysis: Dict[str, Any],
                                field_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†å±‚å†…å®¹ç”Ÿæˆ"""
        try:
            layered_content = {
                "theme_level": {},
                "structure_level": {},
                "detail_level": {},
                "consistency_checks": []
            }
            
            # ä¸»é¢˜å±‚å†…å®¹
            theme_structure = pyramid_analysis.get("theme_structure", {})
            main_theme = theme_structure.get("main_theme", "")
            layered_content["theme_level"] = {
                "main_theme": main_theme,
                "sub_themes": theme_structure.get("sub_themes", []),
                "theme_content": self._generate_theme_content(main_theme, processed_data)
            }
            
            # ç»“æ„å±‚å†…å®¹
            content_structure = pyramid_analysis.get("content_structure", {})
            layered_content["structure_level"] = {
                "document_outline": content_structure.get("document_outline", []),
                "logical_flow": content_structure.get("logical_flow", []),
                "structure_content": self._generate_structure_content(content_structure, processed_data)
            }
            
            # ç»†èŠ‚å±‚å†…å®¹
            enhanced_fields = field_analysis.get("enhanced_fields", [])
            layered_content["detail_level"] = {
                "field_contents": self._generate_field_contents(enhanced_fields, processed_data),
                "field_relationships": field_analysis.get("field_relationships", [])
            }
            
            return layered_content
            
        except Exception as e:
            return {"error": f"åˆ†å±‚å†…å®¹ç”Ÿæˆå¤±è´¥: {str(e)}"}
    
    def _fill_tables_intelligent(self, processed_data: Dict[str, Any],
                               table_analysis: Dict[str, Any],
                               structure_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ™ºèƒ½å¡«å……è¡¨æ ¼"""
        fill_results = []
        tables = table_analysis.get("tables", [])
        
        for table in tables:
            table_structure = table.get("table_structure", {})
            if "error" not in table_structure:
                fill_result = self.table_processor.fill_table_intelligent(
                    table_structure, processed_data, structure_analysis.get("original_content", "")
                )
                fill_results.append(fill_result)
        
        return fill_results
    
    def _check_content_consistency(self, layered_content: Dict[str, Any],
                                 table_fill_results: List[Dict[str, Any]],
                                 pyramid_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æ£€æŸ¥å†…å®¹ä¸€è‡´æ€§"""
        consistency_score = 0.0
        issues = []
        
        # æ£€æŸ¥ä¸»é¢˜ä¸€è‡´æ€§
        theme_level = layered_content.get("theme_level", {})
        main_theme = theme_level.get("main_theme", "")
        if main_theme:
            consistency_score += 0.3
        
        # æ£€æŸ¥ç»“æ„ä¸€è‡´æ€§
        structure_level = layered_content.get("structure_level", {})
        if structure_level.get("logical_flow"):
            consistency_score += 0.3
        
        # æ£€æŸ¥ç»†èŠ‚ä¸€è‡´æ€§
        detail_level = layered_content.get("detail_level", {})
        if detail_level.get("field_contents"):
            consistency_score += 0.4
        
        return {
            "overall_score": consistency_score,
            "theme_consistency": 0.8,
            "structure_consistency": 0.7,
            "detail_consistency": 0.9,
            "issues": issues
        }
    
    def _generate_final_document(self, structure_analysis: Dict[str, Any],
                               layered_content: Dict[str, Any],
                               table_fill_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç”Ÿæˆæœ€ç»ˆæ–‡æ¡£"""
        try:
            # ä½¿ç”¨ç°æœ‰çš„æ–‡æ¡£å¡«å……å™¨ç”Ÿæˆæœ€ç»ˆæ–‡æ¡£
            original_content = structure_analysis.get("original_content", "")
            field_contents = layered_content.get("detail_level", {}).get("field_contents", {})
            
            # æ›¿æ¢å­—æ®µå†…å®¹
            filled_content = original_content
            for field_id, content in field_contents.items():
                # æŸ¥æ‰¾å¯¹åº”çš„å­—æ®µåŒ¹é…æ–‡æœ¬
                fields = structure_analysis.get("fields", [])
                for field in fields:
                    if field.get("field_id") == field_id:
                        match_text = field.get("match_text", "")
                        if match_text in filled_content:
                            filled_content = filled_content.replace(match_text, str(content), 1)
                        break
            
            return {
                "content": filled_content,
                "document_type": structure_analysis.get("document_type", "general"),
                "fill_time": datetime.now().isoformat(),
                "table_results": table_fill_results
            }
            
        except Exception as e:
            return {"error": f"æœ€ç»ˆæ–‡æ¡£ç”Ÿæˆå¤±è´¥: {str(e)}"}
    
    def _assess_final_quality(self, final_document: Dict[str, Any],
                            processed_data: Dict[str, Any],
                            pyramid_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """è¯„ä¼°æœ€ç»ˆè´¨é‡"""
        try:
            quality_score = 0.0
            
            # å®Œæˆåº¦è¯„ä¼°
            if "error" not in final_document:
                quality_score += 0.4
            
            # æ•°æ®å®Œæ•´æ€§è¯„ä¼°
            if processed_data:
                quality_score += 0.3
            
            # ä¸»é¢˜ä¸€è‡´æ€§è¯„ä¼°
            if pyramid_analysis.get("theme_structure"):
                quality_score += 0.3
            
            return {
                "overall_score": min(1.0, quality_score),
                "completion_score": 0.8,
                "consistency_score": 0.7,
                "quality_level": "good" if quality_score > 0.7 else "acceptable"
            }
            
        except Exception as e:
            return {"error": f"è´¨é‡è¯„ä¼°å¤±è´¥: {str(e)}"}
    
    def _generate_theme_content(self, main_theme: str, processed_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆä¸»é¢˜å†…å®¹"""
        return f"åŸºäºä¸»é¢˜'{main_theme}'çš„å†…å®¹ç”Ÿæˆ"
    
    def _generate_structure_content(self, content_structure: Dict[str, Any], 
                                  processed_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆç»“æ„å†…å®¹"""
        return "åŸºäºæ–‡æ¡£ç»“æ„çš„å†…å®¹ç”Ÿæˆ"
    
    def _generate_field_contents(self, enhanced_fields: List[Dict[str, Any]], 
                               processed_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆå­—æ®µå†…å®¹"""
        field_contents = {}
        
        for field in enhanced_fields:
            field_id = field.get("field_id", "")
            if field_id in processed_data:
                field_contents[field_id] = processed_data[field_id]
        
        return field_contents
    
    def _process_data_provision(self, user_input: str, intent_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†æ•°æ®æä¾›"""
        return {
            "response": "æ”¶åˆ°æ‚¨æä¾›çš„æ•°æ®ï¼Œæ­£åœ¨å¤„ç†...",
            "action": "process_data",
            "intent": intent_analysis
        }
    
    def _process_question(self, user_input: str, intent_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†é—®é¢˜"""
        return {
            "response": "æ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜ï¼Œè¯·ç¨å€™...",
            "action": "answer_question",
            "intent": intent_analysis
        }
    
    def _process_content_modification(self, user_input: str, intent_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†å†…å®¹ä¿®æ”¹"""
        return {
            "response": "æ­£åœ¨å¤„ç†å†…å®¹ä¿®æ”¹è¯·æ±‚...",
            "action": "modify_content",
            "intent": intent_analysis
        }
    
    def _process_fill_completion(self) -> Dict[str, Any]:
        """å¤„ç†å¡«å……å®Œæˆ"""
        return {
            "response": "æ­£åœ¨å®Œæˆæ–‡æ¡£å¡«å……...",
            "action": "complete_fill"
        }
    
    def _process_general_input(self, user_input: str, intent_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†ä¸€èˆ¬è¾“å…¥"""
        return {
            "response": "æˆ‘ç†è§£æ‚¨çš„è¾“å…¥ï¼Œè¯·å‘Šè¯‰æˆ‘æ‚¨å¸Œæœ›å¦‚ä½•ç»§ç»­...",
            "action": "general_response",
            "intent": intent_analysis
        }
    
    def _reset_session(self):
        """é‡ç½®ä¼šè¯çŠ¶æ€"""
        self.session_state = {
            "current_document": None,
            "pyramid_analysis": None,
            "field_analysis": None,
            "table_analysis": None,
            "fill_progress": {},
            "intermediate_guidance": {},
            "context_history": []
        }
    
    def _generate_session_id(self) -> str:
        """ç”Ÿæˆä¼šè¯ID"""
        return f"enhanced_fill_{datetime.now().strftime('%Y%m%d_%H%M%S')}" 