"""
å¢å¼ºçš„æ–‡æ¡£å¡«å……å™¨
é›†æˆä¸“åˆ©åˆ†æã€å›¾ç‰‡å¤„ç†ã€AIæ™ºèƒ½å¡«å†™ç­‰åŠŸèƒ½
"""

import re
import json
import os
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from .patent_document_analyzer import PatentDocumentAnalyzer
from .intelligent_image_processor import IntelligentImageProcessor
from .complex_document_filler import ComplexDocumentFiller

class EnhancedDocumentFiller:
    """å¢å¼ºçš„æ–‡æ¡£å¡«å……å™¨"""
    
    def __init__(self, llm_client=None):
        self.llm_client = llm_client
        self.tool_name = "å¢å¼ºçš„æ–‡æ¡£å¡«å……å™¨"
        self.description = "é›†æˆä¸“åˆ©åˆ†æã€å›¾ç‰‡å¤„ç†ã€AIæ™ºèƒ½å¡«å†™çš„å®Œæ•´æ–‡æ¡£å¤„ç†ç³»ç»Ÿ"
        
        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.patent_analyzer = PatentDocumentAnalyzer(llm_client)
        self.image_processor = IntelligentImageProcessor()
        self.document_filler = ComplexDocumentFiller(llm_client)
        
        # æ–‡æ¡£ç±»å‹è¯†åˆ«å™¨
        self.document_type_patterns = {
            "patent": [
                r"ä¸“åˆ©.*ç”³è¯·.*ä¹¦",
                r"å‘æ˜.*ç”³è¯·.*ä¹¦",
                r"å®ç”¨æ–°å‹.*ç”³è¯·.*ä¹¦",
                r"å¤–è§‚è®¾è®¡.*ç”³è¯·.*ä¹¦"
            ],
            "project": [
                r"é¡¹ç›®.*ç”³è¯·.*è¡¨",
                r"è¯¾é¢˜.*ç”³è¯·.*ä¹¦",
                r"åŸºé‡‘.*ç”³è¯·.*ä¹¦"
            ],
            "contract": [
                r"åˆåŒ.*ä¹¦",
                r"åè®®.*ä¹¦",
                r"æ„å‘.*ä¹¦"
            ],
            "report": [
                r"æŠ¥å‘Š.*ä¹¦",
                r"æ€»ç»“.*æŠ¥å‘Š",
                r"åˆ†æ.*æŠ¥å‘Š"
            ]
        }
    
    def analyze_document_structure(self, document_content: str, document_name: str = None) -> Dict[str, Any]:
        """
        åˆ†ææ–‡æ¡£ç»“æ„ï¼ˆå¢å¼ºç‰ˆï¼‰
        
        Args:
            document_content: æ–‡æ¡£å†…å®¹
            document_name: æ–‡æ¡£åç§°
            
        Returns:
            å¢å¼ºçš„åˆ†æç»“æœ
        """
        try:
            # 1. è¯†åˆ«æ–‡æ¡£ç±»å‹
            document_type = self._identify_document_type(document_content, document_name)
            
            # 2. æ ¹æ®æ–‡æ¡£ç±»å‹é€‰æ‹©åˆ†æå™¨
            if document_type == "patent":
                analysis_result = self.patent_analyzer.analyze_patent_document(document_content, document_name)
            else:
                # ä½¿ç”¨é€šç”¨æ–‡æ¡£åˆ†æå™¨
                analysis_result = self.document_filler.analyze_document_structure(document_content, document_name)
            
            # 3. å¢å¼ºåˆ†æç»“æœ
            enhanced_result = self._enhance_analysis_result(analysis_result, document_type, document_content)
            
            return enhanced_result
            
        except Exception as e:
            return {"error": f"æ–‡æ¡£ç»“æ„åˆ†æå¤±è´¥: {str(e)}"}
    
    def _identify_document_type(self, content: str, document_name: str = None) -> str:
        """è¯†åˆ«æ–‡æ¡£ç±»å‹"""
        # æ£€æŸ¥æ–‡æ¡£åç§°
        if document_name:
            for doc_type, patterns in self.document_type_patterns.items():
                for pattern in patterns:
                    if re.search(pattern, document_name, re.IGNORECASE):
                        return doc_type
        
        # æ£€æŸ¥æ–‡æ¡£å†…å®¹
        for doc_type, patterns in self.document_type_patterns.items():
            for pattern in patterns:
                if re.search(pattern, content, re.IGNORECASE):
                    return doc_type
        
        return "general"
    
    def _enhance_analysis_result(self, analysis_result: Dict[str, Any], 
                               document_type: str, content: str) -> Dict[str, Any]:
        """å¢å¼ºåˆ†æç»“æœ"""
        if "error" in analysis_result:
            return analysis_result
        
        # æ·»åŠ æ–‡æ¡£ç±»å‹ä¿¡æ¯
        analysis_result["document_type"] = document_type
        
        # æ·»åŠ AIå¡«å†™å»ºè®®
        if document_type == "patent":
            ai_suggestions = self.patent_analyzer.generate_ai_fill_suggestions(analysis_result)
            analysis_result["ai_suggestions"] = ai_suggestions
        
        # æ·»åŠ å›¾ç‰‡å¤„ç†ä¿¡æ¯
        image_positions = analysis_result.get("image_positions", [])
        if image_positions:
            analysis_result["image_processing_required"] = True
            analysis_result["image_count"] = len(image_positions)
        else:
            analysis_result["image_processing_required"] = False
            analysis_result["image_count"] = 0
        
        # æ·»åŠ æ™ºèƒ½å¡«å†™ç­–ç•¥
        analysis_result["fill_strategy"] = self._generate_fill_strategy(analysis_result, document_type)
        
        return analysis_result
    
    def _generate_fill_strategy(self, analysis_result: Dict[str, Any], document_type: str) -> Dict[str, Any]:
        """ç”Ÿæˆå¡«å†™ç­–ç•¥"""
        strategy = {
            "document_type": document_type,
            "auto_fill_enabled": True,
            "ai_assisted_fill": True,
            "image_integration": analysis_result.get("image_processing_required", False),
            "validation_rules": [],
            "consistency_checks": []
        }
        
        if document_type == "patent":
            strategy["validation_rules"] = [
                "å‘æ˜åç§°ä¸èƒ½è¶…è¿‡100å­—ç¬¦",
                "æ‘˜è¦é•¿åº¦åœ¨100-500å­—ç¬¦ä¹‹é—´",
                "æŠ€æœ¯é¢†åŸŸå¿…é¡»ä»é¢„å®šä¹‰é€‰é¡¹ä¸­é€‰æ‹©",
                "ç”³è¯·æ—¥æœŸæ ¼å¼ä¸ºYYYY-MM-DD"
            ]
            strategy["consistency_checks"] = [
                "å‘æ˜åç§°ä¸æ‘˜è¦å†…å®¹ä¸€è‡´æ€§",
                "æŠ€æœ¯é¢†åŸŸä¸å‘æ˜å†…å®¹åŒ¹é…",
                "é™„å›¾è¯´æ˜ä¸æƒåˆ©è¦æ±‚ä¸€è‡´"
            ]
        
        return strategy
    
    def intelligent_fill_document(self, analysis_result: Dict[str, Any], 
                                user_data: Dict[str, Any] = None,
                                image_files: List[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        æ™ºèƒ½å¡«å……æ–‡æ¡£ï¼ˆå¢å¼ºç‰ˆï¼‰
        
        Args:
            analysis_result: æ–‡æ¡£åˆ†æç»“æœ
            user_data: ç”¨æˆ·æä¾›çš„æ•°æ®
            image_files: å›¾ç‰‡æ–‡ä»¶åˆ—è¡¨
            
        Returns:
            å¡«å……ç»“æœ
        """
        try:
            document_type = analysis_result.get("document_type", "general")
            document_content = analysis_result.get("original_content", "")
            
            # 1. å¤„ç†å›¾ç‰‡æ–‡ä»¶
            if image_files and analysis_result.get("image_processing_required", False):
                image_result = self._process_document_images(image_files, analysis_result)
                if "error" not in image_result:
                    document_content = image_result["updated_document"]
            
            # 2. ç”ŸæˆAIå¡«å†™å†…å®¹
            ai_filled_data = self._generate_ai_filled_content(analysis_result, user_data)
            
            # 3. åˆå¹¶ç”¨æˆ·æ•°æ®å’ŒAIæ•°æ®
            combined_data = self._merge_user_and_ai_data(user_data, ai_filled_data)
            
            # 4. å¡«å……æ–‡æ¡£
            if document_type == "patent":
                fill_result = self._fill_patent_document(analysis_result, combined_data, document_content)
            else:
                fill_result = self.document_filler.fill_document(analysis_result, combined_data)
            
            # 5. å¢å¼ºç»“æœ
            enhanced_result = self._enhance_fill_result(fill_result, analysis_result, combined_data)
            
            return enhanced_result
            
        except Exception as e:
            return {"error": f"æ™ºèƒ½æ–‡æ¡£å¡«å……å¤±è´¥: {str(e)}"}
    
    def generate_fill_preview(self, analysis_result: Dict[str, Any], 
                            user_data: Dict[str, Any] = None,
                            image_files: List[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        ç”Ÿæˆå¡«å……é¢„è§ˆ
        
        Args:
            analysis_result: æ–‡æ¡£åˆ†æç»“æœ
            user_data: ç”¨æˆ·æä¾›çš„æ•°æ®
            image_files: å›¾ç‰‡æ–‡ä»¶åˆ—è¡¨
            
        Returns:
            é¢„è§ˆç»“æœ
        """
        try:
            # 1. éªŒè¯è¾“å…¥å‚æ•°
            if not analysis_result or "error" in analysis_result:
                return {
                    "success": False,
                    "error": "æ–‡æ¡£åˆ†æç»“æœæ— æ•ˆ"
                }
            
            document_type = analysis_result.get("document_type", "general")
            document_content = analysis_result.get("original_content", "")
            
            # 2. ç”ŸæˆAIå¡«å†™å†…å®¹ï¼ˆä»…é¢„è§ˆï¼Œä¸ä¿å­˜ï¼‰
            ai_filled_data = self._generate_ai_filled_content(analysis_result, user_data)
            
            # 3. åˆå¹¶ç”¨æˆ·æ•°æ®å’ŒAIæ•°æ®
            combined_data = self._merge_user_and_ai_data(user_data, ai_filled_data)
            
            # 4. ç”Ÿæˆé¢„è§ˆå†…å®¹
            preview_content = self._generate_preview_content(analysis_result, combined_data, document_content)
            
            # 5. ç”Ÿæˆé¢„è§ˆæŠ¥å‘Š
            preview_report = self._generate_preview_report(analysis_result, combined_data, ai_filled_data)
            
            # 6. ç”Ÿæˆå­—æ®µæ˜ å°„ä¿¡æ¯
            field_mapping = self._generate_field_mapping(analysis_result, combined_data)
            
            return {
                "success": True,
                "preview_id": f"preview_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "document_type": document_type,
                "preview_content": preview_content,
                "preview_report": preview_report,
                "field_mapping": field_mapping,
                "data_summary": {
                    "total_fields": len(analysis_result.get("fields", [])),
                    "filled_fields": len([f for f in combined_data.values() if f]),
                    "ai_generated_fields": len([f for f in ai_filled_data.values() if f]),
                    "user_provided_fields": len([f for f in (user_data or {}).values() if f]),
                    "unfilled_fields": len([f for f in analysis_result.get("fields", []) if not combined_data.get(f.get("name"))])
                },
                "quality_metrics": self._calculate_preview_quality(combined_data, analysis_result),
                "recommendations": self._generate_preview_recommendations(combined_data, analysis_result),
                "generated_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"ç”Ÿæˆå¡«å……é¢„è§ˆå¤±è´¥: {str(e)}"
            }
    
    def _generate_preview_content(self, analysis_result: Dict[str, Any], 
                                combined_data: Dict[str, Any], 
                                original_content: str) -> str:
        """ç”Ÿæˆé¢„è§ˆå†…å®¹"""
        try:
            # åˆ›å»ºé¢„è§ˆå†…å®¹
            preview_lines = []
            preview_lines.append("# æ–‡æ¡£å¡«å……é¢„è§ˆ")
            preview_lines.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            preview_lines.append(f"æ–‡æ¡£ç±»å‹: {analysis_result.get('document_type', 'general')}")
            preview_lines.append("")
            
            # æ·»åŠ å­—æ®µå¡«å……ä¿¡æ¯
            fields = analysis_result.get("fields", [])
            for field in fields:
                field_name = field.get("name", "")
                field_value = combined_data.get(field_name, "")
                field_type = field.get("type", "text")
                
                preview_lines.append(f"## {field_name}")
                preview_lines.append(f"ç±»å‹: {field_type}")
                preview_lines.append(f"å€¼: {field_value}")
                preview_lines.append("")
            
            # æ·»åŠ åŸå§‹å†…å®¹ï¼ˆå¦‚æœè¾ƒçŸ­ï¼‰
            if len(original_content) < 1000:
                preview_lines.append("## åŸå§‹å†…å®¹")
                preview_lines.append(original_content)
            
            return "\n".join(preview_lines)
            
        except Exception as e:
            return f"é¢„è§ˆå†…å®¹ç”Ÿæˆå¤±è´¥: {str(e)}"
    
    def _generate_preview_report(self, analysis_result: Dict[str, Any], 
                               combined_data: Dict[str, Any], 
                               ai_filled_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆé¢„è§ˆæŠ¥å‘Š"""
        try:
            fields = analysis_result.get("fields", [])
            
            # ç»Ÿè®¡ä¿¡æ¯
            total_fields = len(fields)
            filled_fields = len([f for f in combined_data.values() if f])
            ai_generated = len([f for f in ai_filled_data.values() if f])
            empty_fields = total_fields - filled_fields
            
            # å­—æ®µçŠ¶æ€
            field_status = []
            for field in fields:
                field_name = field.get("name", "")
                field_value = combined_data.get(field_name, "")
                is_ai_generated = field_name in ai_filled_data and ai_filled_data[field_name]
                
                field_status.append({
                    "name": field_name,
                    "type": field.get("type", "text"),
                    "filled": bool(field_value),
                    "ai_generated": is_ai_generated,
                    "value_preview": field_value[:100] + "..." if len(field_value) > 100 else field_value
                })
            
            return {
                "summary": {
                    "total_fields": total_fields,
                    "filled_fields": filled_fields,
                    "empty_fields": empty_fields,
                    "ai_generated_fields": ai_generated,
                    "fill_rate": filled_fields / total_fields if total_fields > 0 else 0
                },
                "field_status": field_status,
                "quality_assessment": self._assess_preview_quality(combined_data, analysis_result)
            }
            
        except Exception as e:
            return {"error": f"é¢„è§ˆæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}"}
    
    def _generate_field_mapping(self, analysis_result: Dict[str, Any], 
                              combined_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆå­—æ®µæ˜ å°„ä¿¡æ¯"""
        try:
            fields = analysis_result.get("fields", [])
            mapping = {
                "exact_matches": [],
                "partial_matches": [],
                "unmatched_fields": [],
                "confidence_scores": {}
            }
            
            for field in fields:
                field_name = field.get("name", "")
                field_value = combined_data.get(field_name, "")
                
                if field_value:
                    # è®¡ç®—åŒ¹é…åº¦
                    confidence = self._calculate_field_confidence(field, field_value)
                    mapping["confidence_scores"][field_name] = confidence
                    
                    if confidence >= 0.8:
                        mapping["exact_matches"].append(field_name)
                    elif confidence >= 0.5:
                        mapping["partial_matches"].append(field_name)
                    else:
                        mapping["unmatched_fields"].append(field_name)
                else:
                    mapping["unmatched_fields"].append(field_name)
                    mapping["confidence_scores"][field_name] = 0.0
            
            return mapping
            
        except Exception as e:
            return {"error": f"å­—æ®µæ˜ å°„ç”Ÿæˆå¤±è´¥: {str(e)}"}
    
    def _calculate_field_confidence(self, field: Dict[str, Any], value: str) -> float:
        """è®¡ç®—å­—æ®µåŒ¹é…ç½®ä¿¡åº¦"""
        try:
            confidence = 0.5  # åŸºç¡€ç½®ä¿¡åº¦
            
            # æ ¹æ®å­—æ®µç±»å‹è°ƒæ•´ç½®ä¿¡åº¦
            field_type = field.get("type", "text")
            if field_type == "date" and self._validate_date_format(value):
                confidence += 0.3
            elif field_type == "email" and self._validate_email_format(value):
                confidence += 0.3
            elif field_type == "phone" and self._validate_phone_format(value):
                confidence += 0.3
            
            # æ ¹æ®å†…å®¹é•¿åº¦è°ƒæ•´ç½®ä¿¡åº¦
            if len(value) >= field.get("min_length", 0):
                confidence += 0.1
            
            if len(value) <= field.get("max_length", 1000):
                confidence += 0.1
            
            return min(1.0, confidence)
            
        except Exception:
            return 0.0
    
    def _calculate_preview_quality(self, combined_data: Dict[str, Any], 
                                 analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """è®¡ç®—é¢„è§ˆè´¨é‡æŒ‡æ ‡"""
        try:
            total_fields = len(analysis_result.get("fields", []))
            filled_fields = len([v for v in combined_data.values() if v])
            
            quality_metrics = {
                "completeness": filled_fields / total_fields if total_fields > 0 else 0,
                "average_length": sum(len(str(v)) for v in combined_data.values() if v) / max(filled_fields, 1),
                "validation_score": self._calculate_validation_score(combined_data, analysis_result),
                "consistency_score": self._calculate_consistency_score(combined_data, analysis_result)
            }
            
            return quality_metrics
            
        except Exception as e:
            return {"error": f"è´¨é‡è®¡ç®—å¤±è´¥: {str(e)}"}
    
    def _calculate_validation_score(self, combined_data: Dict[str, Any], 
                                  analysis_result: Dict[str, Any]) -> float:
        """è®¡ç®—éªŒè¯åˆ†æ•°"""
        try:
            fields = analysis_result.get("fields", [])
            valid_fields = 0
            
            for field in fields:
                field_name = field.get("name", "")
                field_value = combined_data.get(field_name, "")
                
                if field_value and self._validate_field_type(field.get("type", "text"), field_value):
                    valid_fields += 1
            
            return valid_fields / len(fields) if fields else 0.0
            
        except Exception:
            return 0.0
    
    def _calculate_consistency_score(self, combined_data: Dict[str, Any], 
                                   analysis_result: Dict[str, Any]) -> float:
        """è®¡ç®—ä¸€è‡´æ€§åˆ†æ•°"""
        try:
            # ç®€åŒ–çš„ç›¸å…³æ€§æ£€æŸ¥
            score = 0.5  # åŸºç¡€åˆ†æ•°
            
            # æ£€æŸ¥æ—¥æœŸæ ¼å¼ä¸€è‡´æ€§
            date_fields = [f for f in analysis_result.get("fields", []) if f.get("type") == "date"]
            if len(date_fields) > 1:
                date_values = [combined_data.get(f.get("name", "")) for f in date_fields]
                if all(self._validate_date_format(v) for v in date_values if v):
                    score += 0.2
            
            # æ£€æŸ¥å¿…å¡«å­—æ®µå®Œæ•´æ€§
            required_fields = [f for f in analysis_result.get("fields", []) if f.get("required", False)]
            filled_required = sum(1 for f in required_fields if combined_data.get(f.get("name", "")))
            if required_fields:
                score += 0.3 * (filled_required / len(required_fields))
            
            return min(1.0, score)
            
        except Exception:
            return 0.0
    
    def _assess_preview_quality(self, combined_data: Dict[str, Any], 
                              analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """è¯„ä¼°é¢„è§ˆè´¨é‡"""
        try:
            quality_metrics = self._calculate_preview_quality(combined_data, analysis_result)
            
            # è´¨é‡ç­‰çº§è¯„ä¼°
            completeness = quality_metrics.get("completeness", 0)
            validation_score = quality_metrics.get("validation_score", 0)
            consistency_score = quality_metrics.get("consistency_score", 0)
            
            overall_score = (completeness + validation_score + consistency_score) / 3
            
            if overall_score >= 0.8:
                quality_level = "excellent"
                assessment = "é¢„è§ˆè´¨é‡ä¼˜ç§€ï¼Œå¯ä»¥ç«‹å³åº”ç”¨"
            elif overall_score >= 0.6:
                quality_level = "good"
                assessment = "é¢„è§ˆè´¨é‡è‰¯å¥½ï¼Œå»ºè®®å°å¹…è°ƒæ•´"
            elif overall_score >= 0.4:
                quality_level = "fair"
                assessment = "é¢„è§ˆè´¨é‡ä¸€èˆ¬ï¼Œéœ€è¦ä¸­ç­‰ç¨‹åº¦ä¿®æ”¹"
            else:
                quality_level = "poor"
                assessment = "é¢„è§ˆè´¨é‡è¾ƒå·®ï¼Œéœ€è¦å¤§é‡ä¿®æ”¹"
            
            return {
                "overall_score": overall_score,
                "quality_level": quality_level,
                "assessment": assessment,
                "metrics": quality_metrics,
                "improvement_suggestions": self._generate_quality_suggestions(quality_metrics)
            }
            
        except Exception as e:
            return {"error": f"è´¨é‡è¯„ä¼°å¤±è´¥: {str(e)}"}
    
    def _generate_quality_suggestions(self, quality_metrics: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆè´¨é‡æ”¹è¿›å»ºè®®"""
        suggestions = []
        
        completeness = quality_metrics.get("completeness", 0)
        if completeness < 0.8:
            suggestions.append("å»ºè®®å¡«å†™æ›´å¤šå­—æ®µä»¥æé«˜å®Œæ•´æ€§")
        
        validation_score = quality_metrics.get("validation_score", 0)
        if validation_score < 0.9:
            suggestions.append("å»ºè®®æ£€æŸ¥å­—æ®µæ ¼å¼å’ŒéªŒè¯è§„åˆ™")
        
        consistency_score = quality_metrics.get("consistency_score", 0)
        if consistency_score < 0.8:
            suggestions.append("å»ºè®®æ£€æŸ¥å­—æ®µé—´çš„ä¸€è‡´æ€§å’Œç›¸å…³æ€§")
        
        if not suggestions:
            suggestions.append("é¢„è§ˆè´¨é‡è‰¯å¥½ï¼Œå¯ä»¥ç»§ç»­")
        
        return suggestions
    
    def _generate_preview_recommendations(self, combined_data: Dict[str, Any], 
                                        analysis_result: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆé¢„è§ˆå»ºè®®"""
        recommendations = []
        
        # æ£€æŸ¥å¿…å¡«å­—æ®µ
        required_fields = [f for f in analysis_result.get("fields", []) if f.get("required", False)]
        missing_required = [f.get("name") for f in required_fields if not combined_data.get(f.get("name", ""))]
        
        if missing_required:
            recommendations.append(f"éœ€è¦å¡«å†™å¿…å¡«å­—æ®µ: {', '.join(missing_required)}")
        
        # æ£€æŸ¥å­—æ®µé•¿åº¦
        for field in analysis_result.get("fields", []):
            field_name = field.get("name", "")
            field_value = combined_data.get(field_name, "")
            
            if field_value:
                min_length = field.get("min_length", 0)
                max_length = field.get("max_length", 1000)
                
                if len(field_value) < min_length:
                    recommendations.append(f"å­—æ®µ '{field_name}' å†…å®¹è¿‡çŸ­ï¼Œå»ºè®®è¡¥å……")
                elif len(field_value) > max_length:
                    recommendations.append(f"å­—æ®µ '{field_name}' å†…å®¹è¿‡é•¿ï¼Œå»ºè®®ç²¾ç®€")
        
        # æ£€æŸ¥æ–‡æ¡£ç±»å‹ç‰¹å®šå»ºè®®
        document_type = analysis_result.get("document_type", "general")
        if document_type == "patent":
            recommendations.append("ä¸“åˆ©æ–‡æ¡£å»ºè®®æ£€æŸ¥æŠ€æœ¯æœ¯è¯­çš„å‡†ç¡®æ€§")
        elif document_type == "contract":
            recommendations.append("åˆåŒæ–‡æ¡£å»ºè®®æ£€æŸ¥æ³•å¾‹æ¡æ¬¾çš„å®Œæ•´æ€§")
        
        if not recommendations:
            recommendations.append("é¢„è§ˆå†…å®¹ç¬¦åˆè¦æ±‚ï¼Œå¯ä»¥åº”ç”¨")
        
        return recommendations
    
    def _process_document_images(self, image_files: List[Dict[str, Any]], 
                               analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†æ–‡æ¡£å›¾ç‰‡"""
        try:
            image_positions = analysis_result.get("image_positions", [])
            document_content = analysis_result.get("original_content", "")
            
            # æ‰¹é‡å¤„ç†å›¾ç‰‡
            batch_result = self.image_processor.batch_process_images(image_files, document_content)
            
            if "error" in batch_result:
                return batch_result
            
            return {
                "success": True,
                "processed_images": batch_result["processed_images"],
                "updated_document": batch_result["updated_document"],
                "image_count": len(batch_result["processed_images"])
            }
            
        except Exception as e:
            return {"error": f"å›¾ç‰‡å¤„ç†å¤±è´¥: {str(e)}"}
    
    def _generate_ai_filled_content(self, analysis_result: Dict[str, Any], 
                                  user_data: Dict[str, Any] = None) -> Dict[str, Any]:
        """ç”ŸæˆAIå¡«å†™å†…å®¹"""
        try:
            ai_filled_data = {}
            fields = analysis_result.get("fields", [])
            total_fields = len(fields)
            completed_fields = 0
            
            # è·å–æ–‡æ¡£ç±»å‹å’Œç”¨æˆ·è§’è‰²ä¿¡æ¯
            document_type = analysis_result.get("document_type", "general")
            user_role = self._identify_user_role(analysis_result, user_data)
            
            print(f"ğŸ¤– å¼€å§‹AIå†…å®¹ç”Ÿæˆï¼Œå…±{total_fields}ä¸ªå­—æ®µéœ€è¦å¤„ç†...")
            print(f"ğŸ“ æ–‡æ¡£ç±»å‹: {document_type}, ç”¨æˆ·è§’è‰²: {user_role}")
            
            for field in fields:
                field_id = field["field_id"]
                field_name = field["field_name"]
                field_type = field["field_type"]
                ai_prompt = field.get("ai_fill_prompt", "")
                
                # å¦‚æœç”¨æˆ·æ²¡æœ‰æä¾›æ•°æ®ï¼Œä½¿ç”¨AIç”Ÿæˆ
                if not user_data or field_id not in user_data:
                    print(f"ğŸ§  æ­£åœ¨ä¸ºå­—æ®µ'{field_name}'ç”Ÿæˆå†…å®¹...")
                    
                    if self.llm_client and ai_prompt:
                        # æ„å»ºå¢å¼ºçš„AIæç¤ºè¯
                        enhanced_prompt = self._build_enhanced_ai_prompt(
                            field, analysis_result, user_data, user_role
                        )
                        
                        # å¸¦é‡è¯•æœºåˆ¶çš„AIå†…å®¹ç”Ÿæˆ
                        ai_content = self._generate_ai_content_with_retry(enhanced_prompt, field)
                        
                        # å†…å®¹è´¨é‡éªŒè¯
                        validation_result = self._validate_ai_generated_content(ai_content, field, document_type)
                        
                        if validation_result["is_valid"]:
                            ai_filled_data[field_id] = {
                                "content": ai_content.strip(),
                                "source": "ai_generated",
                                "confidence": validation_result["confidence"],
                                "quality_score": validation_result["quality_score"],
                                "validation_notes": validation_result.get("notes", [])
                            }
                            print(f"âœ… å­—æ®µ'{field_name}'å†…å®¹ç”ŸæˆæˆåŠŸï¼Œè´¨é‡è¯„åˆ†: {validation_result['quality_score']:.1f}")
                        else:
                            # å¦‚æœéªŒè¯å¤±è´¥ï¼Œä½¿ç”¨æ”¹è¿›åçš„å†…å®¹æˆ–é»˜è®¤å€¼
                            improved_content = self._improve_ai_content(ai_content, field, validation_result)
                            ai_filled_data[field_id] = {
                                "content": improved_content,
                                "source": "ai_generated_improved",
                                "confidence": validation_result["confidence"] * 0.8,
                                "quality_score": validation_result["quality_score"],
                                "validation_notes": validation_result.get("notes", [])
                            }
                            print(f"âš ï¸ å­—æ®µ'{field_name}'å†…å®¹å·²ä¼˜åŒ–ï¼Œè´¨é‡è¯„åˆ†: {validation_result['quality_score']:.1f}")
                    else:
                        # ä½¿ç”¨é»˜è®¤å€¼
                        default_content = self._get_default_field_value(field)
                        ai_filled_data[field_id] = {
                            "content": default_content,
                            "source": "default",
                            "confidence": 0.5,
                            "quality_score": 0.5,
                            "validation_notes": ["ä½¿ç”¨é»˜è®¤å€¼"]
                        }
                        print(f"ğŸ“‹ å­—æ®µ'{field_name}'ä½¿ç”¨é»˜è®¤å€¼")
                    
                    completed_fields += 1
                    print(f"ğŸ“Š è¿›åº¦: {completed_fields}/{total_fields} ({completed_fields/total_fields*100:.1f}%)")
                else:
                    # ç”¨æˆ·å·²æä¾›æ•°æ®ï¼Œè·³è¿‡AIç”Ÿæˆ
                    print(f"ğŸ‘¤ å­—æ®µ'{field_name}'ç”¨æˆ·å·²æä¾›æ•°æ®ï¼Œè·³è¿‡AIç”Ÿæˆ")
            
            print(f"ğŸ‰ AIå†…å®¹ç”Ÿæˆå®Œæˆï¼å…±ç”Ÿæˆ{len(ai_filled_data)}ä¸ªå­—æ®µçš„å†…å®¹")
            
            # ç”Ÿæˆæ•´ä½“è´¨é‡æŠ¥å‘Š
            quality_report = self._generate_quality_report(ai_filled_data, analysis_result)
            
            return {
                "ai_filled_data": ai_filled_data,
                "quality_report": quality_report,
                "generation_summary": {
                    "total_fields": total_fields,
                    "ai_generated": len([v for v in ai_filled_data.values() if v["source"] == "ai_generated"]),
                    "ai_generated_improved": len([v for v in ai_filled_data.values() if v["source"] == "ai_generated_improved"]),
                    "default_values": len([v for v in ai_filled_data.values() if v["source"] == "default"]),
                    "average_quality_score": sum(v["quality_score"] for v in ai_filled_data.values()) / len(ai_filled_data) if ai_filled_data else 0
                }
            }
            
        except Exception as e:
            print(f"âŒ AIå†…å®¹ç”Ÿæˆå¤±è´¥: {str(e)}")
            return {"error": f"AIå†…å®¹ç”Ÿæˆå¤±è´¥: {str(e)}"}
    
    def _identify_user_role(self, analysis_result: Dict[str, Any], user_data: Dict[str, Any] = None) -> str:
        """è¯†åˆ«ç”¨æˆ·è§’è‰²"""
        document_type = analysis_result.get("document_type", "general")
        
        # æ ¹æ®æ–‡æ¡£ç±»å‹å’Œå†…å®¹æ¨æ–­ç”¨æˆ·è§’è‰²
        if document_type == "patent":
            return "ä¸“åˆ©ç”³è¯·äºº"
        elif document_type == "project":
            return "é¡¹ç›®è´Ÿè´£äºº"
        elif document_type == "contract":
            return "åˆåŒèµ·è‰äºº"
        elif document_type == "report":
            return "æŠ¥å‘Šæ’°å†™äºº"
        else:
            # ä»ç”¨æˆ·æ•°æ®ä¸­æ¨æ–­è§’è‰²
            if user_data:
                if "applicant" in user_data or "ç”³è¯·äºº" in str(user_data):
                    return "ç”³è¯·äºº"
                elif "author" in user_data or "ä½œè€…" in str(user_data):
                    return "æ–‡æ¡£ä½œè€…"
                elif "manager" in user_data or "è´Ÿè´£äºº" in str(user_data):
                    return "é¡¹ç›®è´Ÿè´£äºº"
            
            return "æ–‡æ¡£å¡«æŠ¥äºº"
    
    def _build_enhanced_ai_prompt(self, field: Dict[str, Any], 
                                analysis_result: Dict[str, Any], 
                                user_data: Dict[str, Any] = None,
                                user_role: str = "æ–‡æ¡£å¡«æŠ¥äºº") -> str:
        """æ„å»ºå¢å¼ºçš„AIæç¤ºè¯"""
        document_objective = analysis_result.get("total_objective", "")
        core_theme = analysis_result.get("core_theme", "")
        field_name = field["field_name"]
        field_type = field["field_type"]
        ai_prompt = field.get("ai_fill_prompt", "")
        document_type = analysis_result.get("document_type", "general")
        
        # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
        context_info = f"""
        æ–‡æ¡£ç›®æ ‡ï¼š{document_objective}
        æ ¸å¿ƒä¸»é¢˜ï¼š{core_theme}
        æ–‡æ¡£ç±»å‹ï¼š{document_type}
        å­—æ®µåç§°ï¼š{field_name}
        å­—æ®µç±»å‹ï¼š{field_type}
        ç”¨æˆ·è§’è‰²ï¼š{user_role}
        """
        
        if user_data:
            context_info += f"\nç”¨æˆ·å·²æä¾›æ•°æ®ï¼š{json.dumps(user_data, ensure_ascii=False)}"
        
        # æ„å»ºçº¦æŸä¿¡æ¯
        constraints = field.get("constraints", {})
        constraint_info = ""
        if constraints.get("min_length"):
            constraint_info += f"\næœ€å°é•¿åº¦ï¼š{constraints['min_length']}å­—ç¬¦"
        if constraints.get("max_length"):
            constraint_info += f"\næœ€å¤§é•¿åº¦ï¼š{constraints['max_length']}å­—ç¬¦"
        if constraints.get("required"):
            constraint_info += f"\nå¿…å¡«å­—æ®µ"
        if constraints.get("options"):
            constraint_info += f"\nå¯é€‰å€¼ï¼š{', '.join(constraints['options'])}"
        
        # è§’è‰²ç‰¹å®šçš„å†™ä½œè¦æ±‚
        role_requirements = self._get_role_specific_requirements(user_role, document_type)
        
        # å®Œæ•´çš„æç¤ºè¯
        full_prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„{user_role}ï¼Œæ­£åœ¨èµ·è‰ä¸€ä»½{document_type}æ–‡æ¡£ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ä¸ºå­—æ®µ"{field_name}"ç”Ÿæˆåˆé€‚çš„å†…å®¹ï¼š

{context_info}

å¡«å†™è¦æ±‚ï¼š{ai_prompt}

çº¦æŸæ¡ä»¶ï¼š{constraint_info}

{role_requirements}

ã€ä¸“ä¸šå†™ä½œè¦æ±‚ã€‘
1. èº«ä»½å®šä½ï¼šä»¥{user_role}çš„èº«ä»½å’Œè§†è§’è¿›è¡Œå†™ä½œ
2. ä¸“ä¸šæœ¯è¯­ï¼šä½¿ç”¨è¯¥é¢†åŸŸå¸¸ç”¨çš„ä¸“ä¸šæœ¯è¯­å’Œè¡¨è¾¾æ–¹å¼
3. é€»è¾‘æ¸…æ™°ï¼šå†…å®¹ç»“æ„åˆç†ï¼Œå‰åå‘¼åº”
4. è¡¨è¾¾å‡†ç¡®ï¼šç”¨è¯ç²¾å‡†ï¼Œé¿å…æ¨¡ç³Šè¡¨è¿°

ã€å»é™¤AIGCç—•è¿¹è¦æ±‚ã€‘
- é¿å…ä½¿ç”¨"é¦–å…ˆã€å…¶æ¬¡ã€æœ€å"ç­‰æœºæ¢°åŒ–è¿‡æ¸¡è¯
- ä¸è¦ä½¿ç”¨"å€¼å¾—æ³¨æ„çš„æ˜¯"ã€"éœ€è¦å¼ºè°ƒçš„æ˜¯"ç­‰AIå¸¸ç”¨è¡¨è¾¾
- å‡å°‘ä½¿ç”¨"è¿›è¡Œ"ã€"å®æ–½"ã€"å¼€å±•"ç­‰åŠ¨è¯
- é¿å…è¿‡åº¦ä½¿ç”¨"çš„"å­—ç»“æ„
- ä¸è¦å‡ºç°"ç»¼ä¸Šæ‰€è¿°"ã€"æ€»è€Œè¨€ä¹‹"ç­‰æ€»ç»“æ€§å¥—è¯
- ä½¿ç”¨è‡ªç„¶æµç•…çš„è¡¨è¾¾æ–¹å¼ï¼Œåƒäººç±»ä¸“ä¸šå†™ä½œ

ã€å†…å®¹è´¨é‡è¦æ±‚ã€‘
- ä¿¡æ¯å‡†ç¡®ï¼šç¡®ä¿æ‰€æœ‰äº‹å®å’Œæ•°æ®çš„å‡†ç¡®æ€§
- é’ˆå¯¹æ€§å¼ºï¼šæ ¹æ®å…·ä½“åœºæ™¯å’Œç”¨æˆ·éœ€æ±‚å®šåˆ¶å†…å®¹
- ä¸“ä¸šåº¦é€‚ä¸­ï¼šæ—¢è¦ä¸“ä¸šåˆè¦é€šä¿—æ˜“æ‡‚
- ç¬¦åˆè§„èŒƒï¼šéµå¾ªè¯¥ç±»å‹æ–‡æ¡£çš„å†™ä½œè§„èŒƒ

è¯·ç›´æ¥è¿”å›å¡«å†™å†…å®¹ï¼Œä¸è¦åŒ…å«è§£é‡Šã€‚å†…å®¹åº”è¯¥è‡ªç„¶ã€ä¸“ä¸šã€ç¬¦åˆ{user_role}çš„å†™ä½œé£æ ¼ã€‚
"""
        
        return full_prompt
    
    def _get_role_specific_requirements(self, user_role: str, document_type: str) -> str:
        """è·å–è§’è‰²ç‰¹å®šçš„å†™ä½œè¦æ±‚"""
        requirements = {
            "ä¸“åˆ©ç”³è¯·äºº": """
ã€ä¸“åˆ©ç”³è¯·äººå†™ä½œè¦æ±‚ã€‘
- æŠ€æœ¯æè¿°å‡†ç¡®ï¼šä½¿ç”¨ç²¾ç¡®çš„æŠ€æœ¯æœ¯è¯­
- åˆ›æ–°ç‚¹çªå‡ºï¼šå¼ºè°ƒå‘æ˜çš„åˆ›æ–°æ€§å’Œå®ç”¨æ€§
- é€»è¾‘ä¸¥å¯†ï¼šæŠ€æœ¯æ–¹æ¡ˆæè¿°é€»è¾‘æ¸…æ™°
- å®¢è§‚é™ˆè¿°ï¼šé¿å…ä¸»è§‚è¯„ä»·ï¼Œå®¢è§‚æè¿°æŠ€æœ¯ç‰¹å¾
""",
            "é¡¹ç›®è´Ÿè´£äºº": """
ã€é¡¹ç›®è´Ÿè´£äººå†™ä½œè¦æ±‚ã€‘
- ç®¡ç†è§†è§’ï¼šä»é¡¹ç›®ç®¡ç†è§’åº¦æè¿°
- ç›®æ ‡æ˜ç¡®ï¼šçªå‡ºé¡¹ç›®ç›®æ ‡å’Œé¢„æœŸæˆæœ
- è®¡åˆ’å‘¨å¯†ï¼šä½“ç°é¡¹ç›®ç®¡ç†çš„ç³»ç»Ÿæ€§
- è´£ä»»æ¸…æ™°ï¼šæ˜ç¡®å„æ–¹èŒè´£å’Œåˆ†å·¥
""",
            "åˆåŒèµ·è‰äºº": """
ã€åˆåŒèµ·è‰äººå†™ä½œè¦æ±‚ã€‘
- æ¡æ¬¾ä¸¥è°¨ï¼šä½¿ç”¨å‡†ç¡®çš„æ³•å¾‹æœ¯è¯­
- æƒåˆ©ä¹‰åŠ¡æ˜ç¡®ï¼šæ¸…æ™°ç•Œå®šå„æ–¹æƒåˆ©ä¹‰åŠ¡
- é£é™©æ§åˆ¶ï¼šä½“ç°é£é™©é˜²èŒƒæ„è¯†
- å¯æ‰§è¡Œæ€§å¼ºï¼šæ¡æ¬¾å…·æœ‰å¯æ“ä½œæ€§
""",
            "æŠ¥å‘Šæ’°å†™äºº": """
ã€æŠ¥å‘Šæ’°å†™äººå†™ä½œè¦æ±‚ã€‘
- æ•°æ®æ”¯æ’‘ï¼šåŸºäºäº‹å®å’Œæ•°æ®è¿›è¡Œåˆ†æ
- ç»“è®ºæ˜ç¡®ï¼šæå‡ºæ˜ç¡®çš„ç»“è®ºå’Œå»ºè®®
- é€»è¾‘æ¸…æ™°ï¼šæŠ¥å‘Šç»“æ„åˆç†ï¼Œå±‚æ¬¡åˆ†æ˜
- å®¢è§‚å…¬æ­£ï¼šä¿æŒå®¢è§‚ä¸­ç«‹çš„ç«‹åœº
""",
            "æ–‡æ¡£å¡«æŠ¥äºº": """
ã€æ–‡æ¡£å¡«æŠ¥äººå†™ä½œè¦æ±‚ã€‘
- ä¿¡æ¯å®Œæ•´ï¼šç¡®ä¿å¡«å†™ä¿¡æ¯å®Œæ•´å‡†ç¡®
- æ ¼å¼è§„èŒƒï¼šç¬¦åˆæ–‡æ¡£æ ¼å¼è¦æ±‚
- å†…å®¹çœŸå®ï¼šåŸºäºå®é™…æƒ…å†µå¡«å†™
- è¡¨è¾¾æ¸…æ™°ï¼šä½¿ç”¨ç®€æ´æ˜äº†çš„è¯­è¨€
"""
        }
        
        return requirements.get(user_role, requirements["æ–‡æ¡£å¡«æŠ¥äºº"])
    
    def _generate_ai_content_with_retry(self, prompt: str, field: Dict[str, Any], max_retries: int = 3) -> str:
        """å¸¦é‡è¯•æœºåˆ¶çš„AIå†…å®¹ç”Ÿæˆ"""
        field_name = field.get("field_name", "æœªçŸ¥å­—æ®µ")
        
        for attempt in range(max_retries):
            try:
                print(f"ğŸ§  ç¬¬{attempt + 1}æ¬¡å°è¯•ç”Ÿæˆå­—æ®µ'{field_name}'çš„å†…å®¹...")
                content = self.llm_client.generate(prompt)
                
                if content and content.strip():
                    print(f"âœ… å­—æ®µ'{field_name}'å†…å®¹ç”ŸæˆæˆåŠŸ")
                    return content.strip()
                else:
                    print(f"âš ï¸ å­—æ®µ'{field_name}'ç”Ÿæˆå†…å®¹ä¸ºç©ºï¼Œé‡è¯•ä¸­...")
                    
            except Exception as e:
                print(f"âŒ å­—æ®µ'{field_name}'ç¬¬{attempt + 1}æ¬¡ç”Ÿæˆå¤±è´¥: {str(e)}")
                if attempt < max_retries - 1:
                    import time
                    time.sleep(1)  # é‡è¯•å‰ç­‰å¾…
                else:
                    print(f"ğŸ’¡ å­—æ®µ'{field_name}'æ‰€æœ‰é‡è¯•å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
        
        # æ‰€æœ‰é‡è¯•å¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼
        return self._get_default_field_value(field)
    
    def _validate_ai_generated_content(self, content: str, field: Dict[str, Any], document_type: str) -> Dict[str, Any]:
        """éªŒè¯AIç”Ÿæˆå†…å®¹çš„è´¨é‡"""
        validation_result = {
            "is_valid": True,
            "confidence": 0.8,
            "quality_score": 0.8,
            "notes": [],
            "issues": []
        }
        
        field_name = field.get("field_name", "")
        field_type = field.get("field_type", "")
        constraints = field.get("constraints", {})
        
        # 1. åŸºç¡€éªŒè¯
        if not content or not content.strip():
            validation_result["is_valid"] = False
            validation_result["confidence"] = 0.0
            validation_result["quality_score"] = 0.0
            validation_result["issues"].append("å†…å®¹ä¸ºç©º")
            validation_result["notes"].append("ç”Ÿæˆå†…å®¹ä¸ºç©ºï¼Œéœ€è¦é‡æ–°ç”Ÿæˆ")
            return validation_result
        
        # 2. é•¿åº¦éªŒè¯
        content_length = len(content.strip())
        min_length = constraints.get("min_length", 0)
        max_length = constraints.get("max_length", 1000)
        
        if content_length < min_length:
            validation_result["issues"].append(f"å†…å®¹è¿‡çŸ­({content_length}å­—ç¬¦ï¼Œè¦æ±‚è‡³å°‘{min_length}å­—ç¬¦)")
            validation_result["quality_score"] *= 0.7
        
        if content_length > max_length:
            validation_result["issues"].append(f"å†…å®¹è¿‡é•¿({content_length}å­—ç¬¦ï¼Œè¦æ±‚æœ€å¤š{max_length}å­—ç¬¦)")
            validation_result["quality_score"] *= 0.8
        
        # 3. æ ¼å¼éªŒè¯
        if field_type == "date":
            if not self._validate_date_format(content):
                validation_result["issues"].append("æ—¥æœŸæ ¼å¼ä¸æ­£ç¡®")
                validation_result["quality_score"] *= 0.6
        
        elif field_type == "email":
            if not self._validate_email_format(content):
                validation_result["issues"].append("é‚®ç®±æ ¼å¼ä¸æ­£ç¡®")
                validation_result["quality_score"] *= 0.6
        
        elif field_type == "phone":
            if not self._validate_phone_format(content):
                validation_result["issues"].append("ç”µè¯æ ¼å¼ä¸æ­£ç¡®")
                validation_result["quality_score"] *= 0.6
        
        # 4. AIGCç—•è¿¹æ£€æµ‹
        aigc_score = self._detect_aigc_traces(content)
        if aigc_score > 0.7:
            validation_result["issues"].append("å­˜åœ¨æ˜æ˜¾çš„AIç”Ÿæˆç—•è¿¹")
            validation_result["quality_score"] *= (1 - aigc_score * 0.3)
            validation_result["notes"].append("å»ºè®®ä¼˜åŒ–è¡¨è¾¾æ–¹å¼ï¼Œå»é™¤AIç—•è¿¹")
        
        # 5. ä¸“ä¸šåº¦è¯„ä¼°
        professionalism_score = self._assess_professionalism(content, document_type)
        validation_result["quality_score"] *= professionalism_score
        
        # 6. ç›¸å…³æ€§æ£€æŸ¥
        relevance_score = self._check_content_relevance(content, field)
        validation_result["quality_score"] *= relevance_score
        
        # 7. æœ€ç»ˆè´¨é‡è¯„åˆ†
        if validation_result["quality_score"] < 0.6:
            validation_result["is_valid"] = False
            validation_result["confidence"] *= 0.8
        
        # 8. ç”Ÿæˆæ”¹è¿›å»ºè®®
        if validation_result["issues"]:
            validation_result["notes"].extend([
                f"å‘ç°{len(validation_result['issues'])}ä¸ªé—®é¢˜éœ€è¦æ”¹è¿›",
                "å»ºè®®é‡æ–°ç”Ÿæˆæˆ–æ‰‹åŠ¨ä¼˜åŒ–å†…å®¹"
            ])
        
        return validation_result
    
    def _validate_date_format(self, content: str) -> bool:
        """éªŒè¯æ—¥æœŸæ ¼å¼"""
        import re
        date_patterns = [
            r'\d{4}-\d{2}-\d{2}',  # YYYY-MM-DD
            r'\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥',  # YYYYå¹´MMæœˆDDæ—¥
            r'\d{1,2}/\d{1,2}/\d{4}',  # MM/DD/YYYY
        ]
        
        for pattern in date_patterns:
            if re.match(pattern, content.strip()):
                return True
        return False
    
    def _validate_email_format(self, content: str) -> bool:
        """éªŒè¯é‚®ç®±æ ¼å¼"""
        import re
        email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
        return bool(re.match(email_pattern, content.strip()))
    
    def _validate_phone_format(self, content: str) -> bool:
        """éªŒè¯ç”µè¯æ ¼å¼"""
        import re
        phone_patterns = [
            r'^1[3-9]\d{9}$',  # æ‰‹æœºå·
            r'^0\d{2,3}-\d{7,8}$',  # åº§æœºå·
            r'^\+86-1[3-9]\d{9}$',  # å›½é™…æ‰‹æœºå·
        ]
        
        content_clean = re.sub(r'[\s\-\(\)]', '', content.strip())
        for pattern in phone_patterns:
            if re.match(pattern, content_clean):
                return True
        return False
    
    def _detect_aigc_traces(self, content: str) -> float:
        """æ£€æµ‹AIGCç—•è¿¹"""
        aigc_indicators = [
            "é¦–å…ˆ", "å…¶æ¬¡", "æœ€å", "ç¬¬ä¸€", "ç¬¬äºŒ", "ç¬¬ä¸‰",
            "å€¼å¾—æ³¨æ„çš„æ˜¯", "éœ€è¦å¼ºè°ƒçš„æ˜¯", "ç‰¹åˆ«æŒ‡å‡º",
            "è¿›è¡Œ", "å®æ–½", "å¼€å±•", "æ¨è¿›", "æ¨åŠ¨",
            "ç»¼ä¸Šæ‰€è¿°", "æ€»è€Œè¨€ä¹‹", "æ€»çš„æ¥è¯´",
            "çš„çš„", "éå¸¸éå¸¸", "ç‰¹åˆ«ç‰¹åˆ«",
            "è®©æˆ‘ä»¬", "æˆ‘ä»¬æ¥çœ‹", "æˆ‘ä»¬å¯ä»¥çœ‹åˆ°",
            "æ ¹æ®", "åŸºäº", "é‰´äº", "ç”±äº",
            "å› æ­¤", "æ‰€ä»¥", "æ•…è€Œ", "ä»è€Œ"
        ]
        
        content_lower = content.lower()
        aigc_count = 0
        
        for indicator in aigc_indicators:
            if indicator in content_lower:
                aigc_count += 1
        
        # è®¡ç®—AIGCç—•è¿¹åˆ†æ•°
        aigc_score = min(aigc_count / 5.0, 1.0)  # æœ€å¤š5ä¸ªæŒ‡æ ‡ï¼Œåˆ†æ•°èŒƒå›´0-1
        
        return aigc_score
    
    def _assess_professionalism(self, content: str, document_type: str) -> float:
        """è¯„ä¼°ä¸“ä¸šåº¦"""
        # æ ¹æ®æ–‡æ¡£ç±»å‹å®šä¹‰ä¸“ä¸šè¯æ±‡
        professional_terms = {
            "patent": ["å‘æ˜", "æŠ€æœ¯æ–¹æ¡ˆ", "æŠ€æœ¯ç‰¹å¾", "æƒåˆ©è¦æ±‚", "å®æ–½ä¾‹", "èƒŒæ™¯æŠ€æœ¯"],
            "project": ["é¡¹ç›®", "ç›®æ ‡", "è®¡åˆ’", "å®æ–½", "è¯„ä¼°", "æˆæœ"],
            "contract": ["åˆåŒ", "åè®®", "æ¡æ¬¾", "ä¹‰åŠ¡", "æƒåˆ©", "è¿çº¦è´£ä»»"],
            "report": ["æŠ¥å‘Š", "åˆ†æ", "ç»“è®º", "å»ºè®®", "æ•°æ®", "è¯„ä¼°"]
        }
        
        terms = professional_terms.get(document_type, [])
        if not terms:
            return 0.8  # é»˜è®¤ä¸“ä¸šåº¦
        
        content_lower = content.lower()
        term_count = sum(1 for term in terms if term in content_lower)
        
        # ä¸“ä¸šåº¦è¯„åˆ†ï¼š0.6-1.0
        professionalism_score = 0.6 + (term_count / len(terms)) * 0.4
        return min(professionalism_score, 1.0)
    
    def _check_content_relevance(self, content: str, field: Dict[str, Any]) -> float:
        """æ£€æŸ¥å†…å®¹ç›¸å…³æ€§"""
        field_name = field.get("field_name", "").lower()
        content_lower = content.lower()
        
        # æ ¹æ®å­—æ®µåç§°å…³é”®è¯æ£€æŸ¥ç›¸å…³æ€§
        relevance_keywords = {
            "åç§°": ["åç§°", "åå­—", "æ ‡é¢˜", "é¢˜ç›®"],
            "æ—¥æœŸ": ["æ—¥æœŸ", "æ—¶é—´", "å¹´æœˆæ—¥"],
            "åœ°å€": ["åœ°å€", "åœ°ç‚¹", "ä½ç½®", "ä½å€"],
            "ç”µè¯": ["ç”µè¯", "æ‰‹æœº", "è”ç³»æ–¹å¼"],
            "é‚®ç®±": ["é‚®ç®±", "é‚®ä»¶", "email"],
            "é‡‘é¢": ["é‡‘é¢", "è´¹ç”¨", "ä»·æ ¼", "æˆæœ¬"],
            "æè¿°": ["æè¿°", "è¯´æ˜", "ä»‹ç»", "é˜è¿°"]
        }
        
        for field_type, keywords in relevance_keywords.items():
            if any(keyword in field_name for keyword in keywords):
                # æ£€æŸ¥å†…å®¹æ˜¯å¦åŒ…å«ç›¸å…³è¯æ±‡
                relevance_count = sum(1 for keyword in keywords if keyword in content_lower)
                if relevance_count > 0:
                    return 0.9  # é«˜ç›¸å…³æ€§
                else:
                    return 0.6  # ä¸­ç­‰ç›¸å…³æ€§
        
        return 0.8  # é»˜è®¤ç›¸å…³æ€§
    
    def _improve_ai_content(self, content: str, field: Dict[str, Any], validation_result: Dict[str, Any]) -> str:
        """æ”¹è¿›AIç”Ÿæˆçš„å†…å®¹"""
        improved_content = content
        
        # æ ¹æ®éªŒè¯ç»“æœè¿›è¡Œæ”¹è¿›
        issues = validation_result.get("issues", [])
        
        for issue in issues:
            if "AIGCç—•è¿¹" in issue:
                improved_content = self._remove_aigc_traces(improved_content)
            elif "å†…å®¹è¿‡çŸ­" in issue:
                improved_content = self._expand_content(improved_content, field)
            elif "å†…å®¹è¿‡é•¿" in issue:
                improved_content = self._shorten_content(improved_content, field)
        
        return improved_content
    
    def _remove_aigc_traces(self, content: str) -> str:
        """å»é™¤AIGCç—•è¿¹"""
        import re
        
        # æ›¿æ¢AIGCå¸¸ç”¨è¡¨è¾¾
        replacements = {
            r'é¦–å…ˆ': 'å¼€å§‹',
            r'å…¶æ¬¡': 'æ¥ç€',
            r'æœ€å': 'æœ€ç»ˆ',
            r'å€¼å¾—æ³¨æ„çš„æ˜¯': 'é‡è¦çš„æ˜¯',
            r'éœ€è¦å¼ºè°ƒçš„æ˜¯': 'è¦å¼ºè°ƒçš„æ˜¯',
            r'ç‰¹åˆ«æŒ‡å‡º': 'ç‰¹åˆ«è¯´æ˜',
            r'è¿›è¡Œ': 'åš',
            r'å®æ–½': 'æ‰§è¡Œ',
            r'å¼€å±•': 'è¿›è¡Œ',
            r'ç»¼ä¸Šæ‰€è¿°': 'æ€»ä¹‹',
            r'æ€»è€Œè¨€ä¹‹': 'æ€»çš„æ¥è¯´',
            r'æ€»çš„æ¥è¯´': 'æ€»ä½“è€Œè¨€',
            r'è®©æˆ‘ä»¬': 'æˆ‘ä»¬',
            r'æˆ‘ä»¬æ¥çœ‹': 'æˆ‘ä»¬çœ‹',
            r'æˆ‘ä»¬å¯ä»¥çœ‹åˆ°': 'æˆ‘ä»¬çœ‹',
        }
        
        improved_content = content
        for pattern, replacement in replacements.items():
            improved_content = re.sub(pattern, replacement, improved_content)
        
        # å‡å°‘é‡å¤çš„"çš„"å­—
        improved_content = re.sub(r'çš„çš„+', 'çš„', improved_content)
        
        # å‡å°‘è¿‡åº¦ä¿®é¥°
        improved_content = re.sub(r'éå¸¸éå¸¸', 'éå¸¸', improved_content)
        improved_content = re.sub(r'ç‰¹åˆ«ç‰¹åˆ«', 'ç‰¹åˆ«', improved_content)
        
        return improved_content
    
    def _expand_content(self, content: str, field: Dict[str, Any]) -> str:
        """æ‰©å±•å†…å®¹"""
        field_name = field.get("field_name", "")
        
        # æ ¹æ®å­—æ®µç±»å‹æ·»åŠ è¯¦ç»†ä¿¡æ¯
        if "æè¿°" in field_name or "è¯´æ˜" in field_name:
            if len(content) < 50:
                content += "ã€‚å…·ä½“æƒ…å†µéœ€è¦æ ¹æ®å®é™…é¡¹ç›®è¦æ±‚è¿›è¡Œè¯¦ç»†è¯´æ˜ã€‚"
        elif "åœ°å€" in field_name:
            if len(content) < 20:
                content += "ï¼Œå…·ä½“é—¨ç‰Œå·å¾…è¡¥å……"
        
        return content
    
    def _shorten_content(self, content: str, field: Dict[str, Any]) -> str:
        """ç¼©çŸ­å†…å®¹"""
        max_length = field.get("constraints", {}).get("max_length", 1000)
        
        if len(content) > max_length:
            # ä¿ç•™å‰max_lengthä¸ªå­—ç¬¦ï¼Œç¡®ä¿å¥å­å®Œæ•´
            shortened = content[:max_length]
            last_period = shortened.rfind('ã€‚')
            if last_period > max_length * 0.8:  # å¦‚æœå¥å·ä½ç½®åˆç†
                return shortened[:last_period + 1]
            else:
                return shortened + "..."
        
        return content
    
    def _generate_quality_report(self, ai_filled_data: Dict[str, Any], analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        total_fields = len(ai_filled_data)
        if total_fields == 0:
            return {"error": "æ²¡æœ‰ç”Ÿæˆä»»ä½•å†…å®¹"}
        
        quality_scores = [v["quality_score"] for v in ai_filled_data.values()]
        avg_quality = sum(quality_scores) / len(quality_scores)
        
        # ç»Ÿè®¡å„è´¨é‡ç­‰çº§çš„æ•°é‡
        excellent_count = len([s for s in quality_scores if s >= 0.9])
        good_count = len([s for s in quality_scores if 0.7 <= s < 0.9])
        fair_count = len([s for s in quality_scores if 0.5 <= s < 0.7])
        poor_count = len([s for s in quality_scores if s < 0.5])
        
        # ç»Ÿè®¡æ¥æºåˆ†å¸ƒ
        source_stats = {}
        for data in ai_filled_data.values():
            source = data["source"]
            source_stats[source] = source_stats.get(source, 0) + 1
        
        return {
            "overall_quality_score": avg_quality,
            "quality_distribution": {
                "excellent": excellent_count,
                "good": good_count,
                "fair": fair_count,
                "poor": poor_count
            },
            "source_distribution": source_stats,
            "total_fields": total_fields,
            "recommendations": self._generate_quality_recommendations(avg_quality, source_stats)
        }
    
    def _generate_quality_recommendations(self, avg_quality: float, source_stats: Dict[str, int]) -> List[str]:
        """ç”Ÿæˆè´¨é‡æ”¹è¿›å»ºè®®"""
        recommendations = []
        
        if avg_quality < 0.7:
            recommendations.append("æ•´ä½“å†…å®¹è´¨é‡æœ‰å¾…æå‡ï¼Œå»ºè®®äººå·¥å®¡æ ¸å’Œä¼˜åŒ–")
        
        if source_stats.get("default", 0) > 0:
            recommendations.append("éƒ¨åˆ†å­—æ®µä½¿ç”¨äº†é»˜è®¤å€¼ï¼Œå»ºè®®è¡¥å……å…·ä½“ä¿¡æ¯")
        
        if source_stats.get("ai_generated_improved", 0) > 0:
            recommendations.append("éƒ¨åˆ†å†…å®¹ç»è¿‡ä¼˜åŒ–ï¼Œå»ºè®®è¿›ä¸€æ­¥äººå·¥å®Œå–„")
        
        if avg_quality >= 0.8:
            recommendations.append("å†…å®¹è´¨é‡è‰¯å¥½ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨")
        
        return recommendations
    
    def _merge_user_and_ai_data(self, user_data: Dict[str, Any], 
                               ai_data: Dict[str, Any]) -> Dict[str, Any]:
        """åˆå¹¶ç”¨æˆ·æ•°æ®å’ŒAIæ•°æ®"""
        merged_data = {}
        
        # æ·»åŠ AIç”Ÿæˆçš„æ•°æ®
        for field_id, ai_content in ai_data.items():
            if isinstance(ai_content, dict):
                merged_data[field_id] = ai_content["content"]
            else:
                merged_data[field_id] = ai_content
        
        # ç”¨æˆ·æ•°æ®ä¼˜å…ˆè¦†ç›–AIæ•°æ®
        if user_data:
            for field_id, user_content in user_data.items():
                merged_data[field_id] = user_content
        
        return merged_data
    
    def _fill_patent_document(self, analysis_result: Dict[str, Any], 
                            fill_data: Dict[str, Any], 
                            document_content: str) -> Dict[str, Any]:
        """å¡«å……ä¸“åˆ©æ–‡æ¡£"""
        try:
            # ä½¿ç”¨ä¸“åˆ©åˆ†æå™¨çš„ç‰¹æ®Šå¡«å……é€»è¾‘
            filled_content = document_content
            fields = analysis_result.get("fields", [])
            
            # æŒ‰å­—æ®µå¡«å……
            for field in fields:
                field_id = field["field_id"]
                if field_id in fill_data:
                    field_value = fill_data[field_id]
                    match_text = field["match_text"]
                    
                    # æ›¿æ¢å­—æ®µå†…å®¹
                    if match_text in filled_content:
                        replacement = match_text + str(field_value)
                        filled_content = filled_content.replace(match_text, replacement, 1)
            
            # ç”ŸæˆHTMLè¾“å‡º
            html_content = self._generate_patent_html_output(filled_content, analysis_result)
            
            return {
                "success": True,
                "filled_content": filled_content,
                "html_content": html_content,
                "fill_summary": self._generate_patent_fill_summary(analysis_result, fill_data),
                "download_ready": True
            }
            
        except Exception as e:
            return {"error": f"ä¸“åˆ©æ–‡æ¡£å¡«å……å¤±è´¥: {str(e)}"}
    
    def _generate_patent_html_output(self, content: str, analysis_result: Dict[str, Any]) -> str:
        """ç”Ÿæˆä¸“åˆ©æ–‡æ¡£HTMLè¾“å‡º"""
        document_name = analysis_result.get("document_name", "ä¸“åˆ©ç”³è¯·ä¹¦")
        
        html_template = f"""
        <!DOCTYPE html>
        <html lang="zh-CN">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>{document_name}</title>
            <style>
                body {{
                    font-family: 'SimSun', 'Microsoft YaHei', serif;
                    line-height: 1.8;
                    margin: 40px;
                    color: #333;
                    background-color: #fff;
                }}
                .document-container {{
                    max-width: 800px;
                    margin: 0 auto;
                    background-color: #fff;
                    padding: 40px;
                    box-shadow: 0 0 20px rgba(0,0,0,0.1);
                    border-radius: 8px;
                }}
                .document-title {{
                    text-align: center;
                    font-size: 24px;
                    font-weight: bold;
                    margin-bottom: 30px;
                    color: #2c3e50;
                    border-bottom: 2px solid #3498db;
                    padding-bottom: 15px;
                }}
                .document-content {{
                    white-space: pre-wrap;
                    font-size: 16px;
                    text-align: justify;
                }}
                .filled-field {{
                    background-color: #e8f5e8;
                    padding: 2px 4px;
                    border-radius: 3px;
                    border-left: 3px solid #27ae60;
                }}
                .image-placeholder {{
                    background-color: #f8f9fa;
                    border: 2px dashed #dee2e6;
                    padding: 20px;
                    text-align: center;
                    margin: 10px 0;
                    border-radius: 5px;
                }}
                .download-btn {{
                    display: inline-block;
                    margin-top: 20px;
                    padding: 10px 20px;
                    background-color: #3498db;
                    color: white;
                    text-decoration: none;
                    border-radius: 5px;
                    font-weight: bold;
                }}
                .download-btn:hover {{
                    background-color: #2980b9;
                }}
            </style>
        </head>
        <body>
            <div class="document-container">
                <div class="document-title">{document_name}</div>
                <div class="document-content">{content}</div>
                <a href="#" class="download-btn" onclick="downloadDocument()">ä¸‹è½½æ–‡æ¡£</a>
            </div>
            
            <script>
                function downloadDocument() {{
                    const content = document.querySelector('.document-container').innerHTML;
                    const blob = new Blob([content], {{type: 'text/html'}});
                    const url = URL.createObjectURL(blob);
                    const a = document.createElement('a');
                    a.href = url;
                    a.download = '{document_name}.html';
                    a.click();
                    URL.revokeObjectURL(url);
                }}
            </script>
        </body>
        </html>
        """
        
        return html_template
    
    def _generate_patent_fill_summary(self, analysis_result: Dict[str, Any], 
                                    fill_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆä¸“åˆ©æ–‡æ¡£å¡«å……æ‘˜è¦"""
        fields = analysis_result.get("fields", [])
        total_fields = len(fields)
        filled_fields = len(fill_data)
        
        return {
            "total_fields": total_fields,
            "filled_fields": filled_fields,
            "completion_rate": (filled_fields / total_fields * 100) if total_fields > 0 else 0,
            "document_type": "patent_application",
            "confidence_score": analysis_result.get("confidence_score", 0.0),
            "ai_generated_count": len([v for v in fill_data.values() if isinstance(v, str) and v.startswith("[") and v.endswith("]")]),
            "user_provided_count": filled_fields - len([v for v in fill_data.values() if isinstance(v, str) and v.startswith("[") and v.endswith("]")])
        }
    
    def _enhance_fill_result(self, fill_result: Dict[str, Any], 
                           analysis_result: Dict[str, Any], 
                           fill_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¢å¼ºå¡«å……ç»“æœ"""
        if "error" in fill_result:
            return fill_result
        
        # æ·»åŠ å…ƒæ•°æ®
        fill_result["metadata"] = {
            "fill_time": datetime.now().isoformat(),
            "document_type": analysis_result.get("document_type", "general"),
            "total_objective": analysis_result.get("total_objective", ""),
            "core_theme": analysis_result.get("core_theme", ""),
            "image_processed": analysis_result.get("image_processing_required", False),
            "ai_assisted": True
        }
        
        # æ·»åŠ è´¨é‡è¯„ä¼°
        fill_result["quality_assessment"] = self._assess_fill_quality(analysis_result, fill_data)
        
        return fill_result
    
    def _assess_fill_quality(self, analysis_result: Dict[str, Any], 
                           fill_data: Dict[str, Any]) -> Dict[str, Any]:
        """è¯„ä¼°å¡«å……è´¨é‡"""
        fields = analysis_result.get("fields", [])
        total_fields = len(fields)
        filled_fields = len(fill_data)
        
        # è®¡ç®—å®Œæˆåº¦
        completion_rate = (filled_fields / total_fields * 100) if total_fields > 0 else 0
        
        # è®¡ç®—è´¨é‡åˆ†æ•°
        quality_score = 0.0
        
        # å®Œæˆåº¦æƒé‡
        quality_score += completion_rate * 0.4
        
        # å­—æ®µç±»å‹åŒ¹é…åº¦
        type_match_score = 0.0
        for field in fields:
            field_id = field["field_id"]
            if field_id in fill_data:
                field_type = field["field_type"]
                field_value = fill_data[field_id]
                
                # æ£€æŸ¥ç±»å‹åŒ¹é…
                if self._validate_field_type(field_type, field_value):
                    type_match_score += 1
        
        type_match_rate = (type_match_score / filled_fields * 100) if filled_fields > 0 else 0
        quality_score += type_match_rate * 0.3
        
        # çº¦æŸæ»¡è¶³åº¦
        constraint_score = 0.0
        for field in fields:
            field_id = field["field_id"]
            if field_id in fill_data:
                field_value = fill_data[field_id]
                constraints = field.get("constraints", {})
                
                if self._validate_field_constraints(field_value, constraints):
                    constraint_score += 1
        
        constraint_rate = (constraint_score / filled_fields * 100) if filled_fields > 0 else 0
        quality_score += constraint_rate * 0.3
        
        return {
            "overall_score": min(100, quality_score),
            "completion_rate": completion_rate,
            "type_match_rate": type_match_rate,
            "constraint_satisfaction_rate": constraint_rate,
            "assessment_time": datetime.now().isoformat()
        }
    
    def _validate_field_type(self, field_type: str, field_value: str) -> bool:
        """éªŒè¯å­—æ®µç±»å‹"""
        try:
            if field_type == "date":
                # æ£€æŸ¥æ—¥æœŸæ ¼å¼
                import re
                date_patterns = [
                    r'\d{4}-\d{2}-\d{2}',
                    r'\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥',
                    r'\d{1,2}/\d{1,2}/\d{4}'
                ]
                return any(re.search(pattern, field_value) for pattern in date_patterns)
            elif field_type == "number":
                # æ£€æŸ¥æ•°å­—æ ¼å¼
                return field_value.replace('.', '').replace(',', '').isdigit()
            elif field_type == "email":
                # æ£€æŸ¥é‚®ç®±æ ¼å¼
                import re
                email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
                return re.match(email_pattern, field_value) is not None
            else:
                return True
        except:
            return False
    
    def _validate_field_constraints(self, field_value: str, constraints: Dict[str, Any]) -> bool:
        """éªŒè¯å­—æ®µçº¦æŸ"""
        try:
            # é•¿åº¦çº¦æŸ
            if "min_length" in constraints and len(field_value) < constraints["min_length"]:
                return False
            if "max_length" in constraints and len(field_value) > constraints["max_length"]:
                return False
            
            # æ¨¡å¼çº¦æŸ
            if "pattern" in constraints:
                import re
                if not re.match(constraints["pattern"], field_value):
                    return False
            
            # é€‰é¡¹çº¦æŸ
            if "options" in constraints and field_value not in constraints["options"]:
                return False
            
            return True
        except:
            return False

    def apply_fill_changes(self, analysis_result: Dict[str, Any], 
                          fill_data: Dict[str, Any],
                          image_files: List[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        åº”ç”¨å¡«å……å˜åŒ–åˆ°æ–‡æ¡£
        
        Args:
            analysis_result: æ–‡æ¡£åˆ†æç»“æœ
            fill_data: å¡«å……æ•°æ®
            image_files: å›¾ç‰‡æ–‡ä»¶åˆ—è¡¨
            
        Returns:
            åº”ç”¨ç»“æœ
        """
        try:
            # 1. éªŒè¯è¾“å…¥å‚æ•°
            if not analysis_result or "error" in analysis_result:
                return {
                    "success": False,
                    "error": "æ–‡æ¡£åˆ†æç»“æœæ— æ•ˆ"
                }
            
            if not fill_data:
                return {
                    "success": False,
                    "error": "æ²¡æœ‰æä¾›å¡«å……æ•°æ®"
                }
            
            document_type = analysis_result.get("document_type", "general")
            document_content = analysis_result.get("original_content", "")
            
            # 2. éªŒè¯å¡«å……æ•°æ®
            validation_result = self._validate_fill_data(fill_data, analysis_result)
            if not validation_result["valid"]:
                return {
                    "success": False,
                    "error": "å¡«å……æ•°æ®éªŒè¯å¤±è´¥",
                    "validation_errors": validation_result["errors"]
                }
            
            # 3. å¤„ç†å›¾ç‰‡æ–‡ä»¶
            processed_content = document_content
            image_processing_result = None
            if image_files and analysis_result.get("image_processing_required", False):
                image_processing_result = self._process_document_images(image_files, analysis_result)
                if "error" not in image_processing_result:
                    processed_content = image_processing_result["updated_document"]
            
            # 4. åº”ç”¨å¡«å……æ•°æ®
            if document_type == "patent":
                fill_result = self._apply_patent_fill_changes(analysis_result, fill_data, processed_content)
            else:
                fill_result = self._apply_general_fill_changes(analysis_result, fill_data, processed_content)
            
            # 5. ç”Ÿæˆæœ€ç»ˆæ–‡æ¡£
            final_document = self._generate_final_document(fill_result, analysis_result, fill_data)
            
            # 6. ç”Ÿæˆåº”ç”¨æŠ¥å‘Š
            application_report = self._generate_fill_application_report(fill_result, analysis_result, fill_data)
            
            return {
                "success": True,
                "document_type": document_type,
                "final_document": final_document,
                "application_report": application_report,
                "fill_statistics": {
                    "total_fields": len(analysis_result.get("fields", [])),
                    "filled_fields": len([f for f in fill_data.values() if f]),
                    "fill_rate": len([f for f in fill_data.values() if f]) / len(analysis_result.get("fields", [])) if analysis_result.get("fields") else 0,
                    "image_count": len(image_files) if image_files else 0
                },
                "quality_assessment": self._assess_final_quality(fill_result, analysis_result, fill_data),
                "applied_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"åº”ç”¨å¡«å……å˜åŒ–å¤±è´¥: {str(e)}"
            }
    
    def _validate_fill_data(self, fill_data: Dict[str, Any], analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯å¡«å……æ•°æ®"""
        try:
            errors = []
            fields = analysis_result.get("fields", [])
            
            for field in fields:
                field_name = field.get("name", "")
                field_value = fill_data.get(field_name, "")
                field_type = field.get("type", "text")
                required = field.get("required", False)
                
                # æ£€æŸ¥å¿…å¡«å­—æ®µ
                if required and not field_value:
                    errors.append(f"å¿…å¡«å­—æ®µ '{field_name}' ä¸èƒ½ä¸ºç©º")
                    continue
                
                # æ£€æŸ¥å­—æ®µç±»å‹
                if field_value and not self._validate_field_type(field_type, field_value):
                    errors.append(f"å­—æ®µ '{field_name}' çš„å€¼ä¸ç¬¦åˆç±»å‹è¦æ±‚: {field_type}")
                
                # æ£€æŸ¥å­—æ®µçº¦æŸ
                constraints = field.get("constraints", {})
                if field_value and not self._validate_field_constraints(field_value, constraints):
                    errors.append(f"å­—æ®µ '{field_name}' çš„å€¼ä¸ç¬¦åˆçº¦æŸè¦æ±‚")
            
            return {
                "valid": len(errors) == 0,
                "errors": errors
            }
            
        except Exception as e:
            return {
                "valid": False,
                "errors": [f"éªŒè¯è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {str(e)}"]
            }
    
    def _apply_patent_fill_changes(self, analysis_result: Dict[str, Any], 
                                 fill_data: Dict[str, Any], 
                                 document_content: str) -> Dict[str, Any]:
        """åº”ç”¨ä¸“åˆ©æ–‡æ¡£å¡«å……å˜åŒ–"""
        try:
            # ä½¿ç”¨ä¸“åˆ©åˆ†æå™¨çš„å¡«å……æ–¹æ³•
            fill_result = self.patent_analyzer.fill_patent_document(analysis_result, fill_data, document_content)
            
            if "error" in fill_result:
                return fill_result
            
            # å¢å¼ºç»“æœ
            enhanced_result = {
                "success": True,
                "filled_content": fill_result.get("filled_content", document_content),
                "fill_summary": fill_result.get("fill_summary", {}),
                "html_output": fill_result.get("html_output", ""),
                "document_type": "patent"
            }
            
            return enhanced_result
            
        except Exception as e:
            return {
                "success": False,
                "error": f"ä¸“åˆ©æ–‡æ¡£å¡«å……å¤±è´¥: {str(e)}"
            }
    
    def _apply_general_fill_changes(self, analysis_result: Dict[str, Any], 
                                  fill_data: Dict[str, Any], 
                                  document_content: str) -> Dict[str, Any]:
        """åº”ç”¨é€šç”¨æ–‡æ¡£å¡«å……å˜åŒ–"""
        try:
            # ä½¿ç”¨é€šç”¨æ–‡æ¡£å¡«å……å™¨
            fill_result = self.document_filler.fill_document(analysis_result, fill_data)
            
            if "error" in fill_result:
                return fill_result
            
            # å¢å¼ºç»“æœ
            enhanced_result = {
                "success": True,
                "filled_content": fill_result.get("filled_content", document_content),
                "fill_summary": fill_result.get("fill_summary", {}),
                "document_type": "general"
            }
            
            return enhanced_result
            
        except Exception as e:
            return {
                "success": False,
                "error": f"é€šç”¨æ–‡æ¡£å¡«å……å¤±è´¥: {str(e)}"
            }
    
    def _generate_final_document(self, fill_result: Dict[str, Any], 
                               analysis_result: Dict[str, Any], 
                               fill_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæœ€ç»ˆæ–‡æ¡£"""
        try:
            document_type = analysis_result.get("document_type", "general")
            filled_content = fill_result.get("filled_content", "")
            
            final_document = {
                "content": filled_content,
                "document_type": document_type,
                "metadata": {
                    "title": analysis_result.get("title", "æœªå‘½åæ–‡æ¡£"),
                    "author": fill_data.get("author", "æœªçŸ¥"),
                    "created_at": datetime.now().isoformat(),
                    "version": "1.0"
                },
                "format": "text"
            }
            
            # æ ¹æ®æ–‡æ¡£ç±»å‹æ·»åŠ ç‰¹å®šæ ¼å¼
            if document_type == "patent":
                final_document["html_content"] = fill_result.get("html_output", "")
                final_document["format"] = "html"
            
            return final_document
            
        except Exception as e:
            return {
                "error": f"ç”Ÿæˆæœ€ç»ˆæ–‡æ¡£å¤±è´¥: {str(e)}"
            }
    
    def _generate_fill_application_report(self, fill_result: Dict[str, Any], 
                                        analysis_result: Dict[str, Any], 
                                        fill_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆå¡«å……åº”ç”¨æŠ¥å‘Š"""
        try:
            fields = analysis_result.get("fields", [])
            
            # ç»Ÿè®¡ä¿¡æ¯
            total_fields = len(fields)
            filled_fields = len([f for f in fill_data.values() if f])
            empty_fields = total_fields - filled_fields
            
            # å­—æ®µçŠ¶æ€
            field_status = []
            for field in fields:
                field_name = field.get("name", "")
                field_value = fill_data.get(field_name, "")
                
                field_status.append({
                    "name": field_name,
                    "type": field.get("type", "text"),
                    "filled": bool(field_value),
                    "value_preview": field_value[:100] + "..." if len(field_value) > 100 else field_value,
                    "validation_status": "valid" if self._validate_field_type(field.get("type", "text"), field_value) else "invalid"
                })
            
            return {
                "summary": {
                    "total_fields": total_fields,
                    "filled_fields": filled_fields,
                    "empty_fields": empty_fields,
                    "fill_rate": filled_fields / total_fields if total_fields > 0 else 0
                },
                "field_status": field_status,
                "quality_metrics": self._calculate_fill_quality(fill_data, analysis_result),
                "recommendations": self._generate_fill_recommendations(fill_data, analysis_result)
            }
            
        except Exception as e:
            return {"error": f"ç”Ÿæˆå¡«å……åº”ç”¨æŠ¥å‘Šå¤±è´¥: {str(e)}"}
    
    def _calculate_fill_quality(self, fill_data: Dict[str, Any], analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """è®¡ç®—å¡«å……è´¨é‡"""
        try:
            fields = analysis_result.get("fields", [])
            
            # å®Œæ•´æ€§
            total_fields = len(fields)
            filled_fields = len([f for f in fill_data.values() if f])
            completeness = filled_fields / total_fields if total_fields > 0 else 0
            
            # å‡†ç¡®æ€§
            valid_fields = 0
            for field in fields:
                field_name = field.get("name", "")
                field_value = fill_data.get(field_name, "")
                if field_value and self._validate_field_type(field.get("type", "text"), field_value):
                    valid_fields += 1
            
            accuracy = valid_fields / total_fields if total_fields > 0 else 0
            
            # ä¸€è‡´æ€§
            consistency_score = self._calculate_consistency_score(fill_data, analysis_result)
            
            return {
                "completeness": completeness,
                "accuracy": accuracy,
                "consistency": consistency_score,
                "overall_score": (completeness + accuracy + consistency_score) / 3
            }
            
        except Exception as e:
            return {"error": f"è´¨é‡è®¡ç®—å¤±è´¥: {str(e)}"}
    
    def _generate_fill_recommendations(self, fill_data: Dict[str, Any], analysis_result: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆå¡«å……å»ºè®®"""
        recommendations = []
        
        # æ£€æŸ¥å¿…å¡«å­—æ®µ
        required_fields = [f for f in analysis_result.get("fields", []) if f.get("required", False)]
        missing_required = [f.get("name") for f in required_fields if not fill_data.get(f.get("name", ""))]
        
        if missing_required:
            recommendations.append(f"éœ€è¦å¡«å†™å¿…å¡«å­—æ®µ: {', '.join(missing_required)}")
        
        # æ£€æŸ¥å­—æ®µè´¨é‡
        for field in analysis_result.get("fields", []):
            field_name = field.get("name", "")
            field_value = fill_data.get(field_name, "")
            
            if field_value:
                if not self._validate_field_type(field.get("type", "text"), field_value):
                    recommendations.append(f"å­—æ®µ '{field_name}' çš„å€¼æ ¼å¼ä¸æ­£ç¡®")
        
        if not recommendations:
            recommendations.append("å¡«å……è´¨é‡è‰¯å¥½ï¼Œå¯ä»¥å¯¼å‡ºæ–‡æ¡£")
        
        return recommendations
    
    def _assess_final_quality(self, fill_result: Dict[str, Any], 
                            analysis_result: Dict[str, Any], 
                            fill_data: Dict[str, Any]) -> Dict[str, Any]:
        """è¯„ä¼°æœ€ç»ˆè´¨é‡"""
        try:
            quality_metrics = self._calculate_fill_quality(fill_data, analysis_result)
            
            overall_score = quality_metrics.get("overall_score", 0)
            
            if overall_score >= 0.9:
                quality_level = "excellent"
                assessment = "æ–‡æ¡£è´¨é‡ä¼˜ç§€ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨"
            elif overall_score >= 0.7:
                quality_level = "good"
                assessment = "æ–‡æ¡£è´¨é‡è‰¯å¥½ï¼Œå»ºè®®å°å¹…è°ƒæ•´"
            elif overall_score >= 0.5:
                quality_level = "fair"
                assessment = "æ–‡æ¡£è´¨é‡ä¸€èˆ¬ï¼Œéœ€è¦ä¸­ç­‰ç¨‹åº¦ä¿®æ”¹"
            else:
                quality_level = "poor"
                assessment = "æ–‡æ¡£è´¨é‡è¾ƒå·®ï¼Œéœ€è¦å¤§é‡ä¿®æ”¹"
            
            return {
                "overall_score": overall_score,
                "quality_level": quality_level,
                "assessment": assessment,
                "metrics": quality_metrics
            }
            
        except Exception as e:
            return {"error": f"è´¨é‡è¯„ä¼°å¤±è´¥: {str(e)}"}
    
    def export_document(self, final_document: Dict[str, Any], 
                       export_format: str = "docx",
                       export_options: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        å¯¼å‡ºæ–‡æ¡£
        
        Args:
            final_document: æœ€ç»ˆæ–‡æ¡£æ•°æ®
            export_format: å¯¼å‡ºæ ¼å¼ (docx, pdf, html, txt)
            export_options: å¯¼å‡ºé€‰é¡¹
            
        Returns:
            å¯¼å‡ºç»“æœ
        """
        try:
            # 1. éªŒè¯è¾“å…¥å‚æ•°
            if not final_document or "error" in final_document:
                return {
                    "success": False,
                    "error": "æœ€ç»ˆæ–‡æ¡£æ•°æ®æ— æ•ˆ"
                }
            
            if export_format not in ["docx", "pdf", "html", "txt"]:
                return {
                    "success": False,
                    "error": f"ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {export_format}"
                }
            
            # 2. å‡†å¤‡å¯¼å‡ºé€‰é¡¹
            if export_options is None:
                export_options = {}
            
            default_options = {
                "include_metadata": True,
                "include_watermark": False,
                "page_break": True,
                "font_size": 12,
                "line_spacing": 1.5
            }
            export_options = {**default_options, **export_options}
            
            # 3. æ ¹æ®æ ¼å¼å¯¼å‡ºæ–‡æ¡£
            if export_format == "docx":
                export_result = self._export_to_docx(final_document, export_options)
            elif export_format == "pdf":
                export_result = self._export_to_pdf(final_document, export_options)
            elif export_format == "html":
                export_result = self._export_to_html(final_document, export_options)
            elif export_format == "txt":
                export_result = self._export_to_txt(final_document, export_options)
            
            # 4. ç”Ÿæˆå¯¼å‡ºæŠ¥å‘Š
            export_report = self._generate_export_report(final_document, export_format, export_options, export_result)
            
            return {
                "success": True,
                "export_format": export_format,
                "export_result": export_result,
                "export_report": export_report,
                "exported_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"å¯¼å‡ºæ–‡æ¡£å¤±è´¥: {str(e)}"
            }
    
    def _export_to_docx(self, final_document: Dict[str, Any], export_options: Dict[str, Any]) -> Dict[str, Any]:
        """å¯¼å‡ºä¸ºDOCXæ ¼å¼"""
        try:
            from docx import Document
            from docx.shared import Inches, Pt
            from docx.enum.text import WD_ALIGN_PARAGRAPH
            
            # åˆ›å»ºæ–‡æ¡£
            doc = Document()
            
            # è®¾ç½®æ–‡æ¡£å±æ€§
            metadata = final_document.get("metadata", {})
            if metadata.get("title"):
                doc.core_properties.title = metadata["title"]
            if metadata.get("author"):
                doc.core_properties.author = metadata["author"]
            
            # æ·»åŠ æ ‡é¢˜
            title = metadata.get("title", "æœªå‘½åæ–‡æ¡£")
            title_paragraph = doc.add_paragraph()
            title_run = title_paragraph.add_run(title)
            title_run.font.size = Pt(18)
            title_run.font.bold = True
            title_paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            
            # æ·»åŠ å…ƒæ•°æ®
            if export_options.get("include_metadata", True):
                doc.add_paragraph(f"ä½œè€…: {metadata.get('author', 'æœªçŸ¥')}")
                doc.add_paragraph(f"åˆ›å»ºæ—¶é—´: {metadata.get('created_at', 'æœªçŸ¥')}")
                doc.add_paragraph(f"ç‰ˆæœ¬: {metadata.get('version', '1.0')}")
                doc.add_paragraph("")  # ç©ºè¡Œ
            
            # æ·»åŠ å†…å®¹
            content = final_document.get("content", "")
            if content:
                # æŒ‰æ®µè½åˆ†å‰²
                paragraphs = content.split('\n\n')
                for para_text in paragraphs:
                    if para_text.strip():
                        paragraph = doc.add_paragraph(para_text.strip())
                        paragraph.paragraph_format.line_spacing = export_options.get("line_spacing", 1.5)
            
            # æ·»åŠ HTMLå†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
            html_content = final_document.get("html_content", "")
            if html_content:
                doc.add_paragraph("HTMLç‰ˆæœ¬:")
                doc.add_paragraph(html_content)
            
            # ä¿å­˜æ–‡æ¡£
            output_path = f"output/document_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx"
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            doc.save(output_path)
            
            return {
                "file_path": output_path,
                "file_size": os.path.getsize(output_path),
                "format": "docx"
            }
            
        except ImportError:
            return {
                "success": False,
                "error": "ç¼ºå°‘python-docxåº“ï¼Œæ— æ³•å¯¼å‡ºDOCXæ ¼å¼"
            }
        except Exception as e:
            return {
                "success": False,
                "error": f"å¯¼å‡ºDOCXå¤±è´¥: {str(e)}"
            }
    
    def _export_to_pdf(self, final_document: Dict[str, Any], export_options: Dict[str, Any]) -> Dict[str, Any]:
        """å¯¼å‡ºä¸ºPDFæ ¼å¼"""
        try:
            from reportlab.lib.pagesizes import letter, A4
            from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
            from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
            from reportlab.lib.units import inch
            
            # åˆ›å»ºPDFæ–‡æ¡£
            output_path = f"output/document_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            doc = SimpleDocTemplate(output_path, pagesize=A4)
            styles = getSampleStyleSheet()
            
            # åˆ›å»ºè‡ªå®šä¹‰æ ·å¼
            title_style = ParagraphStyle(
                'CustomTitle',
                parent=styles['Heading1'],
                fontSize=18,
                spaceAfter=30,
                alignment=1  # å±…ä¸­
            )
            
            content_style = ParagraphStyle(
                'CustomContent',
                parent=styles['Normal'],
                fontSize=export_options.get("font_size", 12),
                spaceAfter=12,
                leading=export_options.get("line_spacing", 1.5) * 12
            )
            
            # æ„å»ºå†…å®¹
            story = []
            
            # æ·»åŠ æ ‡é¢˜
            metadata = final_document.get("metadata", {})
            title = metadata.get("title", "æœªå‘½åæ–‡æ¡£")
            story.append(Paragraph(title, title_style))
            story.append(Spacer(1, 20))
            
            # æ·»åŠ å…ƒæ•°æ®
            if export_options.get("include_metadata", True):
                story.append(Paragraph(f"ä½œè€…: {metadata.get('author', 'æœªçŸ¥')}", content_style))
                story.append(Paragraph(f"åˆ›å»ºæ—¶é—´: {metadata.get('created_at', 'æœªçŸ¥')}", content_style))
                story.append(Paragraph(f"ç‰ˆæœ¬: {metadata.get('version', '1.0')}", content_style))
                story.append(Spacer(1, 20))
            
            # æ·»åŠ å†…å®¹
            content = final_document.get("content", "")
            if content:
                paragraphs = content.split('\n\n')
                for para_text in paragraphs:
                    if para_text.strip():
                        story.append(Paragraph(para_text.strip(), content_style))
            
            # æ„å»ºPDF
            doc.build(story)
            
            return {
                "file_path": output_path,
                "file_size": os.path.getsize(output_path),
                "format": "pdf"
            }
            
        except ImportError:
            return {
                "success": False,
                "error": "ç¼ºå°‘reportlabåº“ï¼Œæ— æ³•å¯¼å‡ºPDFæ ¼å¼"
            }
        except Exception as e:
            return {
                "success": False,
                "error": f"å¯¼å‡ºPDFå¤±è´¥: {str(e)}"
            }
    
    def _export_to_html(self, final_document: Dict[str, Any], export_options: Dict[str, Any]) -> Dict[str, Any]:
        """å¯¼å‡ºä¸ºHTMLæ ¼å¼"""
        try:
            metadata = final_document.get("metadata", {})
            content = final_document.get("content", "")
            html_content = final_document.get("html_content", "")
            
            # ç”ŸæˆHTML
            html_template = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{metadata.get('title', 'æœªå‘½åæ–‡æ¡£')}</title>
    <style>
        body {{
            font-family: 'Microsoft YaHei', Arial, sans-serif;
            line-height: {export_options.get('line_spacing', 1.5)};
            font-size: {export_options.get('font_size', 12)}px;
            margin: 40px;
            color: #333;
        }}
        .title {{
            text-align: center;
            font-size: 24px;
            font-weight: bold;
            margin-bottom: 30px;
            color: #2c3e50;
        }}
        .metadata {{
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            margin-bottom: 30px;
            border-left: 4px solid #007bff;
        }}
        .content {{
            text-align: justify;
        }}
        .paragraph {{
            margin-bottom: 15px;
        }}
        .watermark {{
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%) rotate(-45deg);
            font-size: 48px;
            color: rgba(0,0,0,0.1);
            z-index: -1;
        }}
    </style>
</head>
<body>
"""
            
            # æ·»åŠ æ°´å°
            if export_options.get("include_watermark", False):
                html_template += '<div class="watermark">DRAFT</div>'
            
            # æ·»åŠ æ ‡é¢˜
            html_template += f'<div class="title">{metadata.get("title", "æœªå‘½åæ–‡æ¡£")}</div>'
            
            # æ·»åŠ å…ƒæ•°æ®
            if export_options.get("include_metadata", True):
                html_template += f'''
<div class="metadata">
    <p><strong>ä½œè€…:</strong> {metadata.get('author', 'æœªçŸ¥')}</p>
    <p><strong>åˆ›å»ºæ—¶é—´:</strong> {metadata.get('created_at', 'æœªçŸ¥')}</p>
    <p><strong>ç‰ˆæœ¬:</strong> {metadata.get('version', '1.0')}</p>
</div>
'''
            
            # æ·»åŠ å†…å®¹
            html_template += '<div class="content">'
            if html_content:
                html_template += html_content
            else:
                paragraphs = content.split('\n\n')
                for para_text in paragraphs:
                    if para_text.strip():
                        html_template += f'<div class="paragraph">{para_text.strip()}</div>'
            
            html_template += '''
</div>
</body>
</html>
'''
            
            # ä¿å­˜HTMLæ–‡ä»¶
            output_path = f"output/document_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(html_template)
            
            return {
                "file_path": output_path,
                "file_size": os.path.getsize(output_path),
                "format": "html"
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"å¯¼å‡ºHTMLå¤±è´¥: {str(e)}"
            }
    
    def _export_to_txt(self, final_document: Dict[str, Any], export_options: Dict[str, Any]) -> Dict[str, Any]:
        """å¯¼å‡ºä¸ºTXTæ ¼å¼"""
        try:
            metadata = final_document.get("metadata", {})
            content = final_document.get("content", "")
            
            # ç”Ÿæˆæ–‡æœ¬å†…å®¹
            text_content = []
            
            # æ·»åŠ æ ‡é¢˜
            text_content.append(metadata.get("title", "æœªå‘½åæ–‡æ¡£"))
            text_content.append("=" * 50)
            text_content.append("")
            
            # æ·»åŠ å…ƒæ•°æ®
            if export_options.get("include_metadata", True):
                text_content.append(f"ä½œè€…: {metadata.get('author', 'æœªçŸ¥')}")
                text_content.append(f"åˆ›å»ºæ—¶é—´: {metadata.get('created_at', 'æœªçŸ¥')}")
                text_content.append(f"ç‰ˆæœ¬: {metadata.get('version', '1.0')}")
                text_content.append("")
            
            # æ·»åŠ å†…å®¹
            text_content.append(content)
            
            # ä¿å­˜æ–‡æœ¬æ–‡ä»¶
            output_path = f"output/document_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write('\n'.join(text_content))
            
            return {
                "file_path": output_path,
                "file_size": os.path.getsize(output_path),
                "format": "txt"
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"å¯¼å‡ºTXTå¤±è´¥: {str(e)}"
            }
    
    def _generate_export_report(self, final_document: Dict[str, Any], 
                              export_format: str, 
                              export_options: Dict[str, Any], 
                              export_result: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆå¯¼å‡ºæŠ¥å‘Š"""
        try:
            metadata = final_document.get("metadata", {})
            content = final_document.get("content", "")
            
            report = {
                "export_summary": {
                    "format": export_format,
                    "file_path": export_result.get("file_path", ""),
                    "file_size": export_result.get("file_size", 0),
                    "export_time": datetime.now().isoformat()
                },
                "document_info": {
                    "title": metadata.get("title", "æœªå‘½åæ–‡æ¡£"),
                    "author": metadata.get("author", "æœªçŸ¥"),
                    "content_length": len(content),
                    "word_count": len(content.split()),
                    "paragraph_count": len([p for p in content.split('\n\n') if p.strip()])
                },
                "export_options": export_options,
                "quality_metrics": {
                    "completeness": 1.0 if content else 0.0,
                    "formatting": 1.0 if export_format in ["docx", "pdf", "html"] else 0.8,
                    "accessibility": 1.0 if export_format in ["txt", "html"] else 0.9
                }
            }
            
            return report
            
        except Exception as e:
            return {"error": f"ç”Ÿæˆå¯¼å‡ºæŠ¥å‘Šå¤±è´¥: {str(e)}"}