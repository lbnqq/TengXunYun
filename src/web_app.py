import os
import sys
import json
import uuid
import time
import traceback
from datetime import datetime
from flask import Flask, request, jsonify, render_template, send_from_directory
from flask_cors import CORS
from werkzeug.utils import secure_filename
from dotenv import load_dotenv
import base64
import tempfile

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å°è¯•å¯¼å…¥å¯é€‰ä¾èµ–
try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False
    print("âš ï¸ pandasæœªå®‰è£…ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½å—é™")

# å°è¯•å¯¼å…¥é¡¹ç›®æ¨¡å—
try:
    from src.core.agent.agent_orchestrator import AgentOrchestrator
    from src.llm_clients.xingcheng_llm import XingchengLLMClient
    from src.llm_clients.multi_llm import MultiLLMClient
    from src.core.tools.format_alignment_coordinator import FormatAlignmentCoordinator
    from src.core.tools.document_fill_coordinator import DocumentFillCoordinator
    from src.core.tools.writing_style_analyzer import WritingStyleAnalyzer
    ADVANCED_FEATURES_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ é«˜çº§åŠŸèƒ½æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    ADVANCED_FEATURES_AVAILABLE = False

# å°è¯•å¯¼å…¥æ•°æ®åº“æ¨¡å—
try:
    from src.core.database import (
        DatabaseManager,
        AppSettingsRepository,
        DocumentRepository,
        TemplateRepository,
        PerformanceRepository,
        BatchProcessingRepository,
        DocumentRecord,
        DocumentType,
        IntentType,
        ProcessingStatus,
        get_database_manager
    )
    DATABASE_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ æ•°æ®åº“æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    DATABASE_AVAILABLE = False

# å°è¯•å¯¼å…¥æ€§èƒ½ç›‘æ§æ¨¡å—
try:
    from src.core.monitoring import get_performance_monitor, PerformanceTimer
    MONITORING_AVAILABLE = True
except ImportError:
    print("âš ï¸ æ€§èƒ½ç›‘æ§æ¨¡å—å¯¼å…¥å¤±è´¥")
    MONITORING_AVAILABLE = False
    # åˆ›å»ºç®€å•çš„æ€§èƒ½è®¡æ—¶å™¨æ›¿ä»£
    class PerformanceTimer:
        def __init__(self, name):
            self.name = name
        def __enter__(self):
            return self
        def __exit__(self, *args):
            pass

# å°è¯•å¯¼å…¥æ‰¹é‡å¤„ç†æ¨¡å—
try:
    from src.core.tools.batch_processor import get_batch_processor
    BATCH_PROCESSING_AVAILABLE = True
except ImportError:
    print("âš ï¸ æ‰¹é‡å¤„ç†æ¨¡å—å¯¼å…¥å¤±è´¥")
    BATCH_PROCESSING_AVAILABLE = False

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)

# åˆ›å»ºFlaskåº”ç”¨ï¼ŒæŒ‡å®šæ¨¡æ¿å’Œé™æ€æ–‡ä»¶è·¯å¾„
app = Flask(__name__,
           template_folder=os.path.join(project_root, 'templates'),
           static_folder=os.path.join(project_root, 'static'))
CORS(app)

# Configuration
app.config['UPLOAD_FOLDER'] = os.path.join(project_root, 'uploads')
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size
app.config['ALLOWED_EXTENSIONS'] = {'txt', 'pdf', 'docx'}

# Ensure upload directory exists
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
os.makedirs(os.path.join(project_root, 'output'), exist_ok=True)

# å…¨å±€å˜é‡å­˜å‚¨åè°ƒå™¨å®ä¾‹
orchestrator_instance = None
format_coordinator = None
fill_coordinator = None
style_analyzer = None

# åˆå§‹åŒ–æ•°æ®åº“
db_manager = None
settings_repo = None
document_repo = None
template_repo = None

# åœ¨å…¨å±€å˜é‡åˆå§‹åŒ–éƒ¨åˆ†æ·»åŠ 
enhanced_document_filler = None
patent_analyzer = None
image_processor = None

def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
    global db_manager, settings_repo, document_repo, template_repo
    try:
        db_manager = get_database_manager()
        settings_repo = AppSettingsRepository()
        document_repo = DocumentRepository()
        template_repo = TemplateRepository()
        print("âœ… æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        return False

def allowed_file(filename):
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in app.config['ALLOWED_EXTENSIONS']

def handle_batch_upload():
    """å¤„ç†æ‰¹é‡ä¸Šä¼ ï¼Œåªä¿å­˜æ–‡ä»¶ä¸è¿›è¡Œå¤„ç†"""
    try:
        if 'file' not in request.files:
            return jsonify({'success': False, 'error': 'æ²¡æœ‰æ–‡ä»¶'}), 400

        file = request.files['file']
        if file.filename == '':
            return jsonify({'success': False, 'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400

        if not allowed_file(file.filename):
            return jsonify({'success': False, 'error': 'ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼'}), 400

        # Generate unique filename
        filename = secure_filename(file.filename)
        unique_filename = f"{uuid.uuid4().hex}_{filename}"
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], unique_filename)

        # Save file
        file.save(filepath)

        print(f"ğŸ“ Batch upload file saved: {filepath}")

        return jsonify({
            'success': True,
            'file_path': filepath,
            'filename': filename,
            'uploaded_at': datetime.now().isoformat()
        })

    except Exception as e:
        print(f"âŒ Batch upload error: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

def initialize_agent(api_type="xingcheng", model_name=None):
    """Initialize the document agent with specified LLM client."""
    KB_PATH = os.path.join(project_root, "src/core/knowledge_base")
    
    if api_type == "multi":
        # ä½¿ç”¨å¤šAPIå®¢æˆ·ç«¯
        try:
            llm_client = MultiLLMClient()
            print("MultiLLMClient initialized successfully")
            return AgentOrchestrator(llm_client=llm_client, kb_path=KB_PATH)
        except Exception as e:
            print(f"Error initializing MultiLLMClient: {e}")
            print("Falling back to mock mode")
            return None
    elif api_type == "xingcheng":
        # ä½¿ç”¨è®¯é£æ˜Ÿç«API
        XINGCHENG_API_KEY = os.getenv("XINGCHENG_API_KEY")
        XINGCHENG_API_SECRET = os.getenv("XINGCHENG_API_SECRET")
        LLM_MODEL_NAME = model_name or os.getenv("LLM_MODEL_NAME", "x1")
        
        if not XINGCHENG_API_KEY:
            print("Warning: Xingcheng API key not configured, using mock mode")
            return None
        
        try:
            llm_client = XingchengLLMClient(
                api_key=XINGCHENG_API_KEY,
                api_secret=XINGCHENG_API_SECRET,
                model_name=LLM_MODEL_NAME
            )
            return AgentOrchestrator(llm_client=llm_client, kb_path=KB_PATH)
        except Exception as e:
            print(f"Error initializing XingchengLLMClient: {e}")
            print("Falling back to mock mode")
            return None
    else:
        print(f"Unknown API type: {api_type}, using mock mode")
        return None

def analyze_document_scenario(content):
    """æ™ºèƒ½åˆ†ææ–‡æ¡£åœºæ™¯å’Œç±»å‹"""
    if not content:
        return 'é€šç”¨æ–‡æ¡£', 'åŠå…¬æ–‡æ¡£', ['æ–‡æ¡£å†…å®¹åˆ†æ', 'ç»“æ„ä¼˜åŒ–å»ºè®®']

    content_lower = content.lower()

    # ä¼šè®®æ–‡æ¡£æ£€æµ‹
    meeting_keywords = ['ä¼šè®®', 'meeting', 'è®®ç¨‹', 'å†³è®®', 'è®¨è®º', 'å‚ä¼š', 'ä¼šè®®çºªè¦', 'å†³ç­–']
    if any(keyword in content_lower for keyword in meeting_keywords):
        return 'ä¼šè®®æ–‡æ¡£', 'è¿™æ˜¯ä¸€ä»½ä¼šè®®ç›¸å…³æ–‡æ¡£ï¼Œè®°å½•äº†ä¼šè®®è®®ç¨‹ã€è®¨è®ºå†…å®¹å’Œå†³ç­–ç»“æœ', [
            'ä¼šè®®ä¸»é¢˜å’Œç›®æ ‡', 'å‚ä¼šäººå‘˜ä¿¡æ¯', 'è®¨è®ºçš„å…³é”®è®®é¢˜', 'è¾¾æˆçš„å†³ç­–å’Œå…±è¯†', 'åç»­è¡ŒåŠ¨è®¡åˆ’'
        ]

    # æŠ€æœ¯æ–‡æ¡£æ£€æµ‹
    tech_keywords = ['æŠ€æœ¯', 'technical', 'ç³»ç»Ÿ', 'æ¶æ„', 'å¼€å‘', 'ä»£ç ', 'api', 'æ•°æ®åº“', 'ç®—æ³•']
    if any(keyword in content_lower for keyword in tech_keywords):
        return 'æŠ€æœ¯æ–‡æ¡£', 'è¿™æ˜¯ä¸€ä»½æŠ€æœ¯æ–‡æ¡£ï¼Œæ¶‰åŠç³»ç»Ÿè®¾è®¡ã€å¼€å‘è§„èŒƒæˆ–æŠ€æœ¯å®ç°', [
            'æŠ€æœ¯æ¶æ„è®¾è®¡', 'æ ¸å¿ƒåŠŸèƒ½æ¨¡å—', 'æ€§èƒ½å’Œå®‰å…¨è¦æ±‚', 'å¼€å‘å’Œéƒ¨ç½²æµç¨‹', 'ç»´æŠ¤å’Œä¼˜åŒ–å»ºè®®'
        ]

    # äº§å“æ–‡æ¡£æ£€æµ‹
    product_keywords = ['äº§å“', 'product', 'åŠŸèƒ½', 'éœ€æ±‚', 'ç”¨æˆ·', 'å¸‚åœº', 'ç«å“', 'è§„åˆ’']
    if any(keyword in content_lower for keyword in product_keywords):
        return 'äº§å“æ–‡æ¡£', 'è¿™æ˜¯ä¸€ä»½äº§å“ç›¸å…³æ–‡æ¡£ï¼Œæè¿°äº†äº§å“åŠŸèƒ½ã€éœ€æ±‚æˆ–å¸‚åœºç­–ç•¥', [
            'äº§å“æ ¸å¿ƒåŠŸèƒ½', 'ç›®æ ‡ç”¨æˆ·ç¾¤ä½“', 'å¸‚åœºå®šä½åˆ†æ', 'åŠŸèƒ½ä¼˜å…ˆçº§', 'äº§å“å‘å±•è·¯çº¿å›¾'
        ]

    # åˆ†ææŠ¥å‘Šæ£€æµ‹
    report_keywords = ['æŠ¥å‘Š', 'report', 'åˆ†æ', 'æ€»ç»“', 'æ•°æ®', 'ç»Ÿè®¡', 'è¶‹åŠ¿', 'ç»“è®º']
    if any(keyword in content_lower for keyword in report_keywords):
        return 'åˆ†ææŠ¥å‘Š', 'è¿™æ˜¯ä¸€ä»½åˆ†ææŠ¥å‘Šï¼ŒåŒ…å«æ•°æ®åˆ†æã€è¶‹åŠ¿æ€»ç»“å’Œç»“è®ºå»ºè®®', [
            'å…³é”®æ•°æ®æŒ‡æ ‡', 'è¶‹åŠ¿åˆ†æç»“æœ', 'é—®é¢˜è¯†åˆ«å’ŒåŸå› ', 'æ”¹è¿›å»ºè®®æ–¹æ¡ˆ', 'é¢„æœŸæ•ˆæœè¯„ä¼°'
        ]

    # å•†ä¸šæ–‡æ¡£æ£€æµ‹
    business_keywords = ['å•†ä¸š', 'business', 'åˆåŒ', 'åè®®', 'æ–¹æ¡ˆ', 'ææ¡ˆ', 'é¢„ç®—', 'æˆæœ¬']
    if any(keyword in content_lower for keyword in business_keywords):
        return 'å•†ä¸šæ–‡æ¡£', 'è¿™æ˜¯ä¸€ä»½å•†ä¸šæ–‡æ¡£ï¼Œæ¶‰åŠå•†ä¸šè®¡åˆ’ã€åˆåŒåè®®æˆ–è´¢åŠ¡åˆ†æ', [
            'å•†ä¸šç›®æ ‡å’Œç­–ç•¥', 'è´¢åŠ¡é¢„ç®—åˆ†æ', 'é£é™©è¯„ä¼°', 'åˆä½œä¼™ä¼´å…³ç³»', 'æ‰§è¡Œæ—¶é—´è¡¨'
        ]

    return 'é€šç”¨æ–‡æ¡£', 'è¿™æ˜¯ä¸€ä»½é€šç”¨åŠå…¬æ–‡æ¡£ï¼ŒåŒ…å«å¤šç§ç±»å‹çš„ä¿¡æ¯å’Œå†…å®¹', [
        'æ–‡æ¡£ä¸»è¦å†…å®¹', 'å…³é”®ä¿¡æ¯è¦ç‚¹', 'é‡è¦è§‚ç‚¹æ€»ç»“', 'è¡ŒåŠ¨å»ºè®®äº‹é¡¹'
    ]

def generate_content_summary(content, max_length=200):
    """æ™ºèƒ½ç”Ÿæˆå†…å®¹æ‘˜è¦"""
    if not content:
        return "æ–‡æ¡£å†…å®¹ä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆæ‘˜è¦ã€‚"

    # åˆ†å¥å¤„ç†
    sentences = content.replace('ã€‚', 'ã€‚\n').replace('ï¼', 'ï¼\n').replace('ï¼Ÿ', 'ï¼Ÿ\n').split('\n')
    sentences = [s.strip() for s in sentences if s.strip() and len(s.strip()) > 5]

    if not sentences:
        return content[:max_length] + ("..." if len(content) > max_length else "")

    # è¯†åˆ«å…³é”®å¥å­ï¼ˆåŒ…å«é‡è¦å…³é”®è¯çš„å¥å­ï¼‰
    important_keywords = [
        'å†³ç­–', 'å†³å®š', 'ç»“è®º', 'å»ºè®®', 'è®¡åˆ’', 'ç›®æ ‡', 'é‡è¦', 'å…³é”®',
        'æ ¸å¿ƒ', 'ä¸»è¦', 'é¦–å…ˆ', 'å…¶æ¬¡', 'æœ€å', 'æ€»ç»“', 'æ¦‚è¿°',
        'é—®é¢˜', 'è§£å†³', 'æ–¹æ¡ˆ', 'ç­–ç•¥', 'æªæ–½', 'è¡ŒåŠ¨', 'æ‰§è¡Œ'
    ]

    # ç»™å¥å­æ‰“åˆ†
    sentence_scores = []
    for i, sentence in enumerate(sentences):
        score = 0
        # ä½ç½®æƒé‡ï¼šå¼€å¤´å’Œç»“å°¾çš„å¥å­æ›´é‡è¦
        if i == 0:
            score += 3
        elif i == len(sentences) - 1:
            score += 2
        elif i < len(sentences) * 0.3:  # å‰30%
            score += 1

        # å…³é”®è¯æƒé‡
        for keyword in important_keywords:
            if keyword in sentence:
                score += 2

        # é•¿åº¦æƒé‡ï¼šé€‚ä¸­é•¿åº¦çš„å¥å­æ›´å¯èƒ½åŒ…å«é‡è¦ä¿¡æ¯
        if 20 <= len(sentence) <= 100:
            score += 1

        # æ•°å­—æƒé‡ï¼šåŒ…å«æ•°å­—çš„å¥å­é€šå¸¸æ›´é‡è¦
        import re
        if re.search(r'\d+', sentence):
            score += 1

        sentence_scores.append((sentence, score))

    # æŒ‰åˆ†æ•°æ’åºï¼Œé€‰æ‹©æœ€é‡è¦çš„å¥å­
    sentence_scores.sort(key=lambda x: x[1], reverse=True)

    # æ„å»ºæ‘˜è¦
    summary_sentences = []
    current_length = 0

    for sentence, score in sentence_scores:
        if current_length + len(sentence) <= max_length - 20:  # ç•™ä¸€äº›ä½™é‡
            summary_sentences.append(sentence)
            current_length += len(sentence)
        else:
            break

    # å¦‚æœæ²¡æœ‰é€‰ä¸­ä»»ä½•å¥å­ï¼Œä½¿ç”¨å‰å‡ å¥
    if not summary_sentences:
        summary_sentences = sentences[:2]

    # æŒ‰åŸæ–‡é¡ºåºé‡æ–°æ’åˆ—
    final_sentences = []
    for sentence in sentences:
        if sentence in summary_sentences:
            final_sentences.append(sentence)

    summary = 'ã€‚'.join(final_sentences)
    if not summary.endswith('ã€‚'):
        summary += 'ã€‚'

    # å¦‚æœè¿˜æ˜¯å¤ªé•¿ï¼Œæˆªæ–­
    if len(summary) > max_length:
        summary = summary[:max_length-3] + "..."

    return summary

def extract_key_entities(content):
    """æ™ºèƒ½æå–å…³é”®å®ä½“å’Œæ¦‚å¿µ"""
    if not content:
        return []

    import re
    entities = []

    # 1. æ—¶é—´å®ä½“æå–
    time_patterns = [
        (r'\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥', 'å…·ä½“æ—¥æœŸ'),
        (r'\d{1,2}æœˆ\d{1,2}æ—¥', 'æœˆæ—¥'),
        (r'\d{4}-\d{1,2}-\d{1,2}', 'æ—¥æœŸ'),
        (r'\d{1,2}:\d{2}', 'æ—¶é—´'),
        (r'ä¸‹å‘¨|æœ¬å‘¨|ä¸Šå‘¨|ä¸‹æœˆ|æœ¬æœˆ|ä¸Šæœˆ', 'ç›¸å¯¹æ—¶é—´')
    ]

    for pattern, type_name in time_patterns:
        matches = re.findall(pattern, content)
        for match in matches[:2]:  # é™åˆ¶æ¯ç§ç±»å‹æœ€å¤š2ä¸ª
            entities.append({'type': type_name, 'value': match})

    # 2. æ•°å€¼å®ä½“æå–
    number_patterns = [
        (r'\d+%', 'ç™¾åˆ†æ¯”'),
        (r'\d+ä¸‡å…ƒ?', 'é‡‘é¢(ä¸‡)'),
        (r'\d+äº¿å…ƒ?', 'é‡‘é¢(äº¿)'),
        (r'ï¿¥\d+', 'äººæ°‘å¸'),
        (r'\$\d+', 'ç¾å…ƒ'),
        (r'\d+äºº', 'äººæ•°'),
        (r'\d+ä¸ª', 'æ•°é‡'),
        (r'\d+é¡¹', 'é¡¹ç›®æ•°')
    ]

    for pattern, type_name in number_patterns:
        matches = re.findall(pattern, content)
        for match in matches[:2]:
            entities.append({'type': type_name, 'value': match})

    # 3. äººåæå–ï¼ˆç®€å•çš„ä¸­æ–‡äººåæ¨¡å¼ï¼‰
    name_patterns = [
        r'[å¼ ç‹æèµµåˆ˜é™ˆæ¨é»„å‘¨å´å¾å­™èƒ¡æœ±é«˜æ—ä½•éƒ­é©¬ç½—æ¢å®‹éƒ‘è°¢éŸ©å”å†¯äºè‘£è§ç¨‹æ›¹è¢é‚“è®¸å‚…æ²ˆæ›¾å½­å•è‹å¢è’‹è”¡è´¾ä¸é­è–›å¶é˜ä½™æ½˜æœæˆ´å¤é’Ÿæ±ªç”°ä»»å§œèŒƒæ–¹çŸ³å§šè°­å»–é‚¹ç†Šé‡‘é™†éƒå­”ç™½å´”åº·æ¯›é‚±ç§¦æ±Ÿå²é¡¾ä¾¯é‚µå­Ÿé¾™ä¸‡æ®µé›·é’±æ±¤å°¹é»æ˜“å¸¸æ­¦ä¹”è´ºèµ–é¾šæ–‡][ä¸€-é¾¯]{1,2}',
    ]

    for pattern in name_patterns:
        matches = re.findall(pattern, content)
        # è¿‡æ»¤æ‰ä¸€äº›å¸¸è§çš„éäººåè¯æ±‡
        filtered_matches = [m for m in matches if len(m) >= 2 and m not in ['ä¼šè®®', 'é¡¹ç›®', 'å…¬å¸', 'éƒ¨é—¨', 'äº§å“', 'æŠ€æœ¯', 'å¸‚åœº', 'æ–¹æ¡ˆ']]
        for match in filtered_matches[:3]:
            entities.append({'type': 'äººå‘˜', 'value': match})

    # 4. ç»„ç»‡æœºæ„æå–
    org_patterns = [
        r'[ä¸€-é¾¯]*éƒ¨é—¨?',
        r'[ä¸€-é¾¯]*å…¬å¸',
        r'[ä¸€-é¾¯]*å›¢é˜Ÿ',
        r'[ä¸€-é¾¯]*å°ç»„',
        r'[ä¸€-é¾¯]*ä¸­å¿ƒ'
    ]

    for pattern in org_patterns:
        matches = re.findall(pattern, content)
        filtered_matches = [m for m in matches if len(m) >= 3 and 'éƒ¨é—¨' in m or 'å…¬å¸' in m or 'å›¢é˜Ÿ' in m or 'å°ç»„' in m or 'ä¸­å¿ƒ' in m]
        for match in filtered_matches[:2]:
            entities.append({'type': 'ç»„ç»‡', 'value': match})

    # 5. å…³é”®æ¦‚å¿µæå–
    concept_keywords = [
        'äº§å“', 'é¡¹ç›®', 'æ–¹æ¡ˆ', 'è®¡åˆ’', 'ç­–ç•¥', 'ç›®æ ‡', 'ä»»åŠ¡', 'åŠŸèƒ½',
        'ç³»ç»Ÿ', 'å¹³å°', 'æœåŠ¡', 'æŠ€æœ¯', 'æ¶æ„', 'è®¾è®¡', 'å¼€å‘', 'æµ‹è¯•',
        'å¸‚åœº', 'ç”¨æˆ·', 'å®¢æˆ·', 'éœ€æ±‚', 'åé¦ˆ', 'ä½“éªŒ', 'æ»¡æ„åº¦',
        'é¢„ç®—', 'æˆæœ¬', 'æ”¶å…¥', 'åˆ©æ¶¦', 'æŠ•èµ„', 'å›æŠ¥', 'é£é™©'
    ]

    found_concepts = []
    for keyword in concept_keywords:
        if keyword in content and keyword not in found_concepts:
            found_concepts.append(keyword)
            entities.append({'type': 'å…³é”®æ¦‚å¿µ', 'value': keyword})
            if len(found_concepts) >= 5:  # æœ€å¤š5ä¸ªæ¦‚å¿µ
                break

    # 6. å¦‚æœå®ä½“å¤ªå°‘ï¼Œæ·»åŠ ä¸€äº›ä»å†…å®¹ä¸­æå–çš„é‡è¦è¯æ±‡
    if len(entities) < 3:
        # æå–å‡ºç°é¢‘ç‡è¾ƒé«˜çš„è¯æ±‡
        words = re.findall(r'[ä¸€-é¾¯]{2,4}', content)
        word_count = {}
        for word in words:
            if len(word) >= 2 and word not in ['è¿™ä¸ª', 'é‚£ä¸ª', 'å¯ä»¥', 'éœ€è¦', 'è¿›è¡Œ', 'å®ç°', 'å®Œæˆ', 'å»ºè®®']:
                word_count[word] = word_count.get(word, 0) + 1

        # é€‰æ‹©å‡ºç°æ¬¡æ•°æœ€å¤šçš„è¯æ±‡
        sorted_words = sorted(word_count.items(), key=lambda x: x[1], reverse=True)
        for word, count in sorted_words[:3]:
            if count >= 2:  # è‡³å°‘å‡ºç°2æ¬¡
                entities.append({'type': 'é‡è¦è¯æ±‡', 'value': f"{word}(å‡ºç°{count}æ¬¡)"})

    # å»é‡å¹¶é™åˆ¶æ•°é‡
    seen = set()
    unique_entities = []
    for entity in entities:
        key = f"{entity['type']}:{entity['value']}"
        if key not in seen:
            seen.add(key)
            unique_entities.append(entity)

    return unique_entities[:10]  # æœ€å¤šè¿”å›10ä¸ªå®ä½“

def analyze_content_depth(content, key_points):
    """æ·±åº¦åˆ†ææ–‡æ¡£å†…å®¹ç‰¹å¾"""
    if not content:
        return {
            'main_topics': [],
            'sentiment': 'æ— å†…å®¹',
            'complexity': 'æ— å†…å®¹',
            'language': 'æœªçŸ¥',
            'formality': 'æœªçŸ¥',
            'urgency': 'æ— ',
            'completeness': 'ä¸å®Œæ•´'
        }

    import re

    # 1. ä¸»è¦è¯é¢˜åˆ†æ
    main_topics = key_points[:3] if key_points else ['æ–‡æ¡£å†…å®¹']

    # 2. æƒ…æ„Ÿå€¾å‘åˆ†æ
    positive_words = ['æˆåŠŸ', 'ä¼˜ç§€', 'è‰¯å¥½', 'æ»¡æ„', 'èµåŒ', 'æ”¯æŒ', 'åŒæ„', 'æ‰¹å‡†', 'é€šè¿‡', 'å®Œæˆ', 'è¾¾æˆ', 'å®ç°', 'æå‡', 'æ”¹å–„', 'ä¼˜åŒ–']
    negative_words = ['å¤±è´¥', 'é—®é¢˜', 'å›°éš¾', 'æŒ‘æˆ˜', 'é£é™©', 'å»¶è¿Ÿ', 'æ¨è¿Ÿ', 'å–æ¶ˆ', 'æ‹’ç»', 'åå¯¹', 'ä¸æ»¡', 'æŠ•è¯‰', 'é”™è¯¯', 'ç¼ºé™·', 'ä¸è¶³']
    neutral_words = ['è®¨è®º', 'åˆ†æ', 'è€ƒè™‘', 'å»ºè®®', 'è®¡åˆ’', 'å®‰æ’', 'å‡†å¤‡', 'è¿›è¡Œ', 'å®æ–½', 'æ‰§è¡Œ']

    positive_count = sum(1 for word in positive_words if word in content)
    negative_count = sum(1 for word in negative_words if word in content)
    neutral_count = sum(1 for word in neutral_words if word in content)

    if positive_count > negative_count and positive_count > 0:
        sentiment = 'ç§¯æ'
    elif negative_count > positive_count and negative_count > 0:
        sentiment = 'æ¶ˆæ'
    elif neutral_count > 0:
        sentiment = 'ä¸­æ€§'
    else:
        sentiment = 'å®¢è§‚'

    # 3. å¤æ‚åº¦åˆ†æ
    word_count = len(content.split())
    sentence_count = len([s for s in re.split(r'[ã€‚ï¼ï¼Ÿ]', content) if s.strip()])
    avg_sentence_length = word_count / max(sentence_count, 1)

    # æ£€æŸ¥ä¸“ä¸šæœ¯è¯­
    technical_terms = ['ç³»ç»Ÿ', 'æ¶æ„', 'æŠ€æœ¯', 'ç®—æ³•', 'æ•°æ®åº“', 'æ¥å£', 'API', 'æ¡†æ¶', 'æ¨¡å—', 'ç»„ä»¶']
    business_terms = ['æˆ˜ç•¥', 'ç­–ç•¥', 'å¸‚åœº', 'å®¢æˆ·', 'ç”¨æˆ·', 'äº§å“', 'æœåŠ¡', 'æ”¶ç›Š', 'æˆæœ¬', 'é¢„ç®—']
    complex_terms = technical_terms + business_terms

    term_count = sum(1 for term in complex_terms if term in content)

    if word_count > 500 or avg_sentence_length > 20 or term_count > 5:
        complexity = 'å¤æ‚'
    elif word_count > 200 or avg_sentence_length > 15 or term_count > 2:
        complexity = 'ä¸­ç­‰'
    elif word_count > 50:
        complexity = 'ç®€å•'
    else:
        complexity = 'æç®€'

    # 4. è¯­è¨€ç‰¹å¾åˆ†æ
    chinese_chars = len(re.findall(r'[ä¸€-é¾¯]', content))
    total_chars = len(content)
    chinese_ratio = chinese_chars / max(total_chars, 1)

    if chinese_ratio > 0.7:
        language = 'ä¸­æ–‡ä¸ºä¸»'
    elif chinese_ratio > 0.3:
        language = 'ä¸­è‹±æ··åˆ'
    else:
        language = 'è‹±æ–‡ä¸ºä¸»'

    # 5. æ­£å¼ç¨‹åº¦åˆ†æ
    formal_words = ['æ‚¨', 'æ•¬è¯·', 'è°¨æ­¤', 'ç‰¹æ­¤', 'å…¹', 'æ®æ­¤', 'ç»¼ä¸Š', 'é‰´äº', 'åŸºäº']
    informal_words = ['ä½ ', 'å’±ä»¬', 'å¤§å®¶', 'å“ˆå“ˆ', 'å—¯', 'å‘ƒ', 'å“¦']

    formal_count = sum(1 for word in formal_words if word in content)
    informal_count = sum(1 for word in informal_words if word in content)

    if formal_count > informal_count and formal_count > 0:
        formality = 'æ­£å¼'
    elif informal_count > 0:
        formality = 'éæ­£å¼'
    else:
        formality = 'ä¸­æ€§'

    # 6. ç´§æ€¥ç¨‹åº¦åˆ†æ
    urgent_words = ['ç´§æ€¥', 'ç«‹å³', 'é©¬ä¸Š', 'å°½å¿«', 'æ€¥éœ€', 'ç«æ€¥', 'åŠ æ€¥', 'ä¼˜å…ˆ', 'é‡è¦', 'å…³é”®']
    urgent_count = sum(1 for word in urgent_words if word in content)

    if urgent_count >= 3:
        urgency = 'é«˜'
    elif urgent_count >= 1:
        urgency = 'ä¸­'
    else:
        urgency = 'ä½'

    # 7. å®Œæ•´æ€§åˆ†æ
    structure_indicators = ['ç›®æ ‡', 'èƒŒæ™¯', 'æ–¹æ¡ˆ', 'ç»“è®º', 'å»ºè®®', 'è®¡åˆ’', 'æ—¶é—´', 'è´£ä»»äºº']
    structure_count = sum(1 for indicator in structure_indicators if indicator in content)

    if structure_count >= 5:
        completeness = 'å®Œæ•´'
    elif structure_count >= 3:
        completeness = 'è¾ƒå®Œæ•´'
    elif structure_count >= 1:
        completeness = 'åŸºæœ¬å®Œæ•´'
    else:
        completeness = 'ä¸å®Œæ•´'

    return {
        'main_topics': main_topics,
        'sentiment': sentiment,
        'complexity': complexity,
        'language': language,
        'formality': formality,
        'urgency': urgency,
        'completeness': completeness,
        'word_count': word_count,
        'sentence_count': sentence_count,
        'avg_sentence_length': round(avg_sentence_length, 1)
    }

def analyze_content_gaps(content, doc_type):
    """åˆ†ææ–‡æ¡£å†…å®¹ç¼ºå¤±å’Œæ”¹è¿›ç‚¹"""
    if not content:
        return ["æ–‡æ¡£å†…å®¹ä¸ºç©ºï¼Œéœ€è¦æ·»åŠ å®è´¨æ€§å†…å®¹"]

    content_lower = content.lower()
    gaps = []

    # é€šç”¨å†…å®¹åˆ†æ
    if len(content) < 100:
        gaps.append("æ–‡æ¡£å†…å®¹è¿‡äºç®€çŸ­ï¼Œå»ºè®®è¡¥å……æ›´å¤šè¯¦ç»†ä¿¡æ¯")

    if 'ã€‚' not in content and '!' not in content and '?' not in content:
        gaps.append("å»ºè®®ä½¿ç”¨æ ‡ç‚¹ç¬¦å·æé«˜æ–‡æ¡£å¯è¯»æ€§")

    # æ£€æŸ¥æ˜¯å¦æœ‰æ ‡é¢˜ç»“æ„
    if not any(marker in content for marker in ['#', 'ä¸€ã€', '1.', 'ï¼ˆä¸€ï¼‰', 'ç¬¬ä¸€']):
        gaps.append("å»ºè®®æ·»åŠ æ¸…æ™°çš„æ ‡é¢˜å’Œç« èŠ‚ç»“æ„")

    # æ ¹æ®æ–‡æ¡£ç±»å‹è¿›è¡Œå…·ä½“åˆ†æ
    if doc_type == 'ä¼šè®®æ–‡æ¡£':
        if 'æ—¶é—´' not in content_lower and 'æ—¥æœŸ' not in content_lower:
            gaps.append("ç¼ºå°‘ä¼šè®®æ—¶é—´ä¿¡æ¯ï¼Œå»ºè®®è¡¥å……å…·ä½“çš„ä¼šè®®æ—¥æœŸå’Œæ—¶é—´")
        if 'å‚ä¼š' not in content_lower and 'å‚ä¸' not in content_lower and 'å‡ºå¸­' not in content_lower:
            gaps.append("ç¼ºå°‘å‚ä¼šäººå‘˜ä¿¡æ¯ï¼Œå»ºè®®æ˜ç¡®è®°å½•å‚ä¼šäººå‘˜åå•")
        if 'å†³ç­–' not in content_lower and 'å†³å®š' not in content_lower and 'ç»“è®º' not in content_lower:
            gaps.append("ç¼ºå°‘æ˜ç¡®çš„å†³ç­–ç»“æœï¼Œå»ºè®®è¡¥å……ä¼šè®®è¾¾æˆçš„å…·ä½“å†³ç­–")
        if 'è¡ŒåŠ¨' not in content_lower and 'æ‰§è¡Œ' not in content_lower and 'è´Ÿè´£' not in content_lower:
            gaps.append("ç¼ºå°‘åç»­è¡ŒåŠ¨è®¡åˆ’ï¼Œå»ºè®®æ˜ç¡®è´£ä»»äººå’Œæ‰§è¡Œæ—¶é—´èŠ‚ç‚¹")

    elif doc_type == 'æŠ€æœ¯æ–‡æ¡£':
        if 'æ¶æ„' not in content_lower and 'è®¾è®¡' not in content_lower:
            gaps.append("ç¼ºå°‘æŠ€æœ¯æ¶æ„è¯´æ˜ï¼Œå»ºè®®è¡¥å……ç³»ç»Ÿè®¾è®¡å’Œæ¶æ„å›¾")
        if 'api' not in content_lower and 'æ¥å£' not in content_lower:
            gaps.append("ç¼ºå°‘æ¥å£æ–‡æ¡£ï¼Œå»ºè®®è¡¥å……APIæ¥å£è¯´æ˜å’Œç¤ºä¾‹")
        if 'æµ‹è¯•' not in content_lower and 'éªŒè¯' not in content_lower:
            gaps.append("ç¼ºå°‘æµ‹è¯•è¯´æ˜ï¼Œå»ºè®®è¡¥å……æµ‹è¯•æ–¹æ³•å’ŒéªŒè¯æ­¥éª¤")

    elif doc_type == 'äº§å“æ–‡æ¡£':
        if 'ç”¨æˆ·' not in content_lower and 'å®¢æˆ·' not in content_lower:
            gaps.append("ç¼ºå°‘ç”¨æˆ·åˆ†æï¼Œå»ºè®®è¡¥å……ç›®æ ‡ç”¨æˆ·ç¾¤ä½“å’Œéœ€æ±‚åˆ†æ")
        if 'åŠŸèƒ½' not in content_lower and 'ç‰¹æ€§' not in content_lower:
            gaps.append("ç¼ºå°‘åŠŸèƒ½è¯´æ˜ï¼Œå»ºè®®è¯¦ç»†æè¿°äº§å“æ ¸å¿ƒåŠŸèƒ½")
        if 'ç«å“' not in content_lower and 'å¸‚åœº' not in content_lower:
            gaps.append("ç¼ºå°‘å¸‚åœºåˆ†æï¼Œå»ºè®®è¡¥å……ç«å“åˆ†æå’Œå¸‚åœºå®šä½")

    elif doc_type == 'åˆ†ææŠ¥å‘Š':
        if 'æ•°æ®' not in content_lower and 'ç»Ÿè®¡' not in content_lower:
            gaps.append("ç¼ºå°‘æ•°æ®æ”¯æ’‘ï¼Œå»ºè®®è¡¥å……å…·ä½“çš„æ•°æ®å’Œç»Ÿè®¡ä¿¡æ¯")
        if 'å›¾è¡¨' not in content_lower and 'å›¾' not in content_lower:
            gaps.append("ç¼ºå°‘å¯è§†åŒ–å±•ç¤ºï¼Œå»ºè®®æ·»åŠ å›¾è¡¨å’Œæ•°æ®å¯è§†åŒ–")
        if 'ç»“è®º' not in content_lower and 'å»ºè®®' not in content_lower:
            gaps.append("ç¼ºå°‘æ˜ç¡®ç»“è®ºï¼Œå»ºè®®è¡¥å……åˆ†æç»“è®ºå’Œæ”¹è¿›å»ºè®®")

    return gaps if gaps else ["æ–‡æ¡£ç»“æ„å®Œæ•´ï¼Œå»ºè®®è¿›ä¸€æ­¥ä¼˜åŒ–å†…å®¹è¡¨è¾¾å’Œæ ¼å¼è§„èŒƒ"]

def generate_improvement_suggestions(content, doc_type):
    """æ ¹æ®æ–‡æ¡£å®é™…å†…å®¹ç”Ÿæˆæ™ºèƒ½æ”¹è¿›å»ºè®®"""
    if not content:
        return ["æ–‡æ¡£å†…å®¹ä¸ºç©ºï¼Œè¯·æ·»åŠ å®è´¨æ€§å†…å®¹"]

    # åˆ†æå†…å®¹ç¼ºå¤±
    content_gaps = analyze_content_gaps(content, doc_type)

    # åˆ†æå†…å®¹è´¨é‡
    quality_suggestions = []

    # æ£€æŸ¥å†…å®¹é•¿åº¦å’Œç»“æ„
    sentences = content.replace('ã€‚', 'ã€‚\n').replace('ï¼', 'ï¼\n').replace('ï¼Ÿ', 'ï¼Ÿ\n').split('\n')
    sentences = [s.strip() for s in sentences if s.strip()]

    if len(sentences) < 3:
        quality_suggestions.append("å»ºè®®æ‰©å±•å†…å®¹ï¼Œå¢åŠ æ›´å¤šè¯¦ç»†è¯´æ˜å’ŒèƒŒæ™¯ä¿¡æ¯")

    # æ£€æŸ¥æ˜¯å¦æœ‰å…·ä½“çš„æ•°å­—ã€æ—¶é—´ç­‰å…³é”®ä¿¡æ¯
    import re
    has_numbers = bool(re.search(r'\d+', content))
    has_dates = bool(re.search(r'\d{4}å¹´|\d{1,2}æœˆ|\d{1,2}æ—¥', content))

    if not has_numbers and doc_type in ['åˆ†ææŠ¥å‘Š', 'æŠ€æœ¯æ–‡æ¡£']:
        quality_suggestions.append("å»ºè®®è¡¥å……å…·ä½“çš„æ•°å­—å’Œé‡åŒ–æŒ‡æ ‡")

    if not has_dates and doc_type in ['ä¼šè®®æ–‡æ¡£', 'åˆ†ææŠ¥å‘Š']:
        quality_suggestions.append("å»ºè®®æ·»åŠ æ˜ç¡®çš„æ—¶é—´ä¿¡æ¯å’Œæ—¶é—´èŠ‚ç‚¹")

    # æ£€æŸ¥æ˜¯å¦æœ‰è¡ŒåŠ¨å¯¼å‘çš„å†…å®¹
    action_words = ['è®¡åˆ’', 'æ‰§è¡Œ', 'å®æ–½', 'å®Œæˆ', 'è´Ÿè´£', 'å®‰æ’', 'æ¨è¿›']
    has_actions = any(word in content for word in action_words)

    if not has_actions and doc_type in ['ä¼šè®®æ–‡æ¡£', 'äº§å“æ–‡æ¡£']:
        quality_suggestions.append("å»ºè®®æ·»åŠ å…·ä½“çš„è¡ŒåŠ¨è®¡åˆ’å’Œæ‰§è¡Œæ­¥éª¤")

    # åˆå¹¶å»ºè®®å¹¶å»é‡
    all_suggestions = content_gaps + quality_suggestions

    # é™åˆ¶å»ºè®®æ•°é‡ï¼Œé€‰æ‹©æœ€é‡è¦çš„
    return all_suggestions[:6] if all_suggestions else ["æ–‡æ¡£è´¨é‡è‰¯å¥½ï¼Œå»ºè®®ç»§ç»­ä¿æŒ"]

def mock_process_document(file_path):
    """Mock document processing for testing without API."""
    print(f"ğŸ­ MOCK PROCESSING STARTED")
    print(f"ğŸ­ File path: {file_path}")

    try:
        content = ""
        file_exists = os.path.exists(file_path)
        print(f"ğŸ­ File exists: {file_exists}")

        if file_exists:
            # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©åˆé€‚çš„è¯»å–æ–¹æ³•
            try:
                file_extension = os.path.splitext(file_path)[1].lower()
                file_size = os.path.getsize(file_path)
                print(f"ğŸ­ File extension: {file_extension}")
                print(f"ğŸ­ File size: {file_size} bytes")

                if file_extension == '.docx':
                    print(f"ğŸ­ Processing Word document...")
                    # ä½¿ç”¨python-docxè¯»å–Wordæ–‡æ¡£
                    try:
                        print(f"ğŸ­ Importing python-docx...")
                        from docx import Document
                        print(f"ğŸ­ Creating Document object...")
                        doc = Document(file_path)
                        print(f"ğŸ­ Document loaded, extracting paragraphs...")
                        content_parts = []
                        paragraph_count = 0
                        for paragraph in doc.paragraphs:
                            paragraph_count += 1
                            if paragraph.text.strip():
                                content_parts.append(paragraph.text.strip())
                        print(f"ğŸ­ Found {paragraph_count} paragraphs, {len(content_parts)} with content")
                        content = '\n'.join(content_parts)
                        if not content:
                            content = "Wordæ–‡æ¡£è§£ææˆåŠŸï¼Œä½†å†…å®¹ä¸ºç©ºã€‚"
                        print(f"ğŸ­ Word document processed successfully: {len(content)} characters")
                    except Exception as docx_error:
                        print(f"âŒ Error reading DOCX file: {docx_error}")
                        print(f"âŒ Error type: {type(docx_error).__name__}")
                        import traceback
                        print(f"âŒ Traceback: {traceback.format_exc()}")
                        content = "Wordæ–‡æ¡£æ ¼å¼ï¼Œä½†è§£æå¤±è´¥ã€‚ä½¿ç”¨æ¨¡æ‹Ÿå†…å®¹è¿›è¡Œæ¼”ç¤ºã€‚"

                elif file_extension == '.pdf':
                    # ä½¿ç”¨PyPDF2è¯»å–PDFæ–‡æ¡£
                    try:
                        import PyPDF2
                        content_parts = []
                        with open(file_path, 'rb') as f:
                            reader = PyPDF2.PdfReader(f)
                            for page in reader.pages:
                                page_text = page.extract_text()
                                if page_text.strip():
                                    content_parts.append(page_text.strip())
                        content = '\n'.join(content_parts)
                        if not content:
                            content = "PDFæ–‡æ¡£è§£ææˆåŠŸï¼Œä½†å†…å®¹ä¸ºç©ºã€‚"
                    except Exception as pdf_error:
                        print(f"Error reading PDF file: {pdf_error}")
                        content = "PDFæ–‡æ¡£æ ¼å¼ï¼Œä½†è§£æå¤±è´¥ã€‚ä½¿ç”¨æ¨¡æ‹Ÿå†…å®¹è¿›è¡Œæ¼”ç¤ºã€‚"

                else:
                    # æ–‡æœ¬æ–‡ä»¶ï¼Œå°è¯•ä¸åŒçš„ç¼–ç 
                    encodings = ['utf-8', 'gbk', 'gb2312', 'latin-1']
                    for encoding in encodings:
                        try:
                            with open(file_path, 'r', encoding=encoding) as f:
                                content = f.read()
                            break
                        except UnicodeDecodeError:
                            continue

                    if not content:
                        content = "æ–‡æœ¬æ–‡ä»¶è¯»å–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå†…å®¹è¿›è¡Œæ¼”ç¤ºã€‚"

            except Exception as read_error:
                print(f"Error reading file: {read_error}")
                content = f"æ–‡ä»¶è¯»å–å¤±è´¥ ({file_extension})ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå†…å®¹è¿›è¡Œæ¼”ç¤ºã€‚"
        else:
            content = "æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå†…å®¹è¿›è¡Œæ¼”ç¤ºã€‚"

        # åˆ†ææ–‡æ¡£å†…å®¹
        lines = content.count('\n') + 1 if content else 1
        paragraphs = max(content.count('\n\n') + 1, 1) if content else 1
        characters = len(content) if content else 0

        # ä½¿ç”¨AIåˆ†æåŠŸèƒ½è¿›è¡Œæ™ºèƒ½æ–‡æ¡£åˆ†æ
        print(f"ğŸ­ Starting intelligent document analysis...")
        doc_type, scenario, key_points = analyze_document_scenario(content)
        print(f"ğŸ­ Document type identified: {doc_type}")

        # ç”Ÿæˆå†…å®¹æ‘˜è¦
        content_summary = generate_content_summary(content)
        print(f"ğŸ­ Content summary generated: {len(content_summary)} characters")

        # æå–å…³é”®å®ä½“
        entities = extract_key_entities(content)
        print(f"ğŸ­ Extracted {len(entities)} key entities")

        # ç”Ÿæˆæ”¹è¿›å»ºè®®
        improvement_suggestions = generate_improvement_suggestions(content, doc_type)
        print(f"ğŸ­ Generated {len(improvement_suggestions)} improvement suggestions")

        # ç”Ÿæˆæ™ºèƒ½å»ºè®®
        suggestions = [
            'å»ºè®®å¢åŠ æ›´å¤šå…·ä½“æ•°æ®æ”¯æ’‘',
            'å¯ä»¥æ·»åŠ å›¾è¡¨å’Œå¯è§†åŒ–å†…å®¹',
            'æ–‡æ¡£ç»“æ„å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–',
            'å»ºè®®æ·»åŠ ç›®å½•å’Œç´¢å¼•',
            'è€ƒè™‘å¢åŠ æ€»ç»“å’Œè¦ç‚¹æç‚¼'
        ]

        # æ ¹æ®æ–‡æ¡£ç±»å‹è°ƒæ•´å»ºè®®
        if doc_type == 'ä¼šè®®æ–‡æ¡£':
            suggestions = [
                'å»ºè®®æ˜ç¡®ä¼šè®®å†³ç­–å’Œè´£ä»»äºº',
                'æ·»åŠ åç»­è¡ŒåŠ¨æ—¶é—´èŠ‚ç‚¹',
                'å®Œå–„ä¼šè®®å‚ä¸è€…ä¿¡æ¯'
            ]
        elif doc_type == 'æŠ€æœ¯æ–‡æ¡£':
            suggestions = [
                'å»ºè®®æ·»åŠ æŠ€æœ¯æ¶æ„å›¾',
                'è¡¥å……æ€§èƒ½æµ‹è¯•æ•°æ®',
                'å¢åŠ ä»£ç ç¤ºä¾‹å’Œé…ç½®è¯´æ˜'
            ]

        # ç”Ÿæˆå®Œæ•´çš„AIåˆ†æç»“æœ
        print(f"ğŸ­ Generating comprehensive AI analysis result...")
        print(f"ğŸ­ Content length: {len(content)} characters")
        print(f"ğŸ­ Document type: {doc_type}")
        print(f"ğŸ­ Lines: {lines}, Paragraphs: {paragraphs}")

        result = {
            # åŸå§‹æ–‡æ¡£å†…å®¹
            'text_content': content,
            'content_summary': content_summary,

            # æ–‡æ¡£ç»“æ„ä¿¡æ¯
            'structure_info': {
                'lines': lines,
                'paragraphs': paragraphs,
                'characters': characters,
                'words': len(content.split()) if content else 0,
                'file_exists': file_exists,
                'file_readable': bool(content and content != "æ— æ³•è¯»å–æ–‡ä»¶å†…å®¹ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå†…å®¹è¿›è¡Œæ¼”ç¤ºã€‚"),
                'estimated_reading_time': f"{max(1, len(content.split()) // 200)} åˆ†é’Ÿ" if content else "0 åˆ†é’Ÿ"
            },

            # æ™ºèƒ½åœºæ™¯åˆ†æ
            'scenario_analysis': {
                'document_type': doc_type,
                'scenario': scenario,
                'key_points': key_points,
                'confidence': 0.85 if content else 0.5,
                'analysis_depth': 'comprehensive'
            },

            # å…³é”®å®ä½“æå–
            'key_entities': entities,

            # æ™ºèƒ½å†…å®¹åˆ†æ
            'content_analysis': analyze_content_depth(content, key_points),

            # æ”¹è¿›å»ºè®®
            'suggestions': improvement_suggestions,

            # è´¨é‡è¯„ä¼°
            'quality_assessment': {
                'completeness': 0.8 if len(content.split()) > 50 else 0.5,
                'clarity': 0.7,
                'structure': 0.6 if paragraphs > 1 else 0.4,
                'overall_score': 0.7,
                'areas_for_improvement': ['ç»“æ„ä¼˜åŒ–', 'å†…å®¹è¡¥å……', 'æ ¼å¼è§„èŒƒ']
            },

            # å¤„ç†çŠ¶æ€
            'processing_status': 'completed',
            'mock_mode': True,
            'processing_time': 'æ¨¡æ‹Ÿå¤„ç†æ—¶é—´: 2.3ç§’',
            'ai_features_used': [
                'æ™ºèƒ½æ–‡æ¡£åˆ†ç±»',
                'å†…å®¹æ‘˜è¦ç”Ÿæˆ',
                'å…³é”®å®ä½“æå–',
                'åœºæ™¯åˆ†æ',
                'æ”¹è¿›å»ºè®®ç”Ÿæˆ',
                'è´¨é‡è¯„ä¼°'
            ]
        }

        print(f"ğŸ­ Mock result generated successfully")
        print(f"ğŸ­ Result keys: {list(result.keys())}")
        return result

    except Exception as e:
        print(f"âŒ MOCK PROCESSING ERROR:")
        print(f"   - Error type: {type(e).__name__}")
        print(f"   - Error message: {str(e)}")
        import traceback
        print(f"   - Full traceback:")
        print(traceback.format_exc())

        # è¿”å›åŸºæœ¬çš„é”™è¯¯æ¢å¤ç»“æœ
        print(f"ğŸ­ Returning error recovery result...")
        return {
            'text_content': 'å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œè¿”å›åŸºæœ¬æ¨¡æ‹Ÿç»“æœ',
            'structure_info': {
                'lines': 1,
                'paragraphs': 1,
                'characters': 20,
                'error': str(e)
            },
            'scenario_analysis': {
                'document_type': 'é”™è¯¯æ¢å¤æ¨¡å¼',
                'scenario': 'ç³»ç»Ÿå¼‚å¸¸',
                'key_points': ['å¤„ç†å¼‚å¸¸', 'é”™è¯¯æ¢å¤'],
                'confidence': 0.1
            },
            'suggestions': [
                'è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®',
                'å°è¯•é‡æ–°ä¸Šä¼ æ–‡ä»¶',
                'è”ç³»æŠ€æœ¯æ”¯æŒ'
            ],
            'processing_status': 'error_recovery',
            'mock_mode': True,
            'error': str(e)
        }

@app.route('/')
def index():
    """Serve the main web interface."""
    return render_template('index.html')

@app.route('/demo')
def demo():
    """Serve the demo page."""
    return render_template('demo.html')

@app.route('/examples/<filename>')
def download_example(filename):
    """Download example files."""
    try:
        examples_dir = os.path.join(project_root, 'examples')
        return send_from_directory(examples_dir, filename, as_attachment=True)
    except Exception as e:
        return jsonify({'error': f'æ–‡ä»¶ä¸‹è½½å¤±è´¥: {str(e)}'}), 404

@app.route('/debug_frontend.html')
def debug_frontend():
    """Serve the debug frontend page."""
    try:
        with open('debug_frontend.html', 'r', encoding='utf-8') as f:
            content = f.read()
        return content
    except FileNotFoundError:
        return "Debug frontend page not found", 404

@app.route('/test_ai_features.html')
def test_ai_features():
    """Serve the AI features test page."""
    try:
        with open('test_ai_features.html', 'r', encoding='utf-8') as f:
            content = f.read()
        return content
    except FileNotFoundError:
        return "AI features test page not found", 404

@app.route('/api/upload', methods=['POST'])
def upload_file():
    """Handle file upload and processing."""
    with PerformanceTimer('file_upload_and_processing') as timer:
        print("=" * 80)
        print("ğŸš€ UPLOAD REQUEST RECEIVED")
        print("=" * 80)
        print(f"â° Timestamp: {datetime.now().isoformat()}")
        print(f"ğŸŒ Remote address: {request.remote_addr}")
        print(f"ğŸ”— User agent: {request.headers.get('User-Agent', 'Unknown')}")

        # æ£€æŸ¥æ˜¯å¦æ˜¯æ‰¹é‡å¤„ç†ä¸Šä¼ ï¼ˆä¸è¿›è¡Œå¤„ç†ï¼Œåªä¿å­˜æ–‡ä»¶ï¼‰
        batch_upload = request.form.get('batch_upload', 'false').lower() == 'true'
        print(f"ğŸ“¦ Batch upload mode: {batch_upload}")

        if batch_upload:
            print("ğŸ”„ Redirecting to batch upload handler")
            return handle_batch_upload()

        # Debug request information
        print(f"ğŸ“‹ Request method: {request.method}")
        print(f"ğŸ“‹ Request content type: {request.content_type}")
        print(f"ğŸ“‹ Request files: {list(request.files.keys())}")
        print(f"ğŸ“‹ Request form data: {dict(request.form)}")
        print(f"ğŸ“‹ Request headers (selected):")
        for header in ['Content-Type', 'Content-Length', 'Accept', 'Origin', 'Referer']:
            value = request.headers.get(header)
            if value:
                print(f"     {header}: {value}")

        # æ£€æŸ¥ä¸Šä¼ æ–‡ä»¶å¤¹é…ç½®
        upload_folder = app.config.get('UPLOAD_FOLDER', 'uploads')
        print(f"ğŸ“ Upload folder configured: {upload_folder}")
        print(f"ğŸ“ Upload folder exists: {os.path.exists(upload_folder)}")
        print(f"ğŸ“ Upload folder writable: {os.access(upload_folder, os.W_OK) if os.path.exists(upload_folder) else 'N/A'}")

        if 'file' not in request.files:
            print("âŒ ERROR: No file provided in request")
            return jsonify({'error': 'No file provided'}), 400

        file = request.files['file']
        if file.filename == '':
            print("âŒ ERROR: No file selected")
            return jsonify({'error': 'No file selected'}), 400

        print(f"ğŸ“„ File info:")
        print(f"   - Filename: {file.filename}")
        print(f"   - Content type: {file.content_type}")

        # Check file size
        file.seek(0, 2)  # Seek to end
        file_size = file.tell()
        file.seek(0)  # Reset to beginning
        print(f"   - File size: {file_size} bytes")

        if file_size > app.config['MAX_CONTENT_LENGTH']:
            print(f"âŒ ERROR: File size exceeds limit: {file_size} bytes")
            return jsonify({'error': 'File too large'}), 413

        if not allowed_file(file.filename):
            print(f"âŒ ERROR: File type not allowed: {file.filename}")
            return jsonify({'error': 'Unsupported file type'}), 400

        # è·å–APIç±»å‹å’Œæ¨¡å‹åç§°
        api_type = request.form.get('api_type', 'xingcheng')
        model_name = request.form.get('model_name', None)

        print(f"ğŸ”§ Processing configuration:")
        print(f"   - API type: {api_type}")
        print(f"   - Model name: {model_name}")
        
        # Generate unique filename
        filename = secure_filename(file.filename)
        unique_filename = f"{uuid.uuid4().hex}_{filename}"
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], unique_filename)
        
        print(f"Processing file: {filename}")
        print(f"File path: {filepath}")
        print(f"API type: {api_type}, Model: {model_name}")
        
        # Save file
        print(f"ğŸ’¾ Saving file to: {filepath}")
        print(f"ğŸ’¾ Directory exists: {os.path.exists(os.path.dirname(filepath))}")
        print(f"ğŸ’¾ Directory writable: {os.access(os.path.dirname(filepath), os.W_OK)}")

        try:
            file.save(filepath)
            print(f"âœ… File saved successfully")
        except Exception as save_error:
            print(f"âŒ ERROR: File save failed with exception: {save_error}")
            print(f"âŒ Exception type: {type(save_error).__name__}")
            print(f"âŒ Exception args: {save_error.args}")
            return jsonify({'error': f'File save failed: {str(save_error)}'}), 500

        # Verify file exists and is readable
        if os.path.exists(filepath):
            file_size_on_disk = os.path.getsize(filepath)
            print(f"âœ… File verified on disk: {file_size_on_disk} bytes")
            print(f"âœ… File readable: {os.access(filepath, os.R_OK)}")

            # éªŒè¯æ–‡ä»¶å†…å®¹å®Œæ•´æ€§
            if file_size_on_disk != file_size:
                print(f"âš ï¸ WARNING: File size mismatch! Original: {file_size}, On disk: {file_size_on_disk}")
            else:
                print(f"âœ… File size verification passed")
        else:
            print(f"âŒ ERROR: File not found on disk after save!")
            print(f"âŒ Attempted path: {filepath}")
            print(f"âŒ Directory listing: {os.listdir(os.path.dirname(filepath)) if os.path.exists(os.path.dirname(filepath)) else 'Directory not found'}")
            return jsonify({'error': 'File save failed - file not found on disk'}), 500

        # è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼
        import hashlib
        with open(filepath, 'rb') as f:
            file_hash = hashlib.md5(f.read()).hexdigest()

        # åˆ›å»ºæ•°æ®åº“è®°å½•
        document_record_id = None
        if document_repo is not None:
            try:
                record = DocumentRecord(
                    original_filename=filename,
                    file_path=filepath,
                    file_size=file_size_on_disk,
                    file_hash=file_hash,
                    document_type=DocumentType.GENERAL_DOCUMENT,  # ç¨åä¼šæ›´æ–°
                    intent_type=IntentType.GENERAL_PROCESSING,    # ç¨åä¼šæ›´æ–°
                    processing_status=ProcessingStatus.PROCESSING,
                    confidence_score=0.0
                )
                document_record_id = document_repo.create_document_record(record)
                print(f"ğŸ“ Created database record with ID: {document_record_id}")
            except Exception as e:
                print(f"âš ï¸ Failed to create database record: {e}")
                # ç»§ç»­å¤„ç†ï¼Œä¸å› æ•°æ®åº“é”™è¯¯ä¸­æ–­

        # Process document
        print(f"ğŸ”„ Starting document processing...")
        try:
            # æ£€æŸ¥æ˜¯å¦æ˜ç¡®é€‰æ‹©äº†æ¨¡æ‹Ÿæ¨¡å¼
            if api_type == 'mock':
                print("ğŸ­ Using explicit mock processing mode")
                print(f"ğŸ­ Calling mock_process_document with: {filepath}")
                result = mock_process_document(file_path=filepath)
                print(f"ğŸ­ Mock processing returned: {type(result)}")
                if isinstance(result, dict):
                    print(f"ğŸ­ Result keys: {list(result.keys())}")
                    if 'error' in result:
                        print(f"âŒ Mock processing error: {result['error']}")
                else:
                    print(f"âŒ Unexpected result type: {type(result)}")
            else:
                print(f"ğŸŒ Initializing real API: {api_type}")
                orchestrator = initialize_agent(api_type, model_name)

                if orchestrator is None:
                    # ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ä½œä¸ºå›é€€
                    print("ğŸ­ API not available, using mock processing mode as fallback")
                    result = mock_process_document(file_path=filepath)
                else:
                    # ä½¿ç”¨çœŸå®API
                    print("ğŸŒ Using real API processing")
                    result = orchestrator.process_document(file_path=filepath)

            # è¯¦ç»†æ£€æŸ¥å¤„ç†ç»“æœ
            print(f"ğŸ“Š Processing result analysis:")
            print(f"   - Result type: {type(result)}")
            if isinstance(result, dict):
                print(f"   - Result keys: {list(result.keys())}")
                status = result.get('processing_status', 'unknown')
                mock_mode = result.get('mock_mode', False)
                error = result.get('error', None)
                print(f"   - Status: {status}")
                print(f"   - Mock mode: {mock_mode}")
                if error:
                    print(f"   - Error: {error}")

                # Check if result has required fields
                required_fields = ['text_content', 'structure_info', 'scenario_analysis']
                missing_fields = [field for field in required_fields if field not in result]
                if missing_fields:
                    print(f"âš ï¸  Missing required fields: {missing_fields}")
            else:
                print(f"âŒ Result is not a dictionary: {result}")

            print(f"âœ… Processing completed successfully")

            # æ›´æ–°æ•°æ®åº“è®°å½•
            if document_record_id is not None and document_repo is not None:
                try:
                    # ä»ç»“æœä¸­æå–ä¿¡æ¯æ›´æ–°è®°å½•
                    processing_time_ms = 0  # å¯ä»¥è®¡ç®—å®é™…å¤„ç†æ—¶é—´
                    confidence_score = 0.8  # é»˜è®¤ç½®ä¿¡åº¦ï¼Œå¯ä»¥ä»ç»“æœä¸­æå–

                    if isinstance(result, dict):
                        # å°è¯•ä»ç»“æœä¸­æå–ç½®ä¿¡åº¦
                        scenario_analysis = result.get('scenario_analysis', {})
                        if isinstance(scenario_analysis, dict):
                            confidence_score = scenario_analysis.get('confidence', 0.8)

                    # æ›´æ–°å¤„ç†çŠ¶æ€ä¸ºå®Œæˆ
                    document_repo.update_processing_status(
                        document_record_id,
                        ProcessingStatus.COMPLETED,
                        processing_time_ms=processing_time_ms
                    )
                    print(f"ğŸ“ Updated database record {document_record_id} to completed")
                except Exception as e:
                    print(f"âš ï¸ Failed to update database record: {e}")

            # Clean up uploaded file
            print(f"ğŸ§¹ Cleaning up file: {filepath}")
            if os.path.exists(filepath):
                os.remove(filepath)
                print(f"âœ… File cleaned up successfully")
            else:
                print(f"âš ï¸ File not found for cleanup: {filepath}")

            # Prepare response
            response_data = {
                'file_id': unique_filename,
                'analysis': {
                    'document_type': result.get('scenario_analysis', {}).get('document_type', 'é€šç”¨æ–‡æ¡£'),
                    'key_entities': result.get('key_entities', [])
                },
                'success': True,
                'result': result,
                'filename': filename,
                'processed_at': datetime.now().isoformat(),
                'api_type': api_type,
                'model_name': model_name
            }

            print(f"ğŸ“¤ Preparing JSON response:")
            print(f"   - Success: {response_data['success']}")
            print(f"   - Filename: {response_data['filename']}")
            print(f"   - API type: {response_data['api_type']}")
            print(f"   - Result type: {type(response_data['result'])}")

            # Try to serialize to JSON to catch any issues
            try:
                import json
                json_str = json.dumps(response_data, ensure_ascii=False, default=str)
                print(f"âœ… JSON serialization successful: {len(json_str)} characters")
            except Exception as json_error:
                print(f"âŒ JSON serialization failed: {json_error}")
                return jsonify({'error': f'Response serialization failed: {str(json_error)}'}), 500

            print(f"ğŸ‰ Returning successful response")
            print("=" * 80)
            return jsonify(response_data)
            
        except Exception as e:
            print(f"âŒ PROCESSING ERROR OCCURRED:")
            print(f"   - Error type: {type(e).__name__}")
            print(f"   - Error message: {str(e)}")
            print(f"   - Full traceback:")
            print(traceback.format_exc())

            # æ›´æ–°æ•°æ®åº“è®°å½•ä¸ºå¤±è´¥çŠ¶æ€
            if document_record_id is not None and document_repo is not None:
                try:
                    document_repo.update_processing_status(
                        document_record_id,
                        ProcessingStatus.FAILED,
                        error_message=str(e)
                    )
                    print(f"ğŸ“ Updated database record {document_record_id} to failed")
                except Exception as db_error:
                    print(f"âš ï¸ Failed to update database record: {db_error}")

            # Clean up file on error
            if os.path.exists(filepath):
                print(f"ğŸ§¹ Cleaning up file after error: {filepath}")
                os.remove(filepath)
                print(f"âœ… File cleaned up after error")
            else:
                print(f"âš ï¸ File not found for cleanup after error: {filepath}")
            
            # å¦‚æœæ˜¯ç½‘ç»œé”™è¯¯ï¼Œå°è¯•ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼
            if "timeout" in str(e).lower() or "connection" in str(e).lower() or "network" in str(e).lower():
                print("Network error detected, trying mock mode")
                try:
                    # é‡æ–°è¯»å–æ–‡ä»¶å†…å®¹è¿›è¡Œæ¨¡æ‹Ÿå¤„ç†
                    if os.path.exists(filepath):
                        result = mock_process_document(file_path=filepath)
                    else:
                        # å¦‚æœæ–‡ä»¶å·²è¢«åˆ é™¤ï¼Œåˆ›å»ºä¸€ä¸ªåŸºæœ¬çš„æ¨¡æ‹Ÿç»“æœ
                        result = {
                            'text_content': 'Mock content for network error fallback',
                            'structure_info': {'lines': 1, 'paragraphs': 1, 'characters': 40},
                            'scenario_analysis': {
                                'document_type': 'é€šç”¨æ–‡æ¡£',
                                'scenario': 'ç½‘ç»œé”™è¯¯å›é€€æ¨¡å¼',
                                'key_points': ['ç½‘ç»œè¿æ¥é—®é¢˜', 'ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼'],
                                'confidence': 0.5
                            },
                            'suggestions': ['æ£€æŸ¥ç½‘ç»œè¿æ¥', 'ç¨åé‡è¯•'],
                            'processing_status': 'completed_with_fallback',
                            'mock_mode': True,
                            'fallback_reason': 'network_error'
                        }

                    return jsonify({
                        'success': True,
                        'result': result,
                        'filename': filename,
                        'processed_at': datetime.now().isoformat(),
                        'note': 'Used mock mode due to network issues',
                        'api_type': 'mock_fallback',
                        'model_name': 'fallback'
                    })
                except Exception as mock_error:
                    return jsonify({'error': f'Processing failed: {str(e)} (Mock mode also failed: {str(mock_error)})'}), 500
            
            return jsonify({'error': f'Processing failed: {str(e)}'}), 500

@app.route('/api/health')
def health_check():
    """Health check endpoint."""
    try:
        # Test different API types
        api_status = {}
        
        # Test Xingcheng API
        try:
            orchestrator = initialize_agent("xingcheng")
            api_status['xingcheng'] = {
                'status': 'available' if orchestrator else 'unavailable',
                'mock_mode': orchestrator is None
            }
        except Exception as e:
            api_status['xingcheng'] = {'status': 'error', 'error': str(e)}
        
        # Test Multi API
        try:
            orchestrator = initialize_agent("multi")
            api_status['multi'] = {
                'status': 'available' if orchestrator else 'unavailable',
                'mock_mode': orchestrator is None
            }
        except Exception as e:
            api_status['multi'] = {'status': 'error', 'error': str(e)}
        
        return jsonify({
            'status': 'healthy',
            'api_status': api_status,
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({
            'status': 'unhealthy',
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500

@app.route('/api/config')
def get_config():
    """Get current configuration (without sensitive data)."""
    return jsonify({
        'allowed_extensions': list(app.config['ALLOWED_EXTENSIONS']),
        'max_file_size_mb': app.config['MAX_CONTENT_LENGTH'] // (1024 * 1024),
        'api_types': ['xingcheng', 'multi', 'mock'],
        'xingcheng_configured': bool(os.getenv("XINGCHENG_API_KEY")),
        'qiniu_configured': bool(os.getenv("QINIU_API_KEY")),
        'together_configured': bool(os.getenv("TOGETHER_API_KEY")),
        'openrouter_configured': bool(os.getenv("OPENROUTER_API_KEY")),
        'mock_mode_available': True,
        'format_alignment_available': True,
        'document_fill_available': True
    })

@app.route('/api/format-alignment', methods=['POST'])
def format_alignment():
    """å¤„ç†æ–‡æ¡£æ ¼å¼å¯¹é½è¯·æ±‚"""
    with PerformanceTimer('format_alignment') as timer:
        global format_coordinator

        try:
            if format_coordinator is None:
                format_coordinator = FormatAlignmentCoordinator()

            data = request.get_json()
            # æ–°å¢ï¼šæ”¯æŒ data_sources ç»“æ„
            data_sources = data.get('data_sources')
            if data_sources:
                # è‡ªåŠ¨æå–ä¸»è¦å†…å®¹
                user_input = ''
                uploaded_files = {}
                image_files = {}
                for item in data_sources:
                    if item.get('type') == 'text' and not user_input:
                        user_input = item.get('content', '')
                    if item.get('type') == 'file':
                        mime = item.get('mime', '')
                        if mime.startswith('image/') and item.get('content'):
                            # å¤„ç† base64 å›¾ç‰‡
                            header, b64data = item['content'].split(',', 1) if ',' in item['content'] else ('', item['content'])
                            binary = base64.b64decode(b64data)
                            tmp_dir = tempfile.gettempdir()
                            img_path = os.path.join(tmp_dir, item.get('name','uploaded_image'))
                            with open(img_path, 'wb') as f:
                                f.write(binary)
                            image_files[item.get('name','file')] = img_path
                        else:
                            uploaded_files[item.get('name','file')] = item.get('content','')
                # å¯å°† image_files åˆå¹¶åˆ° uploaded_files æˆ–å•ç‹¬å¤„ç†
                uploaded_files.update(image_files)
            else:
                user_input = data.get('user_input', '')
                uploaded_files = data.get('uploaded_files', {})

            result = format_coordinator.process_user_request(user_input, uploaded_files)
            return jsonify(result)

        except Exception as e:
            return jsonify({'error': f'æ ¼å¼å¯¹é½å¤„ç†å¤±è´¥: {str(e)}'}), 500

@app.route('/api/format-templates', methods=['GET'])
def list_format_templates():
    """è·å–æ‰€æœ‰æ ¼å¼æ¨¡æ¿"""
    global format_coordinator

    try:
        if format_coordinator is None:
            format_coordinator = FormatAlignmentCoordinator()

        templates = format_coordinator.format_extractor.list_format_templates()

        return jsonify({
            'success': True,
            'templates': templates,
            'count': len(templates)
        })

    except Exception as e:
        return jsonify({'error': f'è·å–æ¨¡æ¿åˆ—è¡¨å¤±è´¥: {str(e)}'}), 500

@app.route('/api/format-templates/<template_id>', methods=['GET'])
def get_format_template(template_id):
    """è·å–ç‰¹å®šæ ¼å¼æ¨¡æ¿"""
    global format_coordinator

    try:
        if format_coordinator is None:
            format_coordinator = FormatAlignmentCoordinator()

        template_data = format_coordinator.format_extractor.load_format_template(template_id)

        if 'error' in template_data:
            return jsonify(template_data), 404

        return jsonify({
            'success': True,
            'template': template_data
        })

    except Exception as e:
        return jsonify({'error': f'è·å–æ¨¡æ¿å¤±è´¥: {str(e)}'}), 500

@app.route('/api/format-templates', methods=['POST'])
def save_format_template():
    """ä¿å­˜æ ¼å¼æ¨¡æ¿"""
    global format_coordinator

    try:
        if format_coordinator is None:
            format_coordinator = FormatAlignmentCoordinator()
            print("Format coordinator initialized")

        data = request.get_json()
        if not data:
            print("Error: No JSON data received in request")
            return jsonify({'error': 'è¯·æ±‚ä¸­æ²¡æœ‰æä¾›æ•°æ®'}), 400

        template_name = data.get('template_name', '')
        template_data = data.get('template_data', {})

        if not template_name or not template_data:
            print(f"Error: Missing template name or data. Name: {template_name}, Data: {bool(template_data)}")
            return jsonify({'error': 'ç¼ºå°‘æ¨¡æ¿åç§°æˆ–æ•°æ®'}), 400

        print(f"Saving format template with name: {template_name}")
        result = format_coordinator.format_extractor.save_format_template(template_name, template_data)

        if 'error' in result:
            print(f"Error in save_format_template result: {result['error']}")
            return jsonify(result), 500

        print(f"Format template saved successfully with ID: {result.get('template_id', 'N/A')}")
        return jsonify({
            'success': True,
            'template_id': result.get('template_id', ''),
            'message': 'æ ¼å¼æ¨¡æ¿ä¿å­˜æˆåŠŸ'
        })

    except Exception as e:
        print(f"Error saving format template: {str(e)}")
        print(f"Stack trace: {traceback.format_exc()}")
        return jsonify({'error': f'ä¿å­˜æ¨¡æ¿å¤±è´¥: {str(e)}'}), 500

@app.route('/api/format-templates/<template_id>/apply', methods=['POST'])
def apply_format_template(template_id):
    """åº”ç”¨æ ¼å¼æ¨¡æ¿åˆ°æ–‡æ¡£"""
    global format_coordinator

    try:
        if format_coordinator is None:
            format_coordinator = FormatAlignmentCoordinator()

        data = request.get_json()
        document_name = data.get('document_name', '')
        document_content = data.get('document_content', '')

        if not document_name or not document_content:
            return jsonify({'error': 'ç¼ºå°‘æ–‡æ¡£åç§°æˆ–å†…å®¹'}), 400

        # æ·»åŠ æ–‡æ¡£åˆ°ä¼šè¯
        format_coordinator.add_document(document_name, document_content)

        # åº”ç”¨æ¨¡æ¿
        result = format_coordinator.use_saved_template(template_id, document_name)

        return jsonify(result)

    except Exception as e:
        return jsonify({'error': f'åº”ç”¨æ¨¡æ¿å¤±è´¥: {str(e)}'}), 500

@app.route('/api/format-alignment/preview/<session_id>')
def preview_formatted_document(session_id):
    """é¢„è§ˆæ ¼å¼å¯¹é½åçš„æ–‡æ¡£"""
    try:
        # è·å–æ ¼å¼å¯¹é½ç»“æœ
        result = format_aligner.get_format_result(session_id)
        if not result:
            return "No content to preview", 404
        
        # ç”ŸæˆSVGå›¾ç‰‡å¹¶æ’å…¥æ–‡æ¡£
        if image_processor:
            # ä¸ºæ–‡æ¡£ç”ŸæˆAI SVG
            svg_result = image_processor.generate_ai_svg_for_document(
                document_type="general",
                content_description="æ ¼å¼å¯¹é½é¢„è§ˆæ–‡æ¡£",
                svg_size=(400, 300)
            )
            
            if svg_result.get("success"):
                # æ’å…¥SVGåˆ°æ–‡æ¡£ï¼ˆé¢„è§ˆæ¨¡å¼ï¼‰
                document_content = result.get("formatted_content", "")
                target_position = {"line_number": 1, "document_type": "general"}
                updated_content = image_processor.insert_svg_to_document(
                    document_content, svg_result, target_position, mode="preview"
                )
                result["formatted_content"] = updated_content
                result["svg_info"] = svg_result
        
        html_content = result.get("formatted_content", "")
        return html_content
        
    except Exception as e:
        return f"Preview error: {str(e)}", 500

@app.route('/api/models')
def get_available_models():
    """Get available models for each API type."""
    try:
        # è·å–å¤šAPIå®¢æˆ·ç«¯çš„å¯ç”¨æ¨¡å‹
        multi_client = MultiLLMClient()
        available_models = multi_client.get_available_models()
        
        models_by_api = {
            'xingcheng': ['x1', 'x2', 'x3'],
            'multi': available_models,
            'mock': ['mock-model']
        }
        
        return jsonify({
            'models': models_by_api,
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({
            'error': str(e),
            'models': {
                'xingcheng': ['x1'],
                'mock': ['mock-model']
            }
        }), 500

@app.route('/api/document-fill/start', methods=['POST'])
def start_document_fill():
    """å¼€å§‹æ–‡æ¡£å¡«å……æµç¨‹"""
    with PerformanceTimer('document_fill_start') as timer:
        global fill_coordinator

        try:
            if fill_coordinator is None:
                fill_coordinator = DocumentFillCoordinator()

            data = request.get_json()
            document_content = data.get('document_content', '')
            document_name = data.get('document_name', '')

            if not document_content:
                return jsonify({'error': 'ç¼ºå°‘æ–‡æ¡£å†…å®¹'}), 400

            result = fill_coordinator.start_document_fill(document_content, document_name)

            return jsonify(result)

        except Exception as e:
            return jsonify({'error': f'å¯åŠ¨æ–‡æ¡£å¡«å……å¤±è´¥: {str(e)}'}), 500

@app.route('/api/document-fill/respond', methods=['POST'])
def respond_to_fill_question():
    """å“åº”æ–‡æ¡£å¡«å……é—®é¢˜"""
    with PerformanceTimer('document_fill_respond') as timer:
        global fill_coordinator

        try:
            if fill_coordinator is None:
                return jsonify({'error': 'æ–‡æ¡£å¡«å……ä¼šè¯æœªåˆå§‹åŒ–'}), 400

            data = request.get_json()
            user_input = data.get('user_input', '')

            if not user_input:
                return jsonify({'error': 'ç¼ºå°‘ç”¨æˆ·è¾“å…¥'}), 400

            result = fill_coordinator.process_user_response(user_input)

            return jsonify(result)

        except Exception as e:
            return jsonify({'error': f'å¤„ç†ç”¨æˆ·å›å¤å¤±è´¥: {str(e)}'}), 500

@app.route('/api/document-fill/status', methods=['GET'])
def get_fill_status():
    """è·å–æ–‡æ¡£å¡«å……çŠ¶æ€"""
    global fill_coordinator

    try:
        if fill_coordinator is None:
            return jsonify({'error': 'æ–‡æ¡£å¡«å……ä¼šè¯æœªåˆå§‹åŒ–'}), 400

        status = fill_coordinator.get_session_status()

        return jsonify({
            'success': True,
            'status': status
        })

    except Exception as e:
        return jsonify({'error': f'è·å–çŠ¶æ€å¤±è´¥: {str(e)}'}), 500

@app.route('/api/document-fill/result', methods=['GET'])
def get_fill_result():
    """è·å–æ–‡æ¡£å¡«å……ç»“æœ"""
    global fill_coordinator

    try:
        if fill_coordinator is None:
            return jsonify({'error': 'æ–‡æ¡£å¡«å……ä¼šè¯æœªåˆå§‹åŒ–'}), 400

        result = fill_coordinator.get_fill_result()

        if not result:
            return jsonify({'error': 'å¡«å……ç»“æœä¸å¯ç”¨'}), 404

        return jsonify({
            'success': True,
            'result': result
        })

    except Exception as e:
        return jsonify({'error': f'è·å–å¡«å……ç»“æœå¤±è´¥: {str(e)}'}), 500

@app.route('/api/document-fill/download', methods=['GET'])
def download_filled_document():
    """ä¸‹è½½å¡«å……åçš„æ–‡æ¡£"""
    global fill_coordinator

    try:
        if fill_coordinator is None:
            return jsonify({'error': 'æ–‡æ¡£å¡«å……ä¼šè¯æœªåˆå§‹åŒ–'}), 400

        result = fill_coordinator.get_fill_result()

        if not result or not result.get('html_content'):
            return jsonify({'error': 'å¡«å……ç»“æœä¸å¯ç”¨'}), 404

        html_content = result['html_content']

        # åˆ›å»ºå“åº”
        from flask import make_response
        response = make_response(html_content)
        response.headers['Content-Type'] = 'text/html; charset=utf-8'
        response.headers['Content-Disposition'] = 'attachment; filename=filled_document.html'

        return response

    except Exception as e:
        return jsonify({'error': f'ä¸‹è½½å¤±è´¥: {str(e)}'}), 500

@app.route('/api/document-fill/add-material', methods=['POST'])
def add_supplementary_material():
    """æ·»åŠ è¡¥å……ææ–™"""
    global fill_coordinator

    try:
        if fill_coordinator is None:
            return jsonify({'error': 'æ–‡æ¡£å¡«å……ä¼šè¯æœªåˆå§‹åŒ–'}), 400

        data = request.get_json()
        material_name = data.get('material_name', '')
        material_content = data.get('material_content', '')

        if not material_name or not material_content:
            return jsonify({'error': 'ç¼ºå°‘ææ–™åç§°æˆ–å†…å®¹'}), 400

        result = fill_coordinator.add_supplementary_material(material_name, material_content)

        return jsonify(result)

    except Exception as e:
        return jsonify({'error': f'æ·»åŠ è¡¥å……ææ–™å¤±è´¥: {str(e)}'}), 500

@app.route('/api/writing-style/analyze', methods=['POST'])
def analyze_writing_style():
    """åˆ†ææ–‡æ¡£å†™ä½œé£æ ¼"""
    with PerformanceTimer('writing_style_analyze') as timer:
        global style_analyzer

        try:
            if style_analyzer is None:
                style_analyzer = WritingStyleAnalyzer()

            data = request.get_json()
            document_content = data.get('document_content', '')
            document_name = data.get('document_name', '')

            if not document_content:
                return jsonify({'error': 'ç¼ºå°‘æ–‡æ¡£å†…å®¹'}), 400

            result = style_analyzer.analyze_writing_style(document_content, document_name)

            return jsonify(result)

        except Exception as e:
            return jsonify({'error': f'æ–‡é£åˆ†æå¤±è´¥: {str(e)}'}), 500

@app.route('/api/writing-style/save-template', methods=['POST'])
def save_writing_style_template():
    """ä¿å­˜æ–‡é£æ¨¡æ¿"""
    global style_analyzer, fill_coordinator

    try:
        if style_analyzer is None:
            style_analyzer = WritingStyleAnalyzer()

        data = request.get_json()
        reference_content = data.get('reference_content', '')
        reference_name = data.get('reference_name', '')

        if not reference_content:
            return jsonify({'error': 'ç¼ºå°‘å‚è€ƒæ–‡æ¡£å†…å®¹'}), 400

        # å¦‚æœæœ‰æ´»è·ƒçš„å¡«å……ä¼šè¯ï¼Œä½¿ç”¨ä¼šè¯ä¸­çš„æ–¹æ³•
        if fill_coordinator is not None:
            result = fill_coordinator.analyze_and_save_writing_style(reference_content, reference_name)
        else:
            # ç›´æ¥ä½¿ç”¨åˆ†æå™¨
            analysis_result = style_analyzer.analyze_writing_style(reference_content, reference_name)
            if "error" in analysis_result:
                return jsonify(analysis_result), 500

            result = style_analyzer.save_style_template(analysis_result)

        return jsonify(result)

    except Exception as e:
        return jsonify({'error': f'ä¿å­˜æ–‡é£æ¨¡æ¿å¤±è´¥: {str(e)}'}), 500

@app.route('/api/writing-style/templates', methods=['GET'])
def list_writing_style_templates():
    """è·å–æ‰€æœ‰æ–‡é£æ¨¡æ¿"""
    global style_analyzer

    try:
        if style_analyzer is None:
            style_analyzer = WritingStyleAnalyzer()

        templates = style_analyzer.list_style_templates()

        return jsonify({
            'success': True,
            'templates': templates,
            'count': len(templates)
        })

    except Exception as e:
        return jsonify({'error': f'è·å–æ–‡é£æ¨¡æ¿åˆ—è¡¨å¤±è´¥: {str(e)}'}), 500

@app.route('/api/writing-style/templates/<template_id>', methods=['GET'])
def get_writing_style_template(template_id):
    """è·å–ç‰¹å®šæ–‡é£æ¨¡æ¿"""
    global style_analyzer

    try:
        if style_analyzer is None:
            style_analyzer = WritingStyleAnalyzer()

        template_data = style_analyzer.load_style_template(template_id)

        if 'error' in template_data:
            return jsonify(template_data), 404

        return jsonify({
            'success': True,
            'template': template_data
        })

    except Exception as e:
        return jsonify({'error': f'è·å–æ–‡é£æ¨¡æ¿å¤±è´¥: {str(e)}'}), 500

@app.route('/api/document-fill/set-style', methods=['POST'])
def set_writing_style_template():
    """è®¾ç½®æ–‡æ¡£å¡«å……çš„æ–‡é£æ¨¡æ¿"""
    global fill_coordinator

    try:
        if fill_coordinator is None:
            return jsonify({'error': 'æ–‡æ¡£å¡«å……ä¼šè¯æœªåˆå§‹åŒ–'}), 400

        data = request.get_json()
        template_id = data.get('template_id', '')

        if not template_id:
            return jsonify({'error': 'ç¼ºå°‘æ¨¡æ¿ID'}), 400

        result = fill_coordinator.set_writing_style_template(template_id)

        return jsonify(result)

    except Exception as e:
        return jsonify({'error': f'è®¾ç½®æ–‡é£æ¨¡æ¿å¤±è´¥: {str(e)}'}), 500

# é£æ ¼å¯¹é½ç›¸å…³APIç«¯ç‚¹
@app.route('/api/style-alignment/preview', methods=['POST'])
def preview_style_changes():
    """é¢„è§ˆæ–‡é£å˜åŒ–"""
    global style_analyzer

    try:
        if style_analyzer is None:
            style_analyzer = WritingStyleAnalyzer()
            print("Style analyzer initialized")

        data = request.get_json()
        if not data:
            print("Error: No JSON data received in request for style preview")
            return jsonify({'error': 'è¯·æ±‚ä¸­æ²¡æœ‰æä¾›æ•°æ®'}), 400

        # æ–°å¢ï¼šæ”¯æŒ data_sources ç»“æ„
        data_sources = data.get('data_sources')
        if data_sources:
            document_content = ''
            document_name = ''
            style_template_id = ''
            image_files = {}
            for item in data_sources:
                if item.get('type') == 'text' and not document_content:
                    document_content = item.get('content', '')
                    document_name = item.get('name', '')
                if item.get('type') == 'style_template_id':
                    style_template_id = item.get('content', '')
                if item.get('type') == 'file':
                    mime = item.get('mime', '')
                    if mime.startswith('image/') and item.get('content'):
                        header, b64data = item['content'].split(',', 1) if ',' in item['content'] else ('', item['content'])
                        binary = base64.b64decode(b64data)
                        tmp_dir = tempfile.gettempdir()
                        img_path = os.path.join(tmp_dir, item.get('name','uploaded_image'))
                        with open(img_path, 'wb') as f:
                            f.write(binary)
                        image_files[item.get('name','file')] = img_path
            # å¯å°† image_files è·¯å¾„ä¼ é€’ç»™åç»­åˆ†æé€»è¾‘
        else:
            document_content = data.get('document_content', '')
            document_name = data.get('document_name', '')
            style_template_id = data.get('style_template_id', '')

        if not document_content or not style_template_id:
            print(f"Error: Missing document content or style template ID. Content: {bool(document_content)}, Template ID: {style_template_id}")
            return jsonify({'error': 'ç¼ºå°‘æ–‡æ¡£å†…å®¹æˆ–æ–‡é£æ¨¡æ¿ID'}), 400

        print(f"Analyzing writing style for document: {document_name}")
        # åˆ†ææ–‡æ¡£å¹¶åº”ç”¨æ–‡é£æ¨¡æ¿ä»¥ç”Ÿæˆé¢„è§ˆ
        analysis_result = style_analyzer.analyze_writing_style(document_content, document_name)
        if "error" in analysis_result:
            print(f"Error in writing style analysis: {analysis_result['error']}")
            return jsonify(analysis_result), 500

        print(f"Generating style preview with template ID: {style_template_id}")
        # ä¿®æ­£ï¼šå…¼å®¹ generate_style_preview æ–¹æ³•
        if hasattr(style_analyzer, 'generate_style_preview'):
            preview_data = style_analyzer.generate_style_preview(analysis_result, style_template_id)
        else:
            return jsonify({'error': 'åç«¯æœªå®ç° generate_style_preview æ–¹æ³•'}), 500
        if "error" in preview_data:
            print(f"Error in style preview generation: {preview_data['error']}")
            return jsonify(preview_data), 500

        print("Style preview generated successfully")
        return jsonify({
            'success': True,
            'preview_data': preview_data,
            'session_id': preview_data.get('session_id', str(uuid.uuid4()))
        })

    except Exception as e:
        print(f"Error previewing style changes: {str(e)}")
        print(f"Stack trace: {traceback.format_exc()}")
        return jsonify({'error': f'é¢„è§ˆæ–‡é£å˜åŒ–å¤±è´¥: {str(e)}'}), 500

@app.route('/api/style-alignment/changes/<session_id>/<change_id>', methods=['PATCH'])
def handle_individual_change(session_id, change_id):
    """æ¥å—æˆ–æ‹’ç»å•ä¸ªæ–‡é£å˜åŒ–"""
    global style_analyzer

    try:
        if style_analyzer is None:
            return jsonify({'error': 'æ–‡é£åˆ†æå™¨æœªåˆå§‹åŒ–'}), 400

        data = request.get_json()
        action = data.get('action', '')

        if action not in ['accept', 'reject']:
            return jsonify({'error': 'æ— æ•ˆçš„æ“ä½œï¼Œå¿…é¡»æ˜¯acceptæˆ–reject'}), 400

        result = style_analyzer.handle_style_change(session_id, change_id, action)
        if "error" in result:
            return jsonify(result), 404

        return jsonify({
            'success': True,
            'change_id': change_id,
            'action': action,
            'updated_preview': result.get('updated_preview', {})
        })

    except Exception as e:
        return jsonify({'error': f'å¤„ç†æ–‡é£å˜åŒ–å¤±è´¥: {str(e)}'}), 500

@app.route('/api/style-alignment/changes/<session_id>/batch', methods=['PATCH'])
def handle_batch_changes(session_id):
    """æ‰¹é‡æ¥å—æˆ–æ‹’ç»æ‰€æœ‰æ–‡é£å˜åŒ–"""
    global style_analyzer

    try:
        if style_analyzer is None:
            return jsonify({'error': 'æ–‡é£åˆ†æå™¨æœªåˆå§‹åŒ–'}), 400

        data = request.get_json()
        if not data:
            return jsonify({'error': 'è¯·æ±‚ä¸­æ²¡æœ‰æä¾›æ•°æ®'}), 400

        action = data.get('action', '')

        if action not in ['accept_all', 'reject_all']:
            return jsonify({'error': 'æ— æ•ˆçš„æ“ä½œï¼Œå¿…é¡»æ˜¯accept_allæˆ–reject_all'}), 400

        if session_id == 'null':
            return jsonify({'error': 'æ— æ•ˆçš„ä¼šè¯ID'}), 400

        result = style_analyzer.handle_batch_style_changes(session_id, action)
        if "error" in result:
            return jsonify(result), 404

        return jsonify({
            'success': True,
            'action': action,
            'change_count': result.get('change_count', 0)
        })

    except Exception as e:
        print(f"Error handling batch style changes: {e}")
        return jsonify({'error': f'æ‰¹é‡å¤„ç†æ–‡é£å˜åŒ–å¤±è´¥: {str(e)}'}), 500

@app.route('/api/style-alignment/export/<session_id>', methods=['GET'])
def export_styled_document(session_id):
    """å¯¼å‡ºåº”ç”¨äº†æ–‡é£å˜åŒ–çš„æ–‡æ¡£"""
    global style_analyzer

    try:
        if style_analyzer is None:
            return jsonify({'error': 'æ–‡é£åˆ†æå™¨æœªåˆå§‹åŒ–'}), 400

        # è°ƒç”¨çœŸæ­£çš„å¯¼å‡ºåŠŸèƒ½
        result = style_analyzer.export_styled_document(session_id)
        if "error" in result:
            return jsonify(result), 404

        from flask import make_response
        
        # ç”ŸæˆSVGå›¾ç‰‡å¹¶æ’å…¥å¯¼å‡ºæ–‡æ¡£
        if image_processor:
            svg_result = image_processor.generate_ai_svg_for_document(
                document_type="style_export",
                content_description="æ–‡é£è°ƒæ•´å¯¼å‡ºæ–‡æ¡£",
                svg_size=(400, 300)
            )
            
            if svg_result.get("success"):
                # æ’å…¥SVGåˆ°å¯¼å‡ºå†…å®¹ï¼ˆä¸‹è½½æ¨¡å¼ï¼‰
                if "html_content" in result:
                    target_position = {"line_number": 1, "document_type": "style_export"}
                    updated_content = image_processor.insert_svg_to_document(
                        result["html_content"], svg_result, target_position, mode="download"
                    )
                    result["html_content"] = updated_content
                    result["svg_info"] = svg_result
        
        # æ ¹æ®è¿”å›ç±»å‹è®¾ç½®å“åº”
        if "docx_content" in result:
            # Wordæ–‡æ¡£
            response = make_response(result['docx_content'])
            response.headers['Content-Type'] = 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
            response.headers['Content-Disposition'] = f'attachment; filename={result.get("filename", "styled_document.docx")}'
            return response
        elif "html_content" in result:
            # HTMLæ–‡æ¡£
            response = make_response(result['html_content'])
            response.headers['Content-Type'] = 'text/html'
            response.headers['Content-Disposition'] = f'attachment; filename={result.get("filename", "styled_document.html")}'
            return response
        else:
            return jsonify(result)

    except Exception as e:
        return jsonify({'error': f'å¯¼å‡ºå¤±è´¥: {str(e)}'}), 500

# æ™ºèƒ½å¡«æŠ¥è‡ªåŠ¨åŒ¹é…æ•°æ®ç›¸å…³APIç«¯ç‚¹
@app.route('/api/document-fill/auto-match', methods=['POST'])
def auto_match_data():
    """è‡ªåŠ¨åŒ¹é…æ•°æ®åˆ°æ–‡æ¡£å­—æ®µ"""
    global fill_coordinator

    try:
        if fill_coordinator is None:
            return jsonify({'error': 'æ–‡æ¡£å¡«å……ä¼šè¯æœªåˆå§‹åŒ–'}), 400

        data = request.get_json()
        session_id = data.get('session_id', '')
        data_sources = data.get('data_sources', [])

        if not session_id:
            return jsonify({'error': 'ç¼ºå°‘ä¼šè¯ID'}), 400

        result = fill_coordinator.auto_match_data(session_id, data_sources)
        if "error" in result:
            return jsonify(result), 500

        return jsonify({
            'success': True,
            'matched_fields': result.get('matched_fields', {}),
            'unmatched_fields': result.get('unmatched_fields', []),
            'confidence_scores': result.get('confidence_scores', {}),
            'conflicts': result.get('conflicts', [])
        })

    except Exception as e:
        return jsonify({'error': f'è‡ªåŠ¨åŒ¹é…æ•°æ®å¤±è´¥: {str(e)}'}), 500

@app.route('/api/document-fill/auto-match/conflicts/<session_id>', methods=['PATCH'])
def resolve_conflicts(session_id):
    """è§£å†³è‡ªåŠ¨åŒ¹é…ä¸­çš„å†²çª"""
    global fill_coordinator

    try:
        if fill_coordinator is None:
            return jsonify({'error': 'æ–‡æ¡£å¡«å……ä¼šè¯æœªåˆå§‹åŒ–'}), 400

        data = request.get_json()
        resolutions = data.get('resolutions', {})

        if not resolutions:
            return jsonify({'error': 'ç¼ºå°‘å†²çªè§£å†³æ–¹æ¡ˆ'}), 400

        result = fill_coordinator.resolve_conflicts(session_id, resolutions)
        if "error" in result:
            return jsonify(result), 500

        return jsonify({
            'success': True,
            'resolved_fields': result.get('resolved_fields', {})
        })

    except Exception as e:
        return jsonify({'error': f'è§£å†³å†²çªå¤±è´¥: {str(e)}'}), 500

# æ–‡æ¡£å®¡é˜…ç›¸å…³APIç«¯ç‚¹
@app.route('/api/document-review/start', methods=['POST'])
def start_document_review():
    """å¼€å§‹æ–‡æ¡£å®¡é˜…è¿‡ç¨‹"""
    global orchestrator_instance

    try:
        if orchestrator_instance is None:
            orchestrator_instance = initialize_agent(api_type="xingcheng")

        data = request.get_json()
        # æ–°å¢ï¼šæ”¯æŒ data_sources ç»“æ„
        data_sources = data.get('data_sources')
        if data_sources:
            document_content = ''
            document_name = ''
            review_focus = 'auto'
            image_files = {}
            for item in data_sources:
                if item.get('type') == 'text' and not document_content:
                    document_content = item.get('content', '')
                    document_name = item.get('name', '')
                if item.get('type') == 'review_focus':
                    review_focus = item.get('content', 'auto')
                if item.get('type') == 'file':
                    mime = item.get('mime', '')
                    if mime.startswith('image/') and item.get('content'):
                        header, b64data = item['content'].split(',', 1) if ',' in item['content'] else ('', item['content'])
                        binary = base64.b64decode(b64data)
                        tmp_dir = tempfile.gettempdir()
                        img_path = os.path.join(tmp_dir, item.get('name','uploaded_image'))
                        with open(img_path, 'wb') as f:
                            f.write(binary)
                        image_files[item.get('name','file')] = img_path
            # å¯å°† image_files è·¯å¾„ä¼ é€’ç»™åç»­åˆ†æé€»è¾‘
        else:
            document_content = data.get('document_content', '')
            document_name = data.get('document_name', '')
            review_focus = data.get('review_focus', 'auto')

        if not document_content:
            return jsonify({'error': 'ç¼ºå°‘æ–‡æ¡£å†…å®¹'}), 400

        session_id = str(uuid.uuid4())
        result = orchestrator_instance.start_document_review(document_content, document_name, review_focus, session_id)
        if "error" in result:
            return jsonify(result), 500

        return jsonify({
            'success': True,
            'review_session_id': session_id,
            'status': 'in_progress'
        })

    except Exception as e:
        return jsonify({'error': f'å¯åŠ¨æ–‡æ¡£å®¡é˜…å¤±è´¥: {str(e)}'}), 500

@app.route('/api/document-review/suggestions/<review_session_id>', methods=['GET'])
def get_review_suggestions(review_session_id):
    """è·å–æ–‡æ¡£å®¡é˜…å»ºè®®"""
    global orchestrator_instance

    try:
        if orchestrator_instance is None:
            return jsonify({'error': 'å®¡é˜…æœåŠ¡æœªåˆå§‹åŒ–'}), 400

        suggestions = orchestrator_instance.get_review_suggestions(review_session_id)
        if "error" in suggestions:
            return jsonify(suggestions), 404

        return jsonify({
            'success': True,
            'suggestions': suggestions
        })

    except Exception as e:
        return jsonify({'error': f'è·å–å®¡é˜…å»ºè®®å¤±è´¥: {str(e)}'}), 500

@app.route('/api/document-review/suggestions/<review_session_id>/<suggestion_id>', methods=['PATCH'])
def handle_review_suggestion(review_session_id, suggestion_id):
    """æ¥å—æˆ–æ‹’ç»ç‰¹å®šå®¡é˜…å»ºè®®"""
    global orchestrator_instance

    try:
        if orchestrator_instance is None:
            return jsonify({'error': 'å®¡é˜…æœåŠ¡æœªåˆå§‹åŒ–'}), 400

        data = request.get_json()
        action = data.get('action', '')

        if action not in ['accept', 'reject']:
            return jsonify({'error': 'æ— æ•ˆçš„æ“ä½œï¼Œå¿…é¡»æ˜¯acceptæˆ–reject'}), 400

        result = orchestrator_instance.handle_review_suggestion(review_session_id, suggestion_id, action)
        if "error" in result:
            return jsonify(result), 404

        return jsonify({
            'success': True,
            'suggestion_id': suggestion_id,
            'action': action
        })

    except Exception as e:
        return jsonify({'error': f'å¤„ç†å®¡é˜…å»ºè®®å¤±è´¥: {str(e)}'}), 500

@app.route('/api/document-review/suggestions/<review_session_id>/batch', methods=['PATCH'])
def handle_batch_review_suggestions(review_session_id):
    """æ‰¹é‡æ¥å—æˆ–æ‹’ç»æ‰€æœ‰å®¡é˜…å»ºè®®"""
    global orchestrator_instance

    try:
        if orchestrator_instance is None:
            return jsonify({'error': 'å®¡é˜…æœåŠ¡æœªåˆå§‹åŒ–'}), 400

        data = request.get_json()
        action = data.get('action', '')

        if action not in ['accept_all', 'reject_all']:
            return jsonify({'error': 'æ— æ•ˆçš„æ“ä½œï¼Œå¿…é¡»æ˜¯accept_allæˆ–reject_all'}), 400

        result = orchestrator_instance.handle_batch_review_suggestions(review_session_id, action)
        if "error" in result:
            return jsonify(result), 404

        return jsonify({
            'success': True,
            'action': action,
            'suggestion_count': result.get('suggestion_count', 0)
        })

    except Exception as e:
        return jsonify({'error': f'æ‰¹é‡å¤„ç†å®¡é˜…å»ºè®®å¤±è´¥: {str(e)}'}), 500

@app.route('/api/document-review/export/<review_session_id>', methods=['GET'])
def export_reviewed_document(review_session_id):
    """å¯¼å‡ºè¯„å®¡åçš„æ–‡æ¡£"""
    global orchestrator_instance
    
    try:
        if orchestrator_instance is None:
            return jsonify({'error': 'æ–‡æ¡£è¯„å®¡å™¨æœªåˆå§‹åŒ–'}), 400
        
        result = orchestrator_instance.export_reviewed_document(review_session_id)
        if "error" in result:
            return jsonify(result), 404
        
        # ç”ŸæˆSVGå›¾ç‰‡å¹¶æ’å…¥è¯„å®¡æ–‡æ¡£
        if image_processor:
            svg_result = image_processor.generate_ai_svg_for_document(
                document_type="review_export",
                content_description="æ–‡æ¡£è¯„å®¡ç»“æœ",
                svg_size=(450, 350)
            )
            
            if svg_result.get("success"):
                # æ’å…¥SVGåˆ°è¯„å®¡æ–‡æ¡£ï¼ˆä¸‹è½½æ¨¡å¼ï¼‰
                if "html_content" in result:
                    target_position = {"line_number": 1, "document_type": "review_export"}
                    updated_content = image_processor.insert_svg_to_document(
                        result["html_content"], svg_result, target_position, mode="download"
                    )
                    result["html_content"] = updated_content
                    result["svg_info"] = svg_result
        
        from flask import make_response
        response = make_response(result['docx_content'])
        response.headers['Content-Type'] = 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
        response.headers['Content-Disposition'] = 'attachment; filename=reviewed_document.docx'
        return response
        
    except Exception as e:
        return jsonify({'error': f'å¯¼å‡ºè¯„å®¡æ–‡æ¡£å¤±è´¥: {str(e)}'}), 500

# æ¨¡æ¿ç®¡ç†ç›¸å…³APIç«¯ç‚¹
@app.route('/api/templates/<template_type>/<template_id>/rename', methods=['PATCH'])
def rename_template(template_type, template_id):
    """é‡å‘½åæ¨¡æ¿"""
    global template_repo

    try:
        if template_repo is None:
            return jsonify({'error': 'æ¨¡æ¿å­˜å‚¨åº“æœªåˆå§‹åŒ–'}), 400

        if template_type not in ['format', 'style']:
            return jsonify({'error': 'æ— æ•ˆçš„æ¨¡æ¿ç±»å‹ï¼Œå¿…é¡»æ˜¯formatæˆ–style'}), 400

        data = request.get_json()
        new_name = data.get('new_name', '')

        if not new_name:
            return jsonify({'error': 'ç¼ºå°‘æ–°åç§°'}), 400

        result = template_repo.rename_template(template_type, template_id, new_name)
        if "error" in result:
            return jsonify(result), 404

        return jsonify({
            'success': True,
            'template_id': template_id,
            'new_name': new_name
        })

    except Exception as e:
        return jsonify({'error': f'é‡å‘½åæ¨¡æ¿å¤±è´¥: {str(e)}'}), 500

@app.route('/api/templates/<template_type>/<template_id>/confirm-delete', methods=['GET'])
def confirm_delete_template(template_type, template_id):
    """ç¡®è®¤åˆ é™¤æ¨¡æ¿"""
    global template_repo

    try:
        if template_repo is None:
            return jsonify({'error': 'æ¨¡æ¿å­˜å‚¨åº“æœªåˆå§‹åŒ–'}), 400

        if template_type not in ['format', 'style']:
            return jsonify({'error': 'æ— æ•ˆçš„æ¨¡æ¿ç±»å‹ï¼Œå¿…é¡»æ˜¯formatæˆ–style'}), 400

        # ç”Ÿæˆä¸€ä¸ªç¡®è®¤ä»¤ç‰Œ
        confirmation_token = str(uuid.uuid4())
        # è¿™é‡Œå¯ä»¥å­˜å‚¨ä»¤ç‰Œä¸æ¨¡æ¿IDçš„å…³è”ï¼Œè®¾ç½®è¿‡æœŸæ—¶é—´ç­‰

        return jsonify({
            'success': True,
            'confirmation_message': 'æ‚¨ç¡®å®šè¦åˆ é™¤æ­¤æ¨¡æ¿å—ï¼Ÿæ­¤æ“ä½œæ— æ³•æ’¤é”€ã€‚',
            'confirmation_token': confirmation_token
        })

    except Exception as e:
        return jsonify({'error': f'ç¡®è®¤åˆ é™¤æ¨¡æ¿å¤±è´¥: {str(e)}'}), 500

@app.route('/api/templates/<template_type>/<template_id>', methods=['DELETE'])
def delete_template(template_type, template_id):
    """åˆ é™¤æ¨¡æ¿"""
    global template_repo

    try:
        if template_repo is None:
            return jsonify({'error': 'æ¨¡æ¿å­˜å‚¨åº“æœªåˆå§‹åŒ–'}), 400

        if template_type not in ['format', 'style']:
            return jsonify({'error': 'æ— æ•ˆçš„æ¨¡æ¿ç±»å‹ï¼Œå¿…é¡»æ˜¯formatæˆ–style'}), 400

        data = request.get_json() or {}
        confirmation_token = data.get('confirmation_token', '')

        if not confirmation_token:
            return jsonify({'error': 'ç¼ºå°‘ç¡®è®¤ä»¤ç‰Œ'}), 400

        # è¿™é‡Œåº”è¯¥éªŒè¯ç¡®è®¤ä»¤ç‰Œ
        # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬å‡è®¾ä»¤ç‰Œæœ‰æ•ˆ

        result = template_repo.delete_template(template_type, template_id)
        if "error" in result:
            return jsonify(result), 404

        return jsonify({
            'success': True,
            'template_id': template_id
        })

    except Exception as e:
        return jsonify({'error': f'åˆ é™¤æ¨¡æ¿å¤±è´¥: {str(e)}'}), 500

# å†å²è®°å½•é‡æ–°åº”ç”¨ç›¸å…³APIç«¯ç‚¹
@app.route('/api/documents/history/<record_id>/reapply', methods=['POST'])
def reapply_operation(record_id):
    """é‡æ–°åº”ç”¨å†å²æ“ä½œ"""
    global document_repo, orchestrator_instance

    try:
        if document_repo is None:
            return jsonify({'error': 'æ–‡æ¡£å­˜å‚¨åº“æœªåˆå§‹åŒ–'}), 400

        if orchestrator_instance is None:
            orchestrator_instance = initialize_agent(api_type="xingcheng")

        record = document_repo.get_document_record(record_id)
        if not record:
            return jsonify({'error': 'å†å²è®°å½•æœªæ‰¾åˆ°'}), 404

        if not os.path.exists(record.file_path):
            return jsonify({
                'success': False,
                'status': 'file_missing',
                'message': 'åŸå§‹æ–‡ä»¶ä¸å†å¯ç”¨ã€‚è¯·é‡æ–°ä¸Šä¼ æ–‡ä»¶ä»¥ç»§ç»­ã€‚'
            }), 400

        # åˆ›å»ºæ–°è®°å½•
        new_record = DocumentRecord(
            original_filename=record.original_filename,
            file_path=record.file_path,
            file_size=record.file_size,
            file_hash=record.file_hash,
            document_type=record.document_type,
            intent_type=record.intent_type,
            processing_status=ProcessingStatus.PROCESSING,
            confidence_score=0.0
        )
        new_record_id = document_repo.create_document_record(new_record)

        # é‡æ–°åº”ç”¨æ“ä½œ
        result = orchestrator_instance.process_document(record.file_path, new_record_id)
        if "error" in result:
            document_repo.update_processing_status(new_record_id, ProcessingStatus.FAILED, error_message=str(result.get('error')))
            return jsonify(result), 500

        document_repo.update_processing_status(new_record_id, ProcessingStatus.COMPLETED)
        return jsonify({
            'success': True,
            'new_record_id': new_record_id,
            'status': 'completed'
        })

    except Exception as e:
        return jsonify({'error': f'é‡æ–°åº”ç”¨æ“ä½œå¤±è´¥: {str(e)}'}), 500

@app.route('/api/documents/history/<record_id>/upload', methods=['POST'])
def upload_for_reapply(record_id):
    """ä¸ºé‡æ–°åº”ç”¨ä¸Šä¼ æ–‡ä»¶"""
    global document_repo

    try:
        if document_repo is None:
            return jsonify({'error': 'æ–‡æ¡£å­˜å‚¨åº“æœªåˆå§‹åŒ–'}), 400

        if 'file' not in request.files:
            return jsonify({'error': 'æ²¡æœ‰æ–‡ä»¶'}), 400

        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400

        if not allowed_file(file.filename):
            return jsonify({'error': 'ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼'}), 400

        filename = secure_filename(file.filename)
        unique_filename = f"{uuid.uuid4().hex}_{filename}"
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], unique_filename)
        file.save(filepath)

        # æ›´æ–°è®°å½•ä¸­çš„æ–‡ä»¶è·¯å¾„
        record = document_repo.get_document_record(record_id)
        if not record:
            return jsonify({'error': 'å†å²è®°å½•æœªæ‰¾åˆ°'}), 404

        document_repo.update_file_path(record_id, filepath)

        return jsonify({
            'success': True,
            'file_path': filepath,
            'message': 'æ–‡ä»¶ä¸Šä¼ æˆåŠŸã€‚æ‚¨ç°åœ¨å¯ä»¥é‡æ–°åº”ç”¨æ“ä½œã€‚'
        })

    except Exception as e:
        return jsonify({'error': f'æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}'}), 500

# æ•°æ®åº“ç›¸å…³APIç«¯ç‚¹
@app.route('/api/database/stats', methods=['GET'])
def get_database_stats():
    """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
    try:
        if db_manager is None:
            return jsonify({'error': 'æ•°æ®åº“æœªåˆå§‹åŒ–'}), 500

        stats = db_manager.get_database_stats()
        doc_stats = document_repo.get_statistics() if document_repo else {}

        return jsonify({
            'success': True,
            'database_stats': stats,
            'document_stats': doc_stats
        })
    except Exception as e:
        return jsonify({'error': f'è·å–æ•°æ®åº“ç»Ÿè®¡å¤±è´¥: {str(e)}'}), 500

@app.route('/api/documents/history', methods=['GET'])
def get_document_history():
    """è·å–æ–‡æ¡£å¤„ç†å†å²"""
    try:
        if document_repo is None:
            print("Error: document_repo is None, database not initialized")
            return jsonify({
                'success': False,
                'history': [],
                'count': 0,
                'message': 'æ•°æ®åº“æœªåˆå§‹åŒ–ï¼Œè¿”å›ç©ºå†å²è®°å½•'
            }), 200

        limit = request.args.get('limit', 50, type=int)
        status = request.args.get('status', None)
        print(f"Fetching document history with limit={limit}, status={status}")

        records = document_repo.get_processing_history(limit=limit, status=status)
        print(f"Retrieved {len(records)} records from database")

        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        history = []
        for record in records:
            try:
                history.append(record.to_dict())
            except Exception as e:
                print(f"Error converting record to dict: {e}")
                continue

        print(f"Successfully converted {len(history)} records to dictionary format")
        return jsonify({
            'success': True,
            'history': history,
            'count': len(history)
        })
    except Exception as e:
        print(f"Error in get_document_history: {e}")
        print(f"Stack trace: {traceback.format_exc()}")
        return jsonify({
            'success': False,
            'history': [],
            'count': 0,
            'message': f'è·å–æ–‡æ¡£å†å²å¤±è´¥: {str(e)}'
        }), 200

@app.route('/api/templates/personal', methods=['GET'])
def get_personal_templates():
    """è·å–ä¸ªäººæ¨¡æ¿åˆ—è¡¨"""
    try:
        if template_repo is None:
            return jsonify({'error': 'æ•°æ®åº“æœªåˆå§‹åŒ–'}), 500

        document_type = request.args.get('document_type', None)
        category = request.args.get('category', None)

        templates = template_repo.get_templates(document_type=document_type, category=category)

        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        template_list = [template.to_dict() for template in templates]

        return jsonify({
            'success': True,
            'templates': template_list,
            'count': len(template_list)
        })
    except Exception as e:
        return jsonify({'error': f'è·å–ä¸ªäººæ¨¡æ¿å¤±è´¥: {str(e)}'}), 500

@app.route('/api/settings', methods=['GET'])
def get_app_settings():
    """è·å–åº”ç”¨è®¾ç½®"""
    try:
        if settings_repo is None:
            return jsonify({'error': 'æ•°æ®åº“æœªåˆå§‹åŒ–'}), 500

        settings = settings_repo.get_all_settings()

        return jsonify({
            'success': True,
            'settings': settings
        })
    except Exception as e:
        return jsonify({'error': f'è·å–åº”ç”¨è®¾ç½®å¤±è´¥: {str(e)}'}), 500

@app.route('/api/settings', methods=['POST'])
def update_app_settings():
    """æ›´æ–°åº”ç”¨è®¾ç½®"""
    try:
        if settings_repo is None:
            return jsonify({'error': 'æ•°æ®åº“æœªåˆå§‹åŒ–'}), 500

        data = request.get_json()

        updated_count = 0
        for key, value in data.items():
            if settings_repo.set_setting(key, value):
                updated_count += 1

        return jsonify({
            'success': True,
            'updated_count': updated_count,
            'message': f'æˆåŠŸæ›´æ–° {updated_count} ä¸ªè®¾ç½®'
        })
    except Exception as e:
        return jsonify({'error': f'æ›´æ–°åº”ç”¨è®¾ç½®å¤±è´¥: {str(e)}'}), 500

@app.route('/api/table-fill', methods=['POST'])
def api_table_fill():
    """
    æ™ºèƒ½è¡¨æ ¼æ‰¹é‡å¡«å……API
    è¯·æ±‚å‚æ•°:
      - tables: List[dict]ï¼Œæ¯ä¸ªdictåŒ…å«'columns'å’Œ'data'ï¼ˆäºŒç»´æ•°ç»„ï¼‰
      - fill_data: list of dictï¼Œæ¯ä¸ª dict å¯¹åº”ä¸€è¡Œæ•°æ®ï¼Œkey ä¸ºè¡¨å¤´
    è¿”å›:
      - å¡«å……åçš„è¡¨æ ¼å†…å®¹ï¼ˆjsonï¼‰
    """
    try:
        data = request.get_json()
        tables = data.get('tables', [])
        fill_data = data.get('fill_data', [])

        # ååºåˆ—åŒ– DataFrame
        pd_tables = []
        for t in tables:
            # t: {'columns': [...], 'data': [[...], ...]}
            df = pd.DataFrame(t['data'], columns=t['columns'])
            pd_tables.append(df)

        processor = DocumentProcessor()
        filled_tables = processor.fill_tables(pd_tables, fill_data)

        # è¿”å›jsonæ ¼å¼
        result = []
        for df in filled_tables:
            result.append({
                'columns': list(df.columns),
                'data': df.values.tolist()
            })

        return jsonify({'success': True, 'filled_tables': result})

    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

# ==================== ä»ªè¡¨æ¿ç›¸å…³APIç«¯ç‚¹ ====================

@app.route('/dashboard')
def dashboard():
    """ä»ªè¡¨æ¿é¡µé¢"""
    return render_template('dashboard.html')

@app.route('/api/performance/stats')
def get_performance_stats():
    """è·å–æ€§èƒ½ç»Ÿè®¡æ•°æ®"""
    try:
        performance_repo = PerformanceRepository()

        # è·å–24å°æ—¶å†…çš„ç»Ÿè®¡æ•°æ®
        stats = performance_repo.get_performance_stats()

        # è·å–å†…å­˜ä¸­çš„æ€§èƒ½ç›‘æ§æ•°æ®
        performance_monitor = get_performance_monitor()
        monitor_stats = performance_monitor.get_performance_summary()

        # åˆå¹¶ç»Ÿè®¡æ•°æ®
        combined_stats = {
            'total_requests': stats.get('total_requests', 0) + monitor_stats.get('total_operations', 0),
            'successful_requests': stats.get('successful_requests', 0) + monitor_stats.get('successful_operations', 0),
            'failed_requests': stats.get('failed_requests', 0) + monitor_stats.get('failed_operations', 0),
            'success_rate': 0.0,
            'avg_duration_ms': stats.get('avg_duration_ms', 0.0),
            'cache_hit_rate': 0.0,
            'recent_requests': monitor_stats.get('total_operations', 0),
            'time_change': 'N/A'
        }

        # è®¡ç®—æˆåŠŸç‡
        total = combined_stats['total_requests']
        if total > 0:
            combined_stats['success_rate'] = combined_stats['successful_requests'] / total

        # è·å–LLMå®¢æˆ·ç«¯çš„æ€§èƒ½æŠ¥å‘Š
        if orchestrator and hasattr(orchestrator.llm_client, 'get_performance_report'):
            llm_stats = orchestrator.llm_client.get_performance_report()
            combined_stats.update({
                'cache_hit_rate': llm_stats.get('cache_hit_rate', 0.0),
                'healthy_endpoints': llm_stats.get('healthy_endpoints', 0)
            })

        return jsonify({
            'success': True,
            'data': combined_stats
        })
    except Exception as e:
        print(f"Error getting performance stats: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/performance/health')
def get_api_health():
    """è·å–APIå¥åº·çŠ¶æ€"""
    try:
        health_data = {
            'endpoints': []
        }

        if orchestrator and hasattr(orchestrator.llm_client, 'get_health_status'):
            health_status = orchestrator.llm_client.get_health_status()

            # è½¬æ¢ä¸ºå‰ç«¯éœ€è¦çš„æ ¼å¼
            for endpoint in health_status.get('healthy_endpoints', []):
                health_data['endpoints'].append({
                    'name': endpoint,
                    'healthy': True,
                    'avg_response_time': 0,  # TODO: ä»ç»Ÿè®¡ä¸­è·å–
                    'success_rate': 1.0
                })

            for endpoint in health_status.get('unhealthy_endpoints', []):
                health_data['endpoints'].append({
                    'name': endpoint,
                    'healthy': False,
                    'warning': True,
                    'avg_response_time': 0,
                    'success_rate': 0.0
                })

        return jsonify({
            'success': True,
            'data': health_data
        })
    except Exception as e:
        print(f"Error getting API health: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/performance/operations')
def get_operation_breakdown():
    """è·å–æ“ä½œç±»å‹åˆ†è§£ç»Ÿè®¡"""
    try:
        performance_repo = PerformanceRepository()
        db_breakdown = performance_repo.get_operation_breakdown()

        # è·å–å†…å­˜ä¸­çš„æ“ä½œç»Ÿè®¡
        performance_monitor = get_performance_monitor()
        monitor_stats = performance_monitor.get_operation_stats()

        # åˆå¹¶æ•°æ®åº“å’Œå†…å­˜ä¸­çš„ç»Ÿè®¡
        combined_breakdown = {}

        # æ·»åŠ æ•°æ®åº“ä¸­çš„æ•°æ®
        for item in db_breakdown:
            op = item['operation']
            combined_breakdown[op] = item

        # æ·»åŠ å†…å­˜ä¸­çš„æ•°æ®
        for op, stats in monitor_stats.items():
            if op in combined_breakdown:
                # åˆå¹¶ç»Ÿè®¡
                combined_breakdown[op]['count'] += stats['count']
                combined_breakdown[op]['success_count'] += stats['success_count']
                # é‡æ–°è®¡ç®—å¹³å‡å€¼
                total_count = combined_breakdown[op]['count']
                if total_count > 0:
                    combined_breakdown[op]['success_rate'] = combined_breakdown[op]['success_count'] / total_count
            else:
                # æ–°å¢æ“ä½œç±»å‹
                combined_breakdown[op] = {
                    'operation': op,
                    'count': stats['count'],
                    'success_count': stats['success_count'],
                    'success_rate': stats['success_rate'],
                    'avg_duration_ms': stats['avg_time'],
                    'total_input_tokens': 0,
                    'total_output_tokens': 0
                }

        # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
        breakdown_list = list(combined_breakdown.values())
        breakdown_list.sort(key=lambda x: x['count'], reverse=True)

        return jsonify({
            'success': True,
            'data': breakdown_list
        })
    except Exception as e:
        print(f"Error getting operation breakdown: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/performance/history')
def get_processing_history():
    """è·å–å¤„ç†å†å²è®°å½•"""
    try:
        page = int(request.args.get('page', 1))
        size = int(request.args.get('size', 10))
        filter_type = request.args.get('filter', 'all')

        # TODO: å®ç°åˆ†é¡µå’Œç­›é€‰é€»è¾‘
        # è¿™é‡Œå…ˆè¿”å›æ¨¡æ‹Ÿæ•°æ®
        mock_records = [
            {
                'id': str(uuid.uuid4()),
                'timestamp': datetime.now().isoformat(),
                'operation': 'document_parse',
                'success': True,
                'duration_ms': 1250,
                'api_endpoint': 'qiniu'
            },
            {
                'id': str(uuid.uuid4()),
                'timestamp': datetime.now().isoformat(),
                'operation': 'content_generate',
                'success': True,
                'duration_ms': 2100,
                'api_endpoint': 'together'
            }
        ]

        return jsonify({
            'success': True,
            'data': {
                'records': mock_records,
                'total': len(mock_records),
                'page': page,
                'size': size
            }
        })
    except Exception as e:
        print(f"Error getting processing history: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/performance/export', methods=['POST'])
def export_performance_data():
    """å¯¼å‡ºæ€§èƒ½æ•°æ®"""
    try:
        data = request.get_json()
        filter_type = data.get('filter', 'all')
        format_type = data.get('format', 'csv')

        # TODO: å®ç°å®é™…çš„å¯¼å‡ºé€»è¾‘
        # è¿™é‡Œè¿”å›ä¸€ä¸ªç®€å•çš„CSVå†…å®¹
        csv_content = "timestamp,operation,success,duration_ms,api_endpoint\n"
        csv_content += "2024-01-01T10:00:00,document_parse,true,1250,qiniu\n"
        csv_content += "2024-01-01T10:01:00,content_generate,true,2100,together\n"

        from flask import Response
        return Response(
            csv_content,
            mimetype='text/csv',
            headers={'Content-Disposition': 'attachment; filename=performance_export.csv'}
        )
    except Exception as e:
        print(f"Error exporting performance data: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ==================== æ‰¹é‡å¤„ç†ç›¸å…³APIç«¯ç‚¹ ====================

@app.route('/batch')
def batch_page():
    """æ‰¹é‡å¤„ç†é¡µé¢"""
    return render_template('batch.html')

@app.route('/api/batch/create', methods=['POST'])
def create_batch_job():
    """åˆ›å»ºæ‰¹é‡å¤„ç†ä½œä¸š"""
    try:
        data = request.get_json()
        name = data.get('name')
        files = data.get('files', [])
        processing_config = data.get('processing_config', {})

        if not name:
            return jsonify({
                'success': False,
                'error': 'ä½œä¸šåç§°ä¸èƒ½ä¸ºç©º'
            }), 400

        if not files or not isinstance(files, list):
            return jsonify({
                'success': False,
                'error': 'æ–‡ä»¶åˆ—è¡¨ä¸èƒ½ä¸ºç©ºä¸”å¿…é¡»æ˜¯æ•°ç»„'
            }), 400

        # è¿‡æ»¤æ‰æ— æ•ˆçš„æ–‡ä»¶è·¯å¾„
        valid_files = [f for f in files if f is not None and isinstance(f, str) and f.strip()]
        if not valid_files:
            return jsonify({
                'success': False,
                'error': 'æ²¡æœ‰æä¾›æœ‰æ•ˆçš„æ–‡ä»¶è·¯å¾„'
            }), 400

        # è·å–æ‰¹é‡å¤„ç†å™¨
        batch_processor = get_batch_processor()

        # æ³¨å†Œå¤„ç†å™¨å‡½æ•°ï¼ˆå¦‚æœè¿˜æ²¡æœ‰æ³¨å†Œï¼‰
        if not hasattr(batch_processor, '_processors_registered'):
            register_batch_processors(batch_processor)
            batch_processor._processors_registered = True

        # åˆ›å»ºä½œä¸š
        job_id = batch_processor.create_batch_job(name, valid_files, processing_config)

        return jsonify({
            'success': True,
            'job_id': job_id,
            'message': 'æ‰¹é‡å¤„ç†ä½œä¸šåˆ›å»ºæˆåŠŸ'
        })

    except Exception as e:
        print(f"Error creating batch job: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/batch/start/<job_id>', methods=['POST'])
def start_batch_job(job_id):
    """å¯åŠ¨æ‰¹é‡å¤„ç†ä½œä¸š"""
    try:
        batch_processor = get_batch_processor()
        success = batch_processor.start_batch_job(job_id)

        if success:
            return jsonify({
                'success': True,
                'message': 'æ‰¹é‡å¤„ç†ä½œä¸šå¯åŠ¨æˆåŠŸ'
            })
        else:
            return jsonify({
                'success': False,
                'error': 'å¯åŠ¨ä½œä¸šå¤±è´¥'
            }), 400

    except Exception as e:
        print(f"Error starting batch job: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/batch/jobs')
def get_batch_jobs():
    """è·å–æ‰¹é‡å¤„ç†ä½œä¸šåˆ—è¡¨"""
    try:
        batch_processor = get_batch_processor()
        jobs = batch_processor.list_active_jobs()

        return jsonify({
            'success': True,
            'jobs': jobs
        })

    except Exception as e:
        print(f"Error getting batch jobs: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/batch/job/<job_id>')
def get_batch_job_status(job_id):
    """è·å–æ‰¹é‡å¤„ç†ä½œä¸šçŠ¶æ€"""
    try:
        batch_processor = get_batch_processor()
        job_status = batch_processor.get_job_status(job_id)

        if job_status:
            return jsonify({
                'success': True,
                'job': job_status
            })
        else:
            return jsonify({
                'success': False,
                'error': 'ä½œä¸šä¸å­˜åœ¨'
            }), 404

    except Exception as e:
        print(f"Error getting batch job status: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/batch/cancel/<job_id>', methods=['POST'])
def cancel_batch_job(job_id):
    """å–æ¶ˆæ‰¹é‡å¤„ç†ä½œä¸š"""
    try:
        batch_processor = get_batch_processor()
        success = batch_processor.cancel_job(job_id)

        if success:
            return jsonify({
                'success': True,
                'message': 'ä½œä¸šå–æ¶ˆæˆåŠŸ'
            })
        else:
            return jsonify({
                'success': False,
                'error': 'å–æ¶ˆä½œä¸šå¤±è´¥'
            }), 400

    except Exception as e:
        print(f"Error cancelling batch job: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

def register_batch_processors(batch_processor):
    """æ³¨å†Œæ‰¹é‡å¤„ç†å™¨å‡½æ•°"""

    def document_parse_processor(file_path, config):
        """æ–‡æ¡£è§£æå¤„ç†å™¨"""
        try:
            # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„æ–‡æ¡£è§£æé€»è¾‘
            # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬è¿”å›ä¸€ä¸ªæ¨¡æ‹Ÿç»“æœ
            time.sleep(1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            return {
                'success': True,
                'output_path': file_path.replace('.', '_parsed.'),
                'message': f'æ–‡æ¡£è§£æå®Œæˆ: {os.path.basename(file_path)}'
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }

    def format_cleanup_processor(file_path, config):
        """æ ¼å¼æ•´ç†å¤„ç†å™¨"""
        try:
            time.sleep(2)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            return {
                'success': True,
                'output_path': file_path.replace('.', '_formatted.'),
                'message': f'æ ¼å¼æ•´ç†å®Œæˆ: {os.path.basename(file_path)}'
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }

    def content_generation_processor(file_path, config):
        """å†…å®¹ç”Ÿæˆå¤„ç†å™¨"""
        try:
            time.sleep(3)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            return {
                'success': True,
                'output_path': file_path.replace('.', '_generated.'),
                'message': f'å†…å®¹ç”Ÿæˆå®Œæˆ: {os.path.basename(file_path)}'
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }

    def style_transfer_processor(file_path, config):
        """é£æ ¼è½¬æ¢å¤„ç†å™¨"""
        try:
            time.sleep(2.5)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            return {
                'success': True,
                'output_path': file_path.replace('.', '_styled.'),
                'message': f'é£æ ¼è½¬æ¢å®Œæˆ: {os.path.basename(file_path)}'
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }

    # æ³¨å†Œå¤„ç†å™¨
    batch_processor.register_processor('document_parse', document_parse_processor)
    batch_processor.register_processor('format_cleanup', format_cleanup_processor)
    batch_processor.register_processor('content_generation', content_generation_processor)
    batch_processor.register_processor('style_transfer', style_transfer_processor)

# æ›¿æ¢å…¨å±€å¼‚å¸¸å¤„ç†ä¸ºï¼šä»…åœ¨ debug æ¨¡å¼ä¸‹è¿”å› traceback
@app.errorhandler(Exception)
def handle_exception(e):
    import traceback
    if app.debug:
        tb = traceback.format_exc()
        return jsonify({'error': str(e), 'traceback': tb}), 500
    else:
        return jsonify({'error': str(e)}), 500

# åœ¨ç°æœ‰APIç«¯ç‚¹åæ·»åŠ æ–°çš„æ™ºèƒ½æ–‡æ¡£å¡«å……ç«¯ç‚¹

@app.route('/api/enhanced-document/analyze', methods=['POST'])
def enhanced_document_analysis():
    """å¢å¼ºçš„æ–‡æ¡£åˆ†æAPI"""
    global enhanced_document_filler
    
    try:
        if enhanced_document_filler is None:
            return jsonify({'error': 'å¢å¼ºæ–‡æ¡£å¡«å……å™¨æœªåˆå§‹åŒ–'}), 400
        
        data = request.get_json()
        if not data:
            return jsonify({'error': 'è¯·æ±‚æ•°æ®ä¸ºç©º'}), 400
        
        document_content = data.get('document_content', '')
        document_name = data.get('document_name', '')
        
        if not document_content:
            return jsonify({'error': 'æ–‡æ¡£å†…å®¹ä¸ºç©º'}), 400
        
        # æ‰§è¡Œå¢å¼ºçš„æ–‡æ¡£åˆ†æ
        analysis_result = enhanced_document_filler.analyze_document_structure(
            document_content, document_name
        )
        
        if "error" in analysis_result:
            return jsonify(analysis_result), 400
        
        return jsonify(analysis_result)
        
    except Exception as e:
        return jsonify({'error': f'æ–‡æ¡£åˆ†æå¤±è´¥: {str(e)}'}), 500

@app.route('/api/enhanced-document/fill', methods=['POST'])
def enhanced_document_fill():
    """å¢å¼ºçš„æ–‡æ¡£å¡«å……API"""
    global enhanced_document_filler
    
    try:
        if enhanced_document_filler is None:
            return jsonify({'error': 'å¢å¼ºæ–‡æ¡£å¡«å……å™¨æœªåˆå§‹åŒ–'}), 400
        
        data = request.get_json()
        if not data:
            return jsonify({'error': 'è¯·æ±‚æ•°æ®ä¸ºç©º'}), 400
        
        analysis_result = data.get('analysis_result', {})
        user_data = data.get('user_data', {})
        image_files = data.get('image_files', [])
        
        if not analysis_result:
            return jsonify({'error': 'åˆ†æç»“æœä¸ºç©º'}), 400
        
        # æ‰§è¡Œæ™ºèƒ½æ–‡æ¡£å¡«å……
        fill_result = enhanced_document_filler.intelligent_fill_document(
            analysis_result, user_data, image_files
        )
        
        if "error" in fill_result:
            return jsonify(fill_result), 400
        
        return jsonify(fill_result)
        
    except Exception as e:
        return jsonify({'error': f'æ–‡æ¡£å¡«å……å¤±è´¥: {str(e)}'}), 500

@app.route('/api/patent-document/analyze', methods=['POST'])
def patent_document_analysis():
    """ä¸“åˆ©æ–‡æ¡£åˆ†æAPI"""
    global patent_analyzer
    
    try:
        if patent_analyzer is None:
            return jsonify({'error': 'ä¸“åˆ©åˆ†æå™¨æœªåˆå§‹åŒ–'}), 400
        
        data = request.get_json()
        if not data:
            return jsonify({'error': 'è¯·æ±‚æ•°æ®ä¸ºç©º'}), 400
        
        document_content = data.get('document_content', '')
        document_name = data.get('document_name', '')
        
        if not document_content:
            return jsonify({'error': 'æ–‡æ¡£å†…å®¹ä¸ºç©º'}), 400
        
        # æ‰§è¡Œä¸“åˆ©æ–‡æ¡£åˆ†æ
        analysis_result = patent_analyzer.analyze_patent_document(
            document_content, document_name
        )
        
        if "error" in analysis_result:
            return jsonify(analysis_result), 400
        
        # ç”ŸæˆAIå¡«å†™å»ºè®®
        ai_suggestions = patent_analyzer.generate_ai_fill_suggestions(analysis_result)
        analysis_result["ai_suggestions"] = ai_suggestions
        
        return jsonify(analysis_result)
        
    except Exception as e:
        return jsonify({'error': f'ä¸“åˆ©æ–‡æ¡£åˆ†æå¤±è´¥: {str(e)}'}), 500

@app.route('/api/image/process', methods=['POST'])
def process_image():
    """å›¾ç‰‡å¤„ç†API"""
    global image_processor
    
    try:
        if image_processor is None:
            return jsonify({'error': 'å›¾ç‰‡å¤„ç†å™¨æœªåˆå§‹åŒ–'}), 400
        
        data = request.get_json()
        if not data:
            return jsonify({'error': 'è¯·æ±‚æ•°æ®ä¸ºç©º'}), 400
        
        image_data = data.get('image_data', '')
        image_name = data.get('image_name', '')
        target_position = data.get('target_position', {})
        
        if not image_data:
            return jsonify({'error': 'å›¾ç‰‡æ•°æ®ä¸ºç©º'}), 400
        
        # å¤„ç†å›¾ç‰‡
        result = image_processor.process_uploaded_image(
            image_data, image_name, target_position
        )
        
        if "error" in result:
            return jsonify(result), 400
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({'error': f'å›¾ç‰‡å¤„ç†å¤±è´¥: {str(e)}'}), 500

@app.route('/api/image/batch-process', methods=['POST'])
def batch_process_images():
    """æ‰¹é‡å›¾ç‰‡å¤„ç†API"""
    global image_processor
    
    try:
        if image_processor is None:
            return jsonify({'error': 'å›¾ç‰‡å¤„ç†å™¨æœªåˆå§‹åŒ–'}), 400
        
        data = request.get_json()
        if not data:
            return jsonify({'error': 'è¯·æ±‚æ•°æ®ä¸ºç©º'}), 400
        
        image_list = data.get('image_list', [])
        document_content = data.get('document_content', '')
        
        if not image_list:
            return jsonify({'error': 'å›¾ç‰‡åˆ—è¡¨ä¸ºç©º'}), 400
        
        # æ‰¹é‡å¤„ç†å›¾ç‰‡
        result = image_processor.batch_process_images(image_list, document_content)
        
        if "error" in result:
            return jsonify(result), 400
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({'error': f'æ‰¹é‡å›¾ç‰‡å¤„ç†å¤±è´¥: {str(e)}'}), 500

@app.route('/api/image/statistics', methods=['GET'])
def get_image_statistics():
    """è·å–å›¾ç‰‡ç»Ÿè®¡ä¿¡æ¯API"""
    global image_processor
    
    try:
        if image_processor is None:
            return jsonify({'error': 'å›¾ç‰‡å¤„ç†å™¨æœªåˆå§‹åŒ–'}), 400
        
        statistics = image_processor.get_image_statistics()
        
        if "error" in statistics:
            return jsonify(statistics), 400
        
        return jsonify(statistics)
        
    except Exception as e:
        return jsonify({'error': f'è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}'}), 500

@app.route('/api/ai-fill-suggestions', methods=['POST'])
def get_ai_fill_suggestions():
    """è·å–AIå¡«å†™å»ºè®®API"""
    global patent_analyzer
    
    try:
        if patent_analyzer is None:
            return jsonify({'error': 'ä¸“åˆ©åˆ†æå™¨æœªåˆå§‹åŒ–'}), 400
        
        data = request.get_json()
        if not data:
            return jsonify({'error': 'è¯·æ±‚æ•°æ®ä¸ºç©º'}), 400
        
        analysis_result = data.get('analysis_result', {})
        
        if not analysis_result:
            return jsonify({'error': 'åˆ†æç»“æœä¸ºç©º'}), 400
        
        # ç”ŸæˆAIå¡«å†™å»ºè®®
        suggestions = patent_analyzer.generate_ai_fill_suggestions(analysis_result)
        
        if "error" in suggestions:
            return jsonify(suggestions), 400
        
        return jsonify(suggestions)
        
    except Exception as e:
        return jsonify({'error': f'ç”ŸæˆAIå»ºè®®å¤±è´¥: {str(e)}'}), 500

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)
