import os
import sys
import json
import uuid
import time
import traceback
from datetime import datetime, timedelta
from flask import Flask, request, jsonify, render_template, send_from_directory
from flask_cors import CORS
from werkzeug.utils import secure_filename
from dotenv import load_dotenv
import base64
import tempfile
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å°è¯•å¯¼å…¥å¯é€‰ä¾èµ–
try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False
    print("âš ï¸ pandasæœªå®‰è£…ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½å—é™")

# å°è¯•å¯¼å…¥é¡¹ç›®æ¨¡å—
try:
    from src.core.agent.agent_orchestrator import AgentOrchestrator
    from src.llm_clients.xingcheng_llm import XingchengLLMClient
    from src.llm_clients.multi_llm import MultiLLMClient
    from src.core.tools.format_alignment_coordinator import FormatAlignmentCoordinator
    from src.core.tools.document_fill_coordinator import DocumentFillCoordinator
    from src.core.tools.writing_style_analyzer import WritingStyleAnalyzer
    ADVANCED_FEATURES_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ é«˜çº§åŠŸèƒ½æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    ADVANCED_FEATURES_AVAILABLE = False

# å°è¯•å¯¼å…¥æ•°æ®åº“æ¨¡å—
try:
    from src.core.database import (
        DatabaseManager,
        AppSettingsRepository,
        DocumentRepository,
        TemplateRepository,
        PerformanceRepository,
        BatchProcessingRepository,
        DocumentRecord,
        DocumentType,
        IntentType,
        ProcessingStatus,
        get_database_manager
    )
    DATABASE_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ æ•°æ®åº“æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    DATABASE_AVAILABLE = False

# å°è¯•å¯¼å…¥æ€§èƒ½ç›‘æ§æ¨¡å—
try:
    from src.core.monitoring import get_performance_monitor, PerformanceTimer
    MONITORING_AVAILABLE = True
except ImportError:
    print("âš ï¸ æ€§èƒ½ç›‘æ§æ¨¡å—å¯¼å…¥å¤±è´¥")
    MONITORING_AVAILABLE = False
    # åˆ›å»ºç®€å•çš„æ€§èƒ½è®¡æ—¶å™¨æ›¿ä»£
    class PerformanceTimer:
        def __init__(self, name):
            self.name = name
        def __enter__(self):
            return self
        def __exit__(self, *args):
            pass

# å°è¯•å¯¼å…¥æ‰¹é‡å¤„ç†æ¨¡å—
try:
    from src.core.tools.batch_processor import get_batch_processor
    BATCH_PROCESSING_AVAILABLE = True
except ImportError:
    print("âš ï¸ æ‰¹é‡å¤„ç†æ¨¡å—å¯¼å…¥å¤±è´¥")
    BATCH_PROCESSING_AVAILABLE = False

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)

# å®šä¹‰æ•°æ®åº“åˆå§‹åŒ–å‡½æ•°ï¼Œæå‰åˆ°appåˆ›å»ºå‰
def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
    global db_manager, settings_repo, document_repo, template_repo
    try:
        db_manager = get_database_manager()
        settings_repo = AppSettingsRepository()
        document_repo = DocumentRepository()
        template_repo = TemplateRepository()
        print("âœ… æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        return False

# åˆ›å»ºFlaskåº”ç”¨ï¼ŒæŒ‡å®šæ¨¡æ¿å’Œé™æ€æ–‡ä»¶è·¯å¾„
app = Flask(__name__,
           template_folder=os.path.join(project_root, 'templates'),
           static_folder=os.path.join(project_root, 'static'))
CORS(app)

# Configuration
app.config['UPLOAD_FOLDER'] = os.path.join(project_root, 'uploads')
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size
app.config['ALLOWED_EXTENSIONS'] = {'txt', 'pdf', 'docx'}

# Ensure upload directory exists
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
os.makedirs(os.path.join(project_root, 'output'), exist_ok=True)

# å…¨å±€å˜é‡å­˜å‚¨åè°ƒå™¨å®ä¾‹
orchestrator_instance = None
format_coordinator = None
fill_coordinator = None
style_analyzer = None
patent_analyzer = None
image_processor = None
logger = logging.getLogger("office_doc_agent")

# åˆå§‹åŒ–æ•°æ®åº“
db_manager = None
settings_repo = None
document_repo = None
template_repo = None

# åœ¨å…¨å±€å˜é‡åˆå§‹åŒ–éƒ¨åˆ†æ·»åŠ 
enhanced_document_filler = None

# ç¡®ä¿æ•°æ®åº“åˆå§‹åŒ–
init_database()

def allowed_file(filename):
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in app.config['ALLOWED_EXTENSIONS']

def handle_batch_upload():
    """å¤„ç†æ‰¹é‡ä¸Šä¼ ï¼Œåªä¿å­˜æ–‡ä»¶ä¸è¿›è¡Œå¤„ç†"""
    try:
        if 'file' not in request.files:
            return jsonify({'success': False, 'error': 'æ²¡æœ‰æ–‡ä»¶'}), 400

        file = request.files['file']
        if file.filename == '':
            return jsonify({'success': False, 'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400

        if not allowed_file(file.filename):
            return jsonify({'success': False, 'error': 'ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼'}), 400

        # Generate unique filename
        filename = secure_filename(file.filename)
        unique_filename = f"{uuid.uuid4().hex}_{filename}"
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], unique_filename)

        # Save file
        file.save(filepath)

        print(f"ğŸ“ Batch upload file saved: {filepath}")

        return jsonify({
            'success': True,
            'file_path': filepath,
            'filename': filename,
            'uploaded_at': datetime.now().isoformat()
        })

    except Exception as e:
        print(f"âŒ Batch upload error: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

def initialize_agent(api_type="xingcheng", model_name=None):
    """Initialize the document agent with specified LLM client."""
    KB_PATH = os.path.join(project_root, "src/core/knowledge_base")
    
    if api_type == "multi":
        # ä½¿ç”¨å¤šAPIå®¢æˆ·ç«¯
        try:
            llm_client = MultiLLMClient()
            print("MultiLLMClient initialized successfully")
            return AgentOrchestrator(llm_client=llm_client, kb_path=KB_PATH)
        except Exception as e:
            print(f"Error initializing MultiLLMClient: {e}")
            print("Falling back to mock mode")
            return None
    elif api_type == "xingcheng":
        # ä½¿ç”¨è®¯é£æ˜Ÿç«API
        XINGCHENG_API_KEY = os.getenv("XINGCHENG_API_KEY")
        XINGCHENG_API_SECRET = os.getenv("XINGCHENG_API_SECRET")
        LLM_MODEL_NAME = model_name or os.getenv("LLM_MODEL_NAME", "x1")
        
        if not XINGCHENG_API_KEY:
            print("Warning: Xingcheng API key not configured, using mock mode")
            return None
        
        try:
            llm_client = XingchengLLMClient(
                api_key=XINGCHENG_API_KEY,
                api_secret=XINGCHENG_API_SECRET,
                model_name=LLM_MODEL_NAME
            )
            return AgentOrchestrator(llm_client=llm_client, kb_path=KB_PATH)
        except Exception as e:
            print(f"Error initializing XingchengLLMClient: {e}")
            print("Falling back to mock mode")
            return None
    else:
        print(f"Unknown API type: {api_type}, using mock mode")
        return None

def analyze_document_scenario(content):
    """æ™ºèƒ½åˆ†ææ–‡æ¡£åœºæ™¯å’Œç±»å‹"""
    if not content:
        return 'é€šç”¨æ–‡æ¡£', 'åŠå…¬æ–‡æ¡£', ['æ–‡æ¡£å†…å®¹åˆ†æ', 'ç»“æ„ä¼˜åŒ–å»ºè®®']

    content_lower = content.lower()

    # ä¼šè®®æ–‡æ¡£æ£€æµ‹
    meeting_keywords = ['ä¼šè®®', 'meeting', 'è®®ç¨‹', 'å†³è®®', 'è®¨è®º', 'å‚ä¼š', 'ä¼šè®®çºªè¦', 'å†³ç­–']
    if any(keyword in content_lower for keyword in meeting_keywords):
        return 'ä¼šè®®æ–‡æ¡£', 'è¿™æ˜¯ä¸€ä»½ä¼šè®®ç›¸å…³æ–‡æ¡£ï¼Œè®°å½•äº†ä¼šè®®è®®ç¨‹ã€è®¨è®ºå†…å®¹å’Œå†³ç­–ç»“æœ', [
            'ä¼šè®®ä¸»é¢˜å’Œç›®æ ‡', 'å‚ä¼šäººå‘˜ä¿¡æ¯', 'è®¨è®ºçš„å…³é”®è®®é¢˜', 'è¾¾æˆçš„å†³ç­–å’Œå…±è¯†', 'åç»­è¡ŒåŠ¨è®¡åˆ’'
        ]

    # æŠ€æœ¯æ–‡æ¡£æ£€æµ‹
    tech_keywords = ['æŠ€æœ¯', 'technical', 'ç³»ç»Ÿ', 'æ¶æ„', 'å¼€å‘', 'ä»£ç ', 'api', 'æ•°æ®åº“', 'ç®—æ³•']
    if any(keyword in content_lower for keyword in tech_keywords):
        return 'æŠ€æœ¯æ–‡æ¡£', 'è¿™æ˜¯ä¸€ä»½æŠ€æœ¯æ–‡æ¡£ï¼Œæ¶‰åŠç³»ç»Ÿè®¾è®¡ã€å¼€å‘è§„èŒƒæˆ–æŠ€æœ¯å®ç°', [
            'æŠ€æœ¯æ¶æ„è®¾è®¡', 'æ ¸å¿ƒåŠŸèƒ½æ¨¡å—', 'æ€§èƒ½å’Œå®‰å…¨è¦æ±‚', 'å¼€å‘å’Œéƒ¨ç½²æµç¨‹', 'ç»´æŠ¤å’Œä¼˜åŒ–å»ºè®®'
        ]

    # äº§å“æ–‡æ¡£æ£€æµ‹
    product_keywords = ['äº§å“', 'product', 'åŠŸèƒ½', 'éœ€æ±‚', 'ç”¨æˆ·', 'å¸‚åœº', 'ç«å“', 'è§„åˆ’']
    if any(keyword in content_lower for keyword in product_keywords):
        return 'äº§å“æ–‡æ¡£', 'è¿™æ˜¯ä¸€ä»½äº§å“ç›¸å…³æ–‡æ¡£ï¼Œæè¿°äº†äº§å“åŠŸèƒ½ã€éœ€æ±‚æˆ–å¸‚åœºç­–ç•¥', [
            'äº§å“æ ¸å¿ƒåŠŸèƒ½', 'ç›®æ ‡ç”¨æˆ·ç¾¤ä½“', 'å¸‚åœºå®šä½åˆ†æ', 'åŠŸèƒ½ä¼˜å…ˆçº§', 'äº§å“å‘å±•è·¯çº¿å›¾'
        ]

    # åˆ†ææŠ¥å‘Šæ£€æµ‹
    report_keywords = ['æŠ¥å‘Š', 'report', 'åˆ†æ', 'æ€»ç»“', 'æ•°æ®', 'ç»Ÿè®¡', 'è¶‹åŠ¿', 'ç»“è®º']
    if any(keyword in content_lower for keyword in report_keywords):
        return 'åˆ†ææŠ¥å‘Š', 'è¿™æ˜¯ä¸€ä»½åˆ†ææŠ¥å‘Šï¼ŒåŒ…å«æ•°æ®åˆ†æã€è¶‹åŠ¿æ€»ç»“å’Œç»“è®ºå»ºè®®', [
            'å…³é”®æ•°æ®æŒ‡æ ‡', 'è¶‹åŠ¿åˆ†æç»“æœ', 'é—®é¢˜è¯†åˆ«å’ŒåŸå› ', 'æ”¹è¿›å»ºè®®æ–¹æ¡ˆ', 'é¢„æœŸæ•ˆæœè¯„ä¼°'
        ]

    # å•†ä¸šæ–‡æ¡£æ£€æµ‹
    business_keywords = ['å•†ä¸š', 'business', 'åˆåŒ', 'åè®®', 'æ–¹æ¡ˆ', 'ææ¡ˆ', 'é¢„ç®—', 'æˆæœ¬']
    if any(keyword in content_lower for keyword in business_keywords):
        return 'å•†ä¸šæ–‡æ¡£', 'è¿™æ˜¯ä¸€ä»½å•†ä¸šæ–‡æ¡£ï¼Œæ¶‰åŠå•†ä¸šè®¡åˆ’ã€åˆåŒåè®®æˆ–è´¢åŠ¡åˆ†æ', [
            'å•†ä¸šç›®æ ‡å’Œç­–ç•¥', 'è´¢åŠ¡é¢„ç®—åˆ†æ', 'é£é™©è¯„ä¼°', 'åˆä½œä¼™ä¼´å…³ç³»', 'æ‰§è¡Œæ—¶é—´è¡¨'
        ]

    return 'é€šç”¨æ–‡æ¡£', 'è¿™æ˜¯ä¸€ä»½é€šç”¨åŠå…¬æ–‡æ¡£ï¼ŒåŒ…å«å¤šç§ç±»å‹çš„ä¿¡æ¯å’Œå†…å®¹', [
        'æ–‡æ¡£ä¸»è¦å†…å®¹', 'å…³é”®ä¿¡æ¯è¦ç‚¹', 'é‡è¦è§‚ç‚¹æ€»ç»“', 'è¡ŒåŠ¨å»ºè®®äº‹é¡¹'
    ]

def generate_content_summary(content, max_length=200):
    """æ™ºèƒ½ç”Ÿæˆå†…å®¹æ‘˜è¦"""
    if not content:
        return "æ–‡æ¡£å†…å®¹ä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆæ‘˜è¦ã€‚"

    # åˆ†å¥å¤„ç†
    sentences = content.replace('ã€‚', 'ã€‚\n').replace('ï¼', 'ï¼\n').replace('ï¼Ÿ', 'ï¼Ÿ\n').split('\n')
    sentences = [s.strip() for s in sentences if s.strip() and len(s.strip()) > 5]

    if not sentences:
        return content[:max_length] + ("..." if len(content) > max_length else "")

    # è¯†åˆ«å…³é”®å¥å­ï¼ˆåŒ…å«é‡è¦å…³é”®è¯çš„å¥å­ï¼‰
    important_keywords = [
        'å†³ç­–', 'å†³å®š', 'ç»“è®º', 'å»ºè®®', 'è®¡åˆ’', 'ç›®æ ‡', 'é‡è¦', 'å…³é”®',
        'æ ¸å¿ƒ', 'ä¸»è¦', 'é¦–å…ˆ', 'å…¶æ¬¡', 'æœ€å', 'æ€»ç»“', 'æ¦‚è¿°',
        'é—®é¢˜', 'è§£å†³', 'æ–¹æ¡ˆ', 'ç­–ç•¥', 'æªæ–½', 'è¡ŒåŠ¨', 'æ‰§è¡Œ'
    ]

    # ç»™å¥å­æ‰“åˆ†
    sentence_scores = []
    for i, sentence in enumerate(sentences):
        score = 0
        # ä½ç½®æƒé‡ï¼šå¼€å¤´å’Œç»“å°¾çš„å¥å­æ›´é‡è¦
        if i == 0:
            score += 3
        elif i == len(sentences) - 1:
            score += 2
        elif i < len(sentences) * 0.3:  # å‰30%
            score += 1

        # å…³é”®è¯æƒé‡
        for keyword in important_keywords:
            if keyword in sentence:
                score += 2

        # é•¿åº¦æƒé‡ï¼šé€‚ä¸­é•¿åº¦çš„å¥å­æ›´å¯èƒ½åŒ…å«é‡è¦ä¿¡æ¯
        if 20 <= len(sentence) <= 100:
            score += 1

        # æ•°å­—æƒé‡ï¼šåŒ…å«æ•°å­—çš„å¥å­é€šå¸¸æ›´é‡è¦
        import re
        if re.search(r'\d+', sentence):
            score += 1

        sentence_scores.append((sentence, score))

    # æŒ‰åˆ†æ•°æ’åºï¼Œé€‰æ‹©æœ€é‡è¦çš„å¥å­
    sentence_scores.sort(key=lambda x: x[1], reverse=True)

    # æ„å»ºæ‘˜è¦
    summary_sentences = []
    current_length = 0

    for sentence, score in sentence_scores:
        if current_length + len(sentence) <= max_length - 20:  # ç•™ä¸€äº›ä½™é‡
            summary_sentences.append(sentence)
            current_length += len(sentence)
        else:
            break

    # å¦‚æœæ²¡æœ‰é€‰ä¸­ä»»ä½•å¥å­ï¼Œä½¿ç”¨å‰å‡ å¥
    if not summary_sentences:
        summary_sentences = sentences[:2]

    # æŒ‰åŸæ–‡é¡ºåºé‡æ–°æ’åˆ—
    final_sentences = []
    for sentence in sentences:
        if sentence in summary_sentences:
            final_sentences.append(sentence)

    summary = 'ã€‚'.join(final_sentences)
    if not summary.endswith('ã€‚'):
        summary += 'ã€‚'

    # å¦‚æœè¿˜æ˜¯å¤ªé•¿ï¼Œæˆªæ–­
    if len(summary) > max_length:
        summary = summary[:max_length-3] + "..."

    return summary

def extract_key_entities(content):
    """æ™ºèƒ½æå–å…³é”®å®ä½“å’Œæ¦‚å¿µ"""
    if not content:
        return []

    import re
    entities = []

    # 1. æ—¶é—´å®ä½“æå–
    time_patterns = [
        (r'\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥', 'å…·ä½“æ—¥æœŸ'),
        (r'\d{1,2}æœˆ\d{1,2}æ—¥', 'æœˆæ—¥'),
        (r'\d{4}-\d{1,2}-\d{1,2}', 'æ—¥æœŸ'),
        (r'\d{1,2}:\d{2}', 'æ—¶é—´'),
        (r'ä¸‹å‘¨|æœ¬å‘¨|ä¸Šå‘¨|ä¸‹æœˆ|æœ¬æœˆ|ä¸Šæœˆ', 'ç›¸å¯¹æ—¶é—´')
    ]

    for pattern, type_name in time_patterns:
        matches = re.findall(pattern, content)
        for match in matches[:2]:  # é™åˆ¶æ¯ç§ç±»å‹æœ€å¤š2ä¸ª
            entities.append({'type': type_name, 'value': match})

    # 2. æ•°å€¼å®ä½“æå–
    number_patterns = [
        (r'\d+%', 'ç™¾åˆ†æ¯”'),
        (r'\d+ä¸‡å…ƒ?', 'é‡‘é¢(ä¸‡)'),
        (r'\d+äº¿å…ƒ?', 'é‡‘é¢(äº¿)'),
        (r'ï¿¥\d+', 'äººæ°‘å¸'),
        (r'\$\d+', 'ç¾å…ƒ'),
        (r'\d+äºº', 'äººæ•°'),
        (r'\d+ä¸ª', 'æ•°é‡'),
        (r'\d+é¡¹', 'é¡¹ç›®æ•°')
    ]

    for pattern, type_name in number_patterns:
        matches = re.findall(pattern, content)
        for match in matches[:2]:
            entities.append({'type': type_name, 'value': match})

    # 3. äººåæå–ï¼ˆç®€å•çš„ä¸­æ–‡äººåæ¨¡å¼ï¼‰
    name_patterns = [
        r'[å¼ ç‹æèµµåˆ˜é™ˆæ¨é»„å‘¨å´å¾å­™èƒ¡æœ±é«˜æ—ä½•éƒ­é©¬ç½—æ¢å®‹éƒ‘è°¢éŸ©å”å†¯äºè‘£è§ç¨‹æ›¹è¢é‚“è®¸å‚…æ²ˆæ›¾å½­å•è‹å¢è’‹è”¡è´¾ä¸é­è–›å¶é˜ä½™æ½˜æœæˆ´å¤é’Ÿæ±ªç”°ä»»å§œèŒƒæ–¹çŸ³å§šè°­å»–é‚¹ç†Šé‡‘é™†éƒå­”ç™½å´”åº·æ¯›é‚±ç§¦æ±Ÿå²é¡¾ä¾¯é‚µå­Ÿé¾™ä¸‡æ®µé›·é’±æ±¤å°¹é»æ˜“å¸¸æ­¦ä¹”è´ºèµ–é¾šæ–‡][ä¸€-é¾¯]{1,2}',
    ]

    for pattern in name_patterns:
        matches = re.findall(pattern, content)
        # è¿‡æ»¤æ‰ä¸€äº›å¸¸è§çš„éäººåè¯æ±‡
        filtered_matches = [m for m in matches if len(m) >= 2 and m not in ['ä¼šè®®', 'é¡¹ç›®', 'å…¬å¸', 'éƒ¨é—¨', 'äº§å“', 'æŠ€æœ¯', 'å¸‚åœº', 'æ–¹æ¡ˆ']]
        for match in filtered_matches[:3]:
            entities.append({'type': 'äººå‘˜', 'value': match})

    # 4. ç»„ç»‡æœºæ„æå–
    org_patterns = [
        r'[ä¸€-é¾¯]*éƒ¨é—¨?',
        r'[ä¸€-é¾¯]*å…¬å¸',
        r'[ä¸€-é¾¯]*å›¢é˜Ÿ',
        r'[ä¸€-é¾¯]*å°ç»„',
        r'[ä¸€-é¾¯]*ä¸­å¿ƒ'
    ]

    for pattern in org_patterns:
        matches = re.findall(pattern, content)
        filtered_matches = [m for m in matches if len(m) >= 3 and 'éƒ¨é—¨' in m or 'å…¬å¸' in m or 'å›¢é˜Ÿ' in m or 'å°ç»„' in m or 'ä¸­å¿ƒ' in m]
        for match in filtered_matches[:2]:
            entities.append({'type': 'ç»„ç»‡', 'value': match})

    # 5. å…³é”®æ¦‚å¿µæå–
    concept_keywords = [
        'äº§å“', 'é¡¹ç›®', 'æ–¹æ¡ˆ', 'è®¡åˆ’', 'ç­–ç•¥', 'ç›®æ ‡', 'ä»»åŠ¡', 'åŠŸèƒ½',
        'ç³»ç»Ÿ', 'å¹³å°', 'æœåŠ¡', 'æŠ€æœ¯', 'æ¶æ„', 'è®¾è®¡', 'å¼€å‘', 'æµ‹è¯•',
        'å¸‚åœº', 'ç”¨æˆ·', 'å®¢æˆ·', 'éœ€æ±‚', 'åé¦ˆ', 'ä½“éªŒ', 'æ»¡æ„åº¦',
        'é¢„ç®—', 'æˆæœ¬', 'æ”¶å…¥', 'åˆ©æ¶¦', 'æŠ•èµ„', 'å›æŠ¥', 'é£é™©'
    ]

    found_concepts = []
    for keyword in concept_keywords:
        if keyword in content and keyword not in found_concepts:
            found_concepts.append(keyword)
            entities.append({'type': 'å…³é”®æ¦‚å¿µ', 'value': keyword})
            if len(found_concepts) >= 5:  # æœ€å¤š5ä¸ªæ¦‚å¿µ
                break

    # 6. å¦‚æœå®ä½“å¤ªå°‘ï¼Œæ·»åŠ ä¸€äº›ä»å†…å®¹ä¸­æå–çš„é‡è¦è¯æ±‡
    if len(entities) < 3:
        # æå–å‡ºç°é¢‘ç‡è¾ƒé«˜çš„è¯æ±‡
        words = re.findall(r'[ä¸€-é¾¯]{2,4}', content)
        word_count = {}
        for word in words:
            if len(word) >= 2 and word not in ['è¿™ä¸ª', 'é‚£ä¸ª', 'å¯ä»¥', 'éœ€è¦', 'è¿›è¡Œ', 'å®ç°', 'å®Œæˆ', 'å»ºè®®']:
                word_count[word] = word_count.get(word, 0) + 1

        # é€‰æ‹©å‡ºç°æ¬¡æ•°æœ€å¤šçš„è¯æ±‡
        sorted_words = sorted(word_count.items(), key=lambda x: x[1], reverse=True)
        for word, count in sorted_words[:3]:
            if count >= 2:  # è‡³å°‘å‡ºç°2æ¬¡
                entities.append({'type': 'é‡è¦è¯æ±‡', 'value': f"{word}(å‡ºç°{count}æ¬¡)"})

    # å»é‡å¹¶é™åˆ¶æ•°é‡
    seen = set()
    unique_entities = []
    for entity in entities:
        key = f"{entity['type']}:{entity['value']}"
        if key not in seen:
            seen.add(key)
            unique_entities.append(entity)

    return unique_entities[:10]  # æœ€å¤šè¿”å›10ä¸ªå®ä½“

def analyze_content_depth(content, key_points):
    """æ·±åº¦åˆ†ææ–‡æ¡£å†…å®¹ç‰¹å¾"""
    if not content:
        return {
            'main_topics': [],
            'sentiment': 'æ— å†…å®¹',
            'complexity': 'æ— å†…å®¹',
            'language': 'æœªçŸ¥',
            'formality': 'æœªçŸ¥',
            'urgency': 'æ— ',
            'completeness': 'ä¸å®Œæ•´'
        }

    import re

    # 1. ä¸»è¦è¯é¢˜åˆ†æ
    main_topics = key_points[:3] if key_points else ['æ–‡æ¡£å†…å®¹']

    # 2. æƒ…æ„Ÿå€¾å‘åˆ†æ
    positive_words = ['æˆåŠŸ', 'ä¼˜ç§€', 'è‰¯å¥½', 'æ»¡æ„', 'èµåŒ', 'æ”¯æŒ', 'åŒæ„', 'æ‰¹å‡†', 'é€šè¿‡', 'å®Œæˆ', 'è¾¾æˆ', 'å®ç°', 'æå‡', 'æ”¹å–„', 'ä¼˜åŒ–']
    negative_words = ['å¤±è´¥', 'é—®é¢˜', 'å›°éš¾', 'æŒ‘æˆ˜', 'é£é™©', 'å»¶è¿Ÿ', 'æ¨è¿Ÿ', 'å–æ¶ˆ', 'æ‹’ç»', 'åå¯¹', 'ä¸æ»¡', 'æŠ•è¯‰', 'é”™è¯¯', 'ç¼ºé™·', 'ä¸è¶³']
    neutral_words = ['è®¨è®º', 'åˆ†æ', 'è€ƒè™‘', 'å»ºè®®', 'è®¡åˆ’', 'å®‰æ’', 'å‡†å¤‡', 'è¿›è¡Œ', 'å®æ–½', 'æ‰§è¡Œ']

    positive_count = sum(1 for word in positive_words if word in content)
    negative_count = sum(1 for word in negative_words if word in content)
    neutral_count = sum(1 for word in neutral_words if word in content)

    if positive_count > negative_count and positive_count > 0:
        sentiment = 'ç§¯æ'
    elif negative_count > positive_count and negative_count > 0:
        sentiment = 'æ¶ˆæ'
    elif neutral_count > 0:
        sentiment = 'ä¸­æ€§'
    else:
        sentiment = 'å®¢è§‚'

    # 3. å¤æ‚åº¦åˆ†æ
    word_count = len(content.split())
    sentence_count = len([s for s in re.split(r'[ã€‚ï¼ï¼Ÿ]', content) if s.strip()])
    avg_sentence_length = word_count / max(sentence_count, 1)

    # æ£€æŸ¥ä¸“ä¸šæœ¯è¯­
    technical_terms = ['ç³»ç»Ÿ', 'æ¶æ„', 'æŠ€æœ¯', 'ç®—æ³•', 'æ•°æ®åº“', 'æ¥å£', 'API', 'æ¡†æ¶', 'æ¨¡å—', 'ç»„ä»¶']
    business_terms = ['æˆ˜ç•¥', 'ç­–ç•¥', 'å¸‚åœº', 'å®¢æˆ·', 'ç”¨æˆ·', 'äº§å“', 'æœåŠ¡', 'æ”¶ç›Š', 'æˆæœ¬', 'é¢„ç®—']
    complex_terms = technical_terms + business_terms

    term_count = sum(1 for term in complex_terms if term in content)

    if word_count > 500 or avg_sentence_length > 20 or term_count > 5:
        complexity = 'å¤æ‚'
    elif word_count > 200 or avg_sentence_length > 15 or term_count > 2:
        complexity = 'ä¸­ç­‰'
    elif word_count > 50:
        complexity = 'ç®€å•'
    else:
        complexity = 'æç®€'

    # 4. è¯­è¨€ç‰¹å¾åˆ†æ
    chinese_chars = len(re.findall(r'[ä¸€-é¾¯]', content))
    total_chars = len(content)
    chinese_ratio = chinese_chars / max(total_chars, 1)

    if chinese_ratio > 0.7:
        language = 'ä¸­æ–‡ä¸ºä¸»'
    elif chinese_ratio > 0.3:
        language = 'ä¸­è‹±æ··åˆ'
    else:
        language = 'è‹±æ–‡ä¸ºä¸»'

    # 5. æ­£å¼ç¨‹åº¦åˆ†æ
    formal_words = ['æ‚¨', 'æ•¬è¯·', 'è°¨æ­¤', 'ç‰¹æ­¤', 'å…¹', 'æ®æ­¤', 'ç»¼ä¸Š', 'é‰´äº', 'åŸºäº']
    informal_words = ['ä½ ', 'å’±ä»¬', 'å¤§å®¶', 'å“ˆå“ˆ', 'å—¯', 'å‘ƒ', 'å“¦']

    formal_count = sum(1 for word in formal_words if word in content)
    informal_count = sum(1 for word in informal_words if word in content)

    if formal_count > informal_count and formal_count > 0:
        formality = 'æ­£å¼'
    elif informal_count > 0:
        formality = 'éæ­£å¼'
    else:
        formality = 'ä¸­æ€§'

    # 6. ç´§æ€¥ç¨‹åº¦åˆ†æ
    urgent_words = ['ç´§æ€¥', 'ç«‹å³', 'é©¬ä¸Š', 'å°½å¿«', 'æ€¥éœ€', 'ç«æ€¥', 'åŠ æ€¥', 'ä¼˜å…ˆ', 'é‡è¦', 'å…³é”®']
    urgent_count = sum(1 for word in urgent_words if word in content)

    if urgent_count >= 3:
        urgency = 'é«˜'
    elif urgent_count >= 1:
        urgency = 'ä¸­'
    else:
        urgency = 'ä½'

    # 7. å®Œæ•´æ€§åˆ†æ
    structure_indicators = ['ç›®æ ‡', 'èƒŒæ™¯', 'æ–¹æ¡ˆ', 'ç»“è®º', 'å»ºè®®', 'è®¡åˆ’', 'æ—¶é—´', 'è´£ä»»äºº']
    structure_count = sum(1 for indicator in structure_indicators if indicator in content)

    if structure_count >= 5:
        completeness = 'å®Œæ•´'
    elif structure_count >= 3:
        completeness = 'è¾ƒå®Œæ•´'
    elif structure_count >= 1:
        completeness = 'åŸºæœ¬å®Œæ•´'
    else:
        completeness = 'ä¸å®Œæ•´'

    return {
        'main_topics': main_topics,
        'sentiment': sentiment,
        'complexity': complexity,
        'language': language,
        'formality': formality,
        'urgency': urgency,
        'completeness': completeness,
        'word_count': word_count,
        'sentence_count': sentence_count,
        'avg_sentence_length': round(avg_sentence_length, 1)
    }

def analyze_content_gaps(content, doc_type):
    """åˆ†ææ–‡æ¡£å†…å®¹ç¼ºå¤±å’Œæ”¹è¿›ç‚¹"""
    if not content:
        return ["æ–‡æ¡£å†…å®¹ä¸ºç©ºï¼Œéœ€è¦æ·»åŠ å®è´¨æ€§å†…å®¹"]

    content_lower = content.lower()
    gaps = []

    # é€šç”¨å†…å®¹åˆ†æ
    if len(content) < 100:
        gaps.append("æ–‡æ¡£å†…å®¹è¿‡äºç®€çŸ­ï¼Œå»ºè®®è¡¥å……æ›´å¤šè¯¦ç»†ä¿¡æ¯")

    if 'ã€‚' not in content and '!' not in content and '?' not in content:
        gaps.append("å»ºè®®ä½¿ç”¨æ ‡ç‚¹ç¬¦å·æé«˜æ–‡æ¡£å¯è¯»æ€§")

    # æ£€æŸ¥æ˜¯å¦æœ‰æ ‡é¢˜ç»“æ„
    if not any(marker in content for marker in ['#', 'ä¸€ã€', '1.', 'ï¼ˆä¸€ï¼‰', 'ç¬¬ä¸€']):
        gaps.append("å»ºè®®æ·»åŠ æ¸…æ™°çš„æ ‡é¢˜å’Œç« èŠ‚ç»“æ„")

    # æ ¹æ®æ–‡æ¡£ç±»å‹è¿›è¡Œå…·ä½“åˆ†æ
    if doc_type == 'ä¼šè®®æ–‡æ¡£':
        if 'æ—¶é—´' not in content_lower and 'æ—¥æœŸ' not in content_lower:
            gaps.append("ç¼ºå°‘ä¼šè®®æ—¶é—´ä¿¡æ¯ï¼Œå»ºè®®è¡¥å……å…·ä½“çš„ä¼šè®®æ—¥æœŸå’Œæ—¶é—´")
        if 'å‚ä¼š' not in content_lower and 'å‚ä¸' not in content_lower and 'å‡ºå¸­' not in content_lower:
            gaps.append("ç¼ºå°‘å‚ä¼šäººå‘˜ä¿¡æ¯ï¼Œå»ºè®®æ˜ç¡®è®°å½•å‚ä¼šäººå‘˜åå•")
        if 'å†³ç­–' not in content_lower and 'å†³å®š' not in content_lower and 'ç»“è®º' not in content_lower:
            gaps.append("ç¼ºå°‘æ˜ç¡®çš„å†³ç­–ç»“æœï¼Œå»ºè®®è¡¥å……ä¼šè®®è¾¾æˆçš„å…·ä½“å†³ç­–")
        if 'è¡ŒåŠ¨' not in content_lower and 'æ‰§è¡Œ' not in content_lower and 'è´Ÿè´£' not in content_lower:
            gaps.append("ç¼ºå°‘åç»­è¡ŒåŠ¨è®¡åˆ’ï¼Œå»ºè®®æ˜ç¡®è´£ä»»äººå’Œæ‰§è¡Œæ—¶é—´èŠ‚ç‚¹")

    elif doc_type == 'æŠ€æœ¯æ–‡æ¡£':
        if 'æ¶æ„' not in content_lower and 'è®¾è®¡' not in content_lower:
            gaps.append("ç¼ºå°‘æŠ€æœ¯æ¶æ„è¯´æ˜ï¼Œå»ºè®®è¡¥å……ç³»ç»Ÿè®¾è®¡å’Œæ¶æ„å›¾")
        if 'api' not in content_lower and 'æ¥å£' not in content_lower:
            gaps.append("ç¼ºå°‘æ¥å£æ–‡æ¡£ï¼Œå»ºè®®è¡¥å……APIæ¥å£è¯´æ˜å’Œç¤ºä¾‹")
        if 'æµ‹è¯•' not in content_lower and 'éªŒè¯' not in content_lower:
            gaps.append("ç¼ºå°‘æµ‹è¯•è¯´æ˜ï¼Œå»ºè®®è¡¥å……æµ‹è¯•æ–¹æ³•å’ŒéªŒè¯æ­¥éª¤")

    elif doc_type == 'äº§å“æ–‡æ¡£':
        if 'ç”¨æˆ·' not in content_lower and 'å®¢æˆ·' not in content_lower:
            gaps.append("ç¼ºå°‘ç”¨æˆ·åˆ†æï¼Œå»ºè®®è¡¥å……ç›®æ ‡ç”¨æˆ·ç¾¤ä½“å’Œéœ€æ±‚åˆ†æ")
        if 'åŠŸèƒ½' not in content_lower and 'ç‰¹æ€§' not in content_lower:
            gaps.append("ç¼ºå°‘åŠŸèƒ½è¯´æ˜ï¼Œå»ºè®®è¯¦ç»†æè¿°äº§å“æ ¸å¿ƒåŠŸèƒ½")
        if 'ç«å“' not in content_lower and 'å¸‚åœº' not in content_lower:
            gaps.append("ç¼ºå°‘å¸‚åœºåˆ†æï¼Œå»ºè®®è¡¥å……ç«å“åˆ†æå’Œå¸‚åœºå®šä½")

    elif doc_type == 'åˆ†ææŠ¥å‘Š':
        if 'æ•°æ®' not in content_lower and 'ç»Ÿè®¡' not in content_lower:
            gaps.append("ç¼ºå°‘æ•°æ®æ”¯æ’‘ï¼Œå»ºè®®è¡¥å……å…·ä½“çš„æ•°æ®å’Œç»Ÿè®¡ä¿¡æ¯")
        if 'å›¾è¡¨' not in content_lower and 'å›¾' not in content_lower:
            gaps.append("ç¼ºå°‘å¯è§†åŒ–å±•ç¤ºï¼Œå»ºè®®æ·»åŠ å›¾è¡¨å’Œæ•°æ®å¯è§†åŒ–")
        if 'ç»“è®º' not in content_lower and 'å»ºè®®' not in content_lower:
            gaps.append("ç¼ºå°‘æ˜ç¡®ç»“è®ºï¼Œå»ºè®®è¡¥å……åˆ†æç»“è®ºå’Œæ”¹è¿›å»ºè®®")

    return gaps if gaps else ["æ–‡æ¡£ç»“æ„å®Œæ•´ï¼Œå»ºè®®è¿›ä¸€æ­¥ä¼˜åŒ–å†…å®¹è¡¨è¾¾å’Œæ ¼å¼è§„èŒƒ"]

def generate_improvement_suggestions(content, doc_type):
    """æ ¹æ®æ–‡æ¡£å®é™…å†…å®¹ç”Ÿæˆæ™ºèƒ½æ”¹è¿›å»ºè®®"""
    if not content:
        return ["æ–‡æ¡£å†…å®¹ä¸ºç©ºï¼Œè¯·æ·»åŠ å®è´¨æ€§å†…å®¹"]

    # åˆ†æå†…å®¹ç¼ºå¤±
    content_gaps = analyze_content_gaps(content, doc_type)

    # åˆ†æå†…å®¹è´¨é‡
    quality_suggestions = []

    # æ£€æŸ¥å†…å®¹é•¿åº¦å’Œç»“æ„
    sentences = content.replace('ã€‚', 'ã€‚\n').replace('ï¼', 'ï¼\n').replace('ï¼Ÿ', 'ï¼Ÿ\n').split('\n')
    sentences = [s.strip() for s in sentences if s.strip()]

    if len(sentences) < 3:
        quality_suggestions.append("å»ºè®®æ‰©å±•å†…å®¹ï¼Œå¢åŠ æ›´å¤šè¯¦ç»†è¯´æ˜å’ŒèƒŒæ™¯ä¿¡æ¯")

    # æ£€æŸ¥æ˜¯å¦æœ‰å…·ä½“çš„æ•°å­—ã€æ—¶é—´ç­‰å…³é”®ä¿¡æ¯
    import re
    has_numbers = bool(re.search(r'\d+', content))
    has_dates = bool(re.search(r'\d{4}å¹´|\d{1,2}æœˆ|\d{1,2}æ—¥', content))

    if not has_numbers and doc_type in ['åˆ†ææŠ¥å‘Š', 'æŠ€æœ¯æ–‡æ¡£']:
        quality_suggestions.append("å»ºè®®è¡¥å……å…·ä½“çš„æ•°å­—å’Œé‡åŒ–æŒ‡æ ‡")

    if not has_dates and doc_type in ['ä¼šè®®æ–‡æ¡£', 'åˆ†ææŠ¥å‘Š']:
        quality_suggestions.append("å»ºè®®æ·»åŠ æ˜ç¡®çš„æ—¶é—´ä¿¡æ¯å’Œæ—¶é—´èŠ‚ç‚¹")

    # æ£€æŸ¥æ˜¯å¦æœ‰è¡ŒåŠ¨å¯¼å‘çš„å†…å®¹
    action_words = ['è®¡åˆ’', 'æ‰§è¡Œ', 'å®æ–½', 'å®Œæˆ', 'è´Ÿè´£', 'å®‰æ’', 'æ¨è¿›']
    has_actions = any(word in content for word in action_words)

    if not has_actions and doc_type in ['ä¼šè®®æ–‡æ¡£', 'äº§å“æ–‡æ¡£']:
        quality_suggestions.append("å»ºè®®æ·»åŠ å…·ä½“çš„è¡ŒåŠ¨è®¡åˆ’å’Œæ‰§è¡Œæ­¥éª¤")

    # åˆå¹¶å»ºè®®å¹¶å»é‡
    all_suggestions = content_gaps + quality_suggestions

    # é™åˆ¶å»ºè®®æ•°é‡ï¼Œé€‰æ‹©æœ€é‡è¦çš„
    return all_suggestions[:6] if all_suggestions else ["æ–‡æ¡£è´¨é‡è‰¯å¥½ï¼Œå»ºè®®ç»§ç»­ä¿æŒ"]

def mock_process_document(file_path):
    """Mock document processing for testing without API."""
    print(f"ğŸ­ MOCK PROCESSING STARTED")
    print(f"ğŸ­ File path: {file_path}")

    try:
        content = ""
        file_exists = os.path.exists(file_path)
        print(f"ğŸ­ File exists: {file_exists}")

        if file_exists:
            # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©åˆé€‚çš„è¯»å–æ–¹æ³•
            try:
                file_extension = os.path.splitext(file_path)[1].lower()
                file_size = os.path.getsize(file_path)
                print(f"ğŸ­ File extension: {file_extension}")
                print(f"ğŸ­ File size: {file_size} bytes")

                if file_extension == '.docx':
                    print(f"ğŸ­ Processing Word document...")
                    # ä½¿ç”¨python-docxè¯»å–Wordæ–‡æ¡£
                    try:
                        print(f"ğŸ­ Importing python-docx...")
                        from docx import Document
                        print(f"ğŸ­ Creating Document object...")
                        doc = Document(file_path)
                        print(f"ğŸ­ Document loaded, extracting paragraphs...")
                        content_parts = []
                        paragraph_count = 0
                        for paragraph in doc.paragraphs:
                            paragraph_count += 1
                            if paragraph.text.strip():
                                content_parts.append(paragraph.text.strip())
                        print(f"ğŸ­ Found {paragraph_count} paragraphs, {len(content_parts)} with content")
                        content = '\n'.join(content_parts)
                        if not content:
                            content = "Wordæ–‡æ¡£è§£ææˆåŠŸï¼Œä½†å†…å®¹ä¸ºç©ºã€‚"
                        print(f"ğŸ­ Word document processed successfully: {len(content)} characters")
                    except Exception as docx_error:
                        print(f"âŒ Error reading DOCX file: {docx_error}")
                        print(f"âŒ Error type: {type(docx_error).__name__}")
                        import traceback
                        print(f"âŒ Traceback: {traceback.format_exc()}")
                        content = "Wordæ–‡æ¡£æ ¼å¼ï¼Œä½†è§£æå¤±è´¥ã€‚ä½¿ç”¨æ¨¡æ‹Ÿå†…å®¹è¿›è¡Œæ¼”ç¤ºã€‚"

                elif file_extension == '.pdf':
                    # ä½¿ç”¨PyPDF2è¯»å–PDFæ–‡æ¡£
                    try:
                        import PyPDF2
                        content_parts = []
                        with open(file_path, 'rb') as f:
                            reader = PyPDF2.PdfReader(f)
                            for page in reader.pages:
                                page_text = page.extract_text()
                                if page_text.strip():
                                    content_parts.append(page_text.strip())
                        content = '\n'.join(content_parts)
                        if not content:
                            content = "PDFæ–‡æ¡£è§£ææˆåŠŸï¼Œä½†å†…å®¹ä¸ºç©ºã€‚"
                    except Exception as pdf_error:
                        print(f"Error reading PDF file: {pdf_error}")
                        content = "PDFæ–‡æ¡£æ ¼å¼ï¼Œä½†è§£æå¤±è´¥ã€‚ä½¿ç”¨æ¨¡æ‹Ÿå†…å®¹è¿›è¡Œæ¼”ç¤ºã€‚"

                else:
                    # æ–‡æœ¬æ–‡ä»¶ï¼Œå°è¯•ä¸åŒçš„ç¼–ç 
                    encodings = ['utf-8', 'gbk', 'gb2312', 'latin-1']
                    for encoding in encodings:
                        try:
                            with open(file_path, 'r', encoding=encoding) as f:
                                content = f.read()
                            break
                        except UnicodeDecodeError:
                            continue

                    if not content:
                        content = "æ–‡æœ¬æ–‡ä»¶è¯»å–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå†…å®¹è¿›è¡Œæ¼”ç¤ºã€‚"

            except Exception as read_error:
                print(f"Error reading file: {read_error}")
                content = f"æ–‡ä»¶è¯»å–å¤±è´¥ ({file_extension})ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå†…å®¹è¿›è¡Œæ¼”ç¤ºã€‚"
        else:
            content = "æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå†…å®¹è¿›è¡Œæ¼”ç¤ºã€‚"

        # åˆ†ææ–‡æ¡£å†…å®¹
        lines = content.count('\n') + 1 if content else 1
        paragraphs = max(content.count('\n\n') + 1, 1) if content else 1
        characters = len(content) if content else 0

        # ä½¿ç”¨AIåˆ†æåŠŸèƒ½è¿›è¡Œæ™ºèƒ½æ–‡æ¡£åˆ†æ
        print(f"ğŸ­ Starting intelligent document analysis...")
        doc_type, scenario, key_points = analyze_document_scenario(content)
        print(f"ğŸ­ Document type identified: {doc_type}")

        # ç”Ÿæˆå†…å®¹æ‘˜è¦
        content_summary = generate_content_summary(content)
        print(f"ğŸ­ Content summary generated: {len(content_summary)} characters")

        # æå–å…³é”®å®ä½“
        entities = extract_key_entities(content)
        print(f"ğŸ­ Extracted {len(entities)} key entities")

        # ç”Ÿæˆæ”¹è¿›å»ºè®®
        improvement_suggestions = generate_improvement_suggestions(content, doc_type)
        print(f"ğŸ­ Generated {len(improvement_suggestions)} improvement suggestions")

        # ç”Ÿæˆæ™ºèƒ½å»ºè®®
        suggestions = [
            'å»ºè®®å¢åŠ æ›´å¤šå…·ä½“æ•°æ®æ”¯æ’‘',
            'å¯ä»¥æ·»åŠ å›¾è¡¨å’Œå¯è§†åŒ–å†…å®¹',
            'æ–‡æ¡£ç»“æ„å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–',
            'å»ºè®®æ·»åŠ ç›®å½•å’Œç´¢å¼•',
            'è€ƒè™‘å¢åŠ æ€»ç»“å’Œè¦ç‚¹æç‚¼'
        ]

        # æ ¹æ®æ–‡æ¡£ç±»å‹è°ƒæ•´å»ºè®®
        if doc_type == 'ä¼šè®®æ–‡æ¡£':
            suggestions = [
                'å»ºè®®æ˜ç¡®ä¼šè®®å†³ç­–å’Œè´£ä»»äºº',
                'æ·»åŠ åç»­è¡ŒåŠ¨æ—¶é—´èŠ‚ç‚¹',
                'å®Œå–„ä¼šè®®å‚ä¸è€…ä¿¡æ¯'
            ]
        elif doc_type == 'æŠ€æœ¯æ–‡æ¡£':
            suggestions = [
                'å»ºè®®æ·»åŠ æŠ€æœ¯æ¶æ„å›¾',
                'è¡¥å……æ€§èƒ½æµ‹è¯•æ•°æ®',
                'å¢åŠ ä»£ç ç¤ºä¾‹å’Œé…ç½®è¯´æ˜'
            ]

        # ç”Ÿæˆå®Œæ•´çš„AIåˆ†æç»“æœ
        print(f"ğŸ­ Generating comprehensive AI analysis result...")
        print(f"ğŸ­ Content length: {len(content)} characters")
        print(f"ğŸ­ Document type: {doc_type}")
        print(f"ğŸ­ Lines: {lines}, Paragraphs: {paragraphs}")

        result = {
            # åŸå§‹æ–‡æ¡£å†…å®¹
            'text_content': content,
            'content_summary': content_summary,

            # æ–‡æ¡£ç»“æ„ä¿¡æ¯
            'structure_info': {
                'lines': lines,
                'paragraphs': paragraphs,
                'characters': characters,
                'words': len(content.split()) if content else 0,
                'file_exists': file_exists,
                'file_readable': bool(content and content != "æ— æ³•è¯»å–æ–‡ä»¶å†…å®¹ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå†…å®¹è¿›è¡Œæ¼”ç¤ºã€‚"),
                'estimated_reading_time': f"{max(1, len(content.split()) // 200)} åˆ†é’Ÿ" if content else "0 åˆ†é’Ÿ"
            },

            # æ™ºèƒ½åœºæ™¯åˆ†æ
            'scenario_analysis': {
                'document_type': doc_type,
                'scenario': scenario,
                'key_points': key_points,
                'confidence': 0.85 if content else 0.5,
                'analysis_depth': 'comprehensive'
            },

            # å…³é”®å®ä½“æå–
            'key_entities': entities,

            # æ™ºèƒ½å†…å®¹åˆ†æ
            'content_analysis': analyze_content_depth(content, key_points),

            # æ”¹è¿›å»ºè®®
            'suggestions': improvement_suggestions,

            # è´¨é‡è¯„ä¼°
            'quality_assessment': {
                'completeness': 0.8 if len(content.split()) > 50 else 0.5,
                'clarity': 0.7,
                'structure': 0.6 if paragraphs > 1 else 0.4,
                'overall_score': 0.7,
                'areas_for_improvement': ['ç»“æ„ä¼˜åŒ–', 'å†…å®¹è¡¥å……', 'æ ¼å¼è§„èŒƒ']
            },

            # å¤„ç†çŠ¶æ€
            'processing_status': 'completed',
            'mock_mode': True,
            'processing_time': 'æ¨¡æ‹Ÿå¤„ç†æ—¶é—´: 2.3ç§’',
            'ai_features_used': [
                'æ™ºèƒ½æ–‡æ¡£åˆ†ç±»',
                'å†…å®¹æ‘˜è¦ç”Ÿæˆ',
                'å…³é”®å®ä½“æå–',
                'åœºæ™¯åˆ†æ',
                'æ”¹è¿›å»ºè®®ç”Ÿæˆ',
                'è´¨é‡è¯„ä¼°'
            ]
        }

        print(f"ğŸ­ Mock result generated successfully")
        print(f"ğŸ­ Result keys: {list(result.keys())}")
        return result

    except Exception as e:
        print(f"âŒ MOCK PROCESSING ERROR:")
        print(f"   - Error type: {type(e).__name__}")
        print(f"   - Error message: {str(e)}")
        import traceback
        print(f"   - Full traceback:")
        print(traceback.format_exc())

        # è¿”å›åŸºæœ¬çš„é”™è¯¯æ¢å¤ç»“æœ
        print(f"ğŸ­ Returning error recovery result...")
        return {
            'text_content': 'å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œè¿”å›åŸºæœ¬æ¨¡æ‹Ÿç»“æœ',
            'structure_info': {
                'lines': 1,
                'paragraphs': 1,
                'characters': 20,
                'error': str(e)
            },
            'scenario_analysis': {
                'document_type': 'é”™è¯¯æ¢å¤æ¨¡å¼',
                'scenario': 'ç³»ç»Ÿå¼‚å¸¸',
                'key_points': ['å¤„ç†å¼‚å¸¸', 'é”™è¯¯æ¢å¤'],
                'confidence': 0.1
            },
            'suggestions': [
                'è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®',
                'å°è¯•é‡æ–°ä¸Šä¼ æ–‡ä»¶',
                'è”ç³»æŠ€æœ¯æ”¯æŒ'
            ],
            'processing_status': 'error_recovery',
            'mock_mode': True,
            'error': str(e)
        }

@app.route('/')
def index():
    """Serve the main web interface."""
    return render_template('enhanced-frontend-complete.html')

@app.route('/demo')
def demo():
    """Demo page"""
    return render_template('demo.html')

@app.route('/dashboard')
def dashboard():
    """Performance monitoring dashboard"""
    return render_template('dashboard.html')

@app.route('/enhanced-frontend-complete')
def enhanced_frontend_complete():
    """Enhanced frontend complete page"""
    return render_template('enhanced-frontend-complete.html')

@app.route('/examples/<filename>')
def download_example(filename):
    """Download example files."""
    try:
        examples_dir = os.path.join(project_root, 'examples')
        return send_from_directory(examples_dir, filename, as_attachment=True)
    except Exception as e:
        return jsonify({'error': f'æ–‡ä»¶ä¸‹è½½å¤±è´¥: {str(e)}'}), 404

@app.route('/debug_frontend.html')
def debug_frontend():
    """Serve the debug frontend page."""
    try:
        with open('debug_frontend.html', 'r', encoding='utf-8') as f:
            content = f.read()
        return content
    except FileNotFoundError:
        return "Debug frontend page not found", 404

@app.route('/test_ai_features.html')
def test_ai_features():
    """Serve the AI features test page."""
    try:
        with open('test_ai_features.html', 'r', encoding='utf-8') as f:
            content = f.read()
        return content
    except FileNotFoundError:
        return "AI features test page not found", 404

@app.route('/api/upload', methods=['POST'])
def upload_file():
    """Handle file upload and processing."""
    with PerformanceTimer('file_upload_and_processing') as timer:
        print("=" * 80)
        print("ğŸš€ UPLOAD REQUEST RECEIVED")
        print("=" * 80)
        print(f"â° Timestamp: {datetime.now().isoformat()}")
        print(f"ğŸŒ Remote address: {request.remote_addr}")
        print(f"ğŸ”— User agent: {request.headers.get('User-Agent', 'Unknown')}")

        # æ£€æŸ¥æ˜¯å¦æ˜¯æ‰¹é‡å¤„ç†ä¸Šä¼ ï¼ˆä¸è¿›è¡Œå¤„ç†ï¼Œåªä¿å­˜æ–‡ä»¶ï¼‰
        batch_upload = request.form.get('batch_upload', 'false').lower() == 'true'
        print(f"ğŸ“¦ Batch upload mode: {batch_upload}")

        if batch_upload:
            print("ğŸ”„ Redirecting to batch upload handler")
            return handle_batch_upload()

        # Debug request information
        print(f"ğŸ“‹ Request method: {request.method}")
        print(f"ğŸ“‹ Request content type: {request.content_type}")
        print(f"ğŸ“‹ Request files: {list(request.files.keys())}")
        print(f"ğŸ“‹ Request form data: {dict(request.form)}")
        print(f"ğŸ“‹ Request headers (selected):")
        for header in ['Content-Type', 'Content-Length', 'Accept', 'Origin', 'Referer']:
            value = request.headers.get(header)
            if value:
                print(f"     {header}: {value}")

        # æ£€æŸ¥ä¸Šä¼ æ–‡ä»¶å¤¹é…ç½®
        upload_folder = app.config.get('UPLOAD_FOLDER', 'uploads')
        print(f"ğŸ“ Upload folder configured: {upload_folder}")
        print(f"ğŸ“ Upload folder exists: {os.path.exists(upload_folder)}")
        print(f"ğŸ“ Upload folder writable: {os.access(upload_folder, os.W_OK) if os.path.exists(upload_folder) else 'N/A'}")

        if 'file' not in request.files:
            print("âŒ ERROR: No file provided in request")
            return jsonify({'success': False, 'error': 'No file provided'}), 400

        file = request.files['file']
        if file.filename == '':
            print("âŒ ERROR: No file selected")
            return jsonify({'success': False, 'error': 'No file selected'}), 400

        print(f"ğŸ“„ File info:")
        print(f"   - Filename: {file.filename}")
        print(f"   - Content type: {file.content_type}")

        # Check file size
        file.seek(0, 2)  # Seek to end
        file_size = file.tell()
        file.seek(0)  # Reset to beginning
        print(f"   - File size: {file_size} bytes")

        if file_size > app.config['MAX_CONTENT_LENGTH']:
            print(f"âŒ ERROR: File size exceeds limit: {file_size} bytes")
            return jsonify({'success': False, 'error': 'File too large'}), 413

        if not allowed_file(file.filename):
            print(f"âŒ ERROR: File type not allowed: {file.filename}")
            return jsonify({'success': False, 'error': 'Unsupported file type'}), 400

        # è·å–APIç±»å‹å’Œæ¨¡å‹åç§°
        api_type = request.form.get('api_type', 'xingcheng')
        model_name = request.form.get('model_name', None)

        print(f"ğŸ”§ Processing configuration:")
        print(f"   - API type: {api_type}")
        print(f"   - Model name: {model_name}")
        
        # Generate unique filename
        filename = file.filename or 'uploaded_file'
        filename = secure_filename(filename)
        unique_filename = f"{uuid.uuid4().hex}_{filename}"
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], unique_filename)
        
        print(f"Processing file: {filename}")
        print(f"File path: {filepath}")
        print(f"API type: {api_type}, Model: {model_name}")
        
        # Save file
        print(f"ğŸ’¾ Saving file to: {filepath}")
        print(f"ğŸ’¾ Directory exists: {os.path.exists(os.path.dirname(filepath))}")
        print(f"ğŸ’¾ Directory writable: {os.access(os.path.dirname(filepath), os.W_OK)}")

        try:
            file.save(filepath)
            print(f"âœ… File saved successfully")
        except Exception as save_error:
            print(f"âŒ ERROR: File save failed with exception: {save_error}")
            print(f"âŒ Exception type: {type(save_error).__name__}")
            print(f"âŒ Exception args: {save_error.args}")
            return jsonify({'success': False, 'error': f'File save failed: {str(save_error)}'}), 500

        # Verify file exists and is readable
        if os.path.exists(filepath):
            file_size_on_disk = os.path.getsize(filepath)
            print(f"âœ… File verified on disk: {file_size_on_disk} bytes")
            print(f"âœ… File readable: {os.access(filepath, os.R_OK)}")

            # éªŒè¯æ–‡ä»¶å†…å®¹å®Œæ•´æ€§
            if file_size_on_disk != file_size:
                print(f"âš ï¸ WARNING: File size mismatch! Original: {file_size}, On disk: {file_size_on_disk}")
            else:
                print(f"âœ… File size verification passed")
        else:
            print(f"âŒ ERROR: File not found on disk after save!")
            print(f"âŒ Attempted path: {filepath}")
            print(f"âŒ Directory listing: {os.listdir(os.path.dirname(filepath)) if os.path.exists(os.path.dirname(filepath)) else 'Directory not found'}")
            return jsonify({'success': False, 'error': 'File save failed - file not found on disk'}), 500

        # è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼
        import hashlib
        with open(filepath, 'rb') as f:
            file_hash = hashlib.md5(f.read()).hexdigest()

        # åˆ›å»ºæ•°æ®åº“è®°å½•
        document_record_id = None
        if document_repo is not None:
            try:
                record = DocumentRecord(
                    original_filename=filename,
                    file_path=filepath,
                    file_size=file_size_on_disk,
                    file_hash=file_hash,
                    document_type=DocumentType.GENERAL_DOCUMENT,  # ç¨åä¼šæ›´æ–°
                    intent_type=IntentType.GENERAL_PROCESSING,    # ç¨åä¼šæ›´æ–°
                    processing_status=ProcessingStatus.PROCESSING,
                    confidence_score=0.0
                )
                document_record_id = document_repo.create_document_record(record)
                print(f"ğŸ“ Created database record with ID: {document_record_id}")
            except Exception as e:
                print(f"âš ï¸ Failed to create database record: {e}")
                # ç»§ç»­å¤„ç†ï¼Œä¸å› æ•°æ®åº“é”™è¯¯ä¸­æ–­

        # Process document
        print(f"ğŸ”„ Starting document processing...")
        try:
            # æ£€æŸ¥æ˜¯å¦æ˜ç¡®é€‰æ‹©äº†æ¨¡æ‹Ÿæ¨¡å¼
            if api_type == 'mock':
                print("ğŸ­ Using explicit mock processing mode")
                print(f"ğŸ­ Calling mock_process_document with: {filepath}")
                result = mock_process_document(file_path=filepath)
                print(f"ğŸ­ Mock processing returned: {type(result)}")
                if isinstance(result, dict):
                    print(f"ğŸ­ Result keys: {list(result.keys())}")
                    if 'error' in result:
                        print(f"âŒ Mock processing error: {result['error']}")
                else:
                    print(f"âŒ Unexpected result type: {type(result)}")
            else:
                print(f"ğŸŒ Initializing real API: {api_type}")
                orchestrator = initialize_agent(api_type, model_name)

                if orchestrator is None:
                    # ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ä½œä¸ºå›é€€
                    print("ğŸ­ API not available, using mock processing mode as fallback")
                    result = mock_process_document(file_path=filepath)
                else:
                    # ä½¿ç”¨çœŸå®API
                    print("ğŸŒ Using real API processing")
                    result = orchestrator.process_document(file_path=filepath)

            # è¯¦ç»†æ£€æŸ¥å¤„ç†ç»“æœ
            print(f"ğŸ“Š Processing result analysis:")
            print(f"   - Result type: {type(result)}")
            if isinstance(result, dict):
                print(f"   - Result keys: {list(result.keys())}")
                status = result.get('processing_status', 'unknown')
                mock_mode = result.get('mock_mode', False)
                error = result.get('error', None)
                print(f"   - Status: {status}")
                print(f"   - Mock mode: {mock_mode}")
                if error:
                    print(f"   - Error: {error}")

                # Check if result has required fields
                required_fields = ['text_content', 'structure_info', 'scenario_analysis']
                missing_fields = [field for field in required_fields if field not in result]
                if missing_fields:
                    print(f"âš ï¸  Missing required fields: {missing_fields}")
            else:
                print(f"âŒ Result is not a dictionary: {result}")

            print(f"âœ… Processing completed successfully")

            # æ›´æ–°æ•°æ®åº“è®°å½•
            if document_record_id is not None and document_repo is not None:
                try:
                    # ä»ç»“æœä¸­æå–ä¿¡æ¯æ›´æ–°è®°å½•
                    processing_time_ms = 0  # å¯ä»¥è®¡ç®—å®é™…å¤„ç†æ—¶é—´
                    confidence_score = 0.8  # é»˜è®¤ç½®ä¿¡åº¦ï¼Œå¯ä»¥ä»ç»“æœä¸­æå–

                    if isinstance(result, dict):
                        # å°è¯•ä»ç»“æœä¸­æå–ç½®ä¿¡åº¦
                        scenario_analysis = result.get('scenario_analysis', {})
                        if isinstance(scenario_analysis, dict):
                            confidence_score = scenario_analysis.get('confidence', 0.8)

                    # æ›´æ–°å¤„ç†çŠ¶æ€ä¸ºå®Œæˆ
                    document_repo.update_processing_status(
                        document_record_id,
                        ProcessingStatus.COMPLETED,
                        processing_time_ms=processing_time_ms
                    )
                    print(f"ğŸ“ Updated database record {document_record_id} to completed")
                except Exception as e:
                    print(f"âš ï¸ Failed to update database record: {e}")

            # Clean up uploaded file
            print(f"ğŸ§¹ Cleaning up file: {filepath}")
            if os.path.exists(filepath):
                os.remove(filepath)
                print(f"âœ… File cleaned up successfully")
            else:
                print(f"âš ï¸ File not found for cleanup: {filepath}")

            # Prepare response
            response_data = {
                'file_id': unique_filename,
                'analysis': {
                    'document_type': result.get('scenario_analysis', {}).get('document_type', 'é€šç”¨æ–‡æ¡£'),
                    'key_entities': result.get('key_entities', [])
                },
                'success': True,
                'result': result,
                'filename': filename,
                'processed_at': datetime.now().isoformat(),
                'api_type': api_type,
                'model_name': model_name
            }

            print(f"ğŸ“¤ Preparing JSON response:")
            print(f"   - Success: {response_data['success']}")
            print(f"   - Filename: {response_data['filename']}")
            print(f"   - API type: {response_data['api_type']}")
            print(f"   - Result type: {type(response_data['result'])}")

            # Try to serialize to JSON to catch any issues
            try:
                import json
                json_str = json.dumps(response_data, ensure_ascii=False, default=str)
                print(f"âœ… JSON serialization successful: {len(json_str)} characters")
            except Exception as json_error:
                print(f"âŒ JSON serialization failed: {json_error}")
                return jsonify({'success': False, 'error': f'Response serialization failed: {str(json_error)}'}), 500

            print(f"ğŸ‰ Returning successful response")
            print("=" * 80)
            return jsonify(response_data)
            
        except Exception as e:
            print(f"âŒ PROCESSING ERROR OCCURRED:")
            print(f"   - Error type: {type(e).__name__}")
            print(f"   - Error message: {str(e)}")
            print(f"   - Full traceback:")
            print(traceback.format_exc())

            # æ›´æ–°æ•°æ®åº“è®°å½•ä¸ºå¤±è´¥çŠ¶æ€
            if document_record_id is not None and document_repo is not None:
                try:
                    document_repo.update_processing_status(
                        document_record_id,
                        ProcessingStatus.FAILED,
                        error_message=str(e)
                    )
                    print(f"ğŸ“ Updated database record {document_record_id} to failed")
                except Exception as db_error:
                    print(f"âš ï¸ Failed to update database record: {db_error}")

            # Clean up file on error
            if os.path.exists(filepath):
                print(f"ğŸ§¹ Cleaning up file after error: {filepath}")
                os.remove(filepath)
                print(f"âœ… File cleaned up after error")
            else:
                print(f"âš ï¸ File not found for cleanup after error: {filepath}")
            
            # å¦‚æœæ˜¯ç½‘ç»œé”™è¯¯ï¼Œå°è¯•ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼
            if "timeout" in str(e).lower() or "connection" in str(e).lower() or "network" in str(e).lower():
                print("Network error detected, trying mock mode")
                try:
                    # é‡æ–°è¯»å–æ–‡ä»¶å†…å®¹è¿›è¡Œæ¨¡æ‹Ÿå¤„ç†
                    if os.path.exists(filepath):
                        result = mock_process_document(file_path=filepath)
                    else:
                        # å¦‚æœæ–‡ä»¶å·²è¢«åˆ é™¤ï¼Œåˆ›å»ºä¸€ä¸ªåŸºæœ¬çš„æ¨¡æ‹Ÿç»“æœ
                        result = {
                            'text_content': 'Mock content for network error fallback',
                            'structure_info': {'lines': 1, 'paragraphs': 1, 'characters': 40},
                            'scenario_analysis': {
                                'document_type': 'é€šç”¨æ–‡æ¡£',
                                'scenario': 'ç½‘ç»œé”™è¯¯å›é€€æ¨¡å¼',
                                'key_points': ['ç½‘ç»œè¿æ¥é—®é¢˜', 'ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼'],
                                'confidence': 0.5
                            },
                            'suggestions': ['æ£€æŸ¥ç½‘ç»œè¿æ¥', 'ç¨åé‡è¯•'],
                            'processing_status': 'completed_with_fallback',
                            'mock_mode': True,
                            'fallback_reason': 'network_error'
                        }

                    return jsonify({
                        'success': True,
                        'result': result,
                        'filename': filename,
                        'processed_at': datetime.now().isoformat(),
                        'note': 'Used mock mode due to network issues',
                        'api_type': 'mock_fallback',
                        'model_name': 'fallback'
                    })
                except Exception as mock_error:
                    return jsonify({'success': False, 'error': f'Processing failed: {str(e)} (Mock mode also failed: {str(mock_error)})'}), 500
            
            return jsonify({'success': False, 'error': f'Processing failed: {str(e)}'}), 500

@app.route('/api/health')
def health_check():
    """Health check endpoint."""
    try:
        # Test different API types
        api_status = {}
        
        # Test Xingcheng API
        try:
            orchestrator = initialize_agent("xingcheng")
            api_status['xingcheng'] = {
                'status': 'available' if orchestrator else 'unavailable',
                'mock_mode': orchestrator is None
            }
        except Exception as e:
            api_status['xingcheng'] = {'status': 'error', 'error': str(e)}
        
        # Test Multi API
        try:
            orchestrator = initialize_agent("multi")
            api_status['multi'] = {
                'status': 'available' if orchestrator else 'unavailable',
                'mock_mode': orchestrator is None
            }
        except Exception as e:
            api_status['multi'] = {'status': 'error', 'error': str(e)}
        
        return jsonify({
            'status': 'healthy',
            'api_status': api_status,
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({
            'status': 'unhealthy',
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500

@app.route('/api/config')
def get_config():
    """Get current configuration (without sensitive data)."""
    return jsonify({
        'allowed_extensions': list(app.config['ALLOWED_EXTENSIONS']),
        'max_file_size_mb': app.config['MAX_CONTENT_LENGTH'] // (1024 * 1024),
        'api_types': ['xingcheng', 'multi', 'mock'],
        'xingcheng_configured': bool(os.getenv("XINGCHENG_API_KEY")),
        'qiniu_configured': bool(os.getenv("QINIU_API_KEY")),
        'together_configured': bool(os.getenv("TOGETHER_API_KEY")),
        'openrouter_configured': bool(os.getenv("OPENROUTER_API_KEY")),
        'mock_mode_available': True,
        'format_alignment_available': True,
        'document_fill_available': True
    })

@app.route('/api/format-alignment', methods=['POST'])
def format_alignment():
    """å¤„ç†æ–‡æ¡£æ ¼å¼å¯¹é½è¯·æ±‚"""
    with PerformanceTimer('format_alignment') as timer:
        global format_coordinator

        try:
            if format_coordinator is None:
                format_coordinator = FormatAlignmentCoordinator()

            if not request.is_json:
                return jsonify({'success': False, 'error': 'Content-Typeå¿…é¡»ä¸ºapplication/json'}), 400
            data = request.get_json()
            # æ–°å¢ï¼šæ”¯æŒ data_sources ç»“æ„
            data_sources = data.get('data_sources')
            if data_sources:
                # è‡ªåŠ¨æå–ä¸»è¦å†…å®¹
                user_input = ''
                uploaded_files = {}
                image_files = {}
                for item in data_sources:
                    if item.get('type') == 'text' and not user_input:
                        user_input = item.get('content', '')
                    if item.get('type') == 'file':
                        mime = item.get('mime', '')
                        if mime.startswith('image/') and item.get('content'):
                            # å¤„ç† base64 å›¾ç‰‡
                            header, b64data = item['content'].split(',', 1) if ',' in item['content'] else ('', item['content'])
                            binary = base64.b64decode(b64data)
                            tmp_dir = tempfile.gettempdir()
                            img_path = os.path.join(tmp_dir, item.get('name','uploaded_image'))
                            with open(img_path, 'wb') as f:
                                f.write(binary)
                            image_files[item.get('name','file')] = img_path
                        else:
                            uploaded_files[item.get('name','file')] = item.get('content','')
                # å¯å°† image_files åˆå¹¶åˆ° uploaded_files æˆ–å•ç‹¬å¤„ç†
                uploaded_files.update(image_files)
            else:
                user_input = data.get('user_input', '')
                uploaded_files = data.get('uploaded_files', {})

            result = format_coordinator.process_user_request(user_input, uploaded_files)
            if isinstance(result, dict) and 'error' in result:
                return jsonify({'success': False, 'error': result['error']}), 400
            if isinstance(result, dict):
                result['success'] = True
            return jsonify(result)

        except Exception as e:
            return jsonify({'success': False, 'error': f'æ ¼å¼å¯¹é½å¤„ç†å¤±è´¥: {str(e)}'}), 500

@app.route('/api/format-templates', methods=['GET'])
def list_format_templates():
    """è·å–æ‰€æœ‰æ ¼å¼æ¨¡æ¿"""
    global format_coordinator

    try:
        if format_coordinator is None:
            format_coordinator = FormatAlignmentCoordinator()

        templates = format_coordinator.format_extractor.list_format_templates()

        return jsonify({
            'success': True,
            'templates': templates,
            'count': len(templates)
        })

    except Exception as e:
        return jsonify({'error': f'è·å–æ¨¡æ¿åˆ—è¡¨å¤±è´¥: {str(e)}'}), 500

@app.route('/api/format-templates/<template_id>', methods=['GET'])
def get_format_template(template_id):
    """è·å–ç‰¹å®šæ ¼å¼æ¨¡æ¿"""
    global format_coordinator

    try:
        if format_coordinator is None:
            format_coordinator = FormatAlignmentCoordinator()

        template_data = format_coordinator.format_extractor.load_format_template(template_id)

        if 'error' in template_data:
            return jsonify(template_data), 404

        return jsonify({
            'success': True,
            'template': template_data
        })

    except Exception as e:
        return jsonify({'error': f'è·å–æ¨¡æ¿å¤±è´¥: {str(e)}'}), 500

@app.route('/api/format-templates', methods=['POST'])
def save_format_template():
    """ä¿å­˜æ ¼å¼æ¨¡æ¿"""
    global format_coordinator

    try:
        if format_coordinator is None:
            format_coordinator = FormatAlignmentCoordinator()
            print("Format coordinator initialized")

        data = request.get_json()
        if not data:
            print("Error: No JSON data received in request")
            return jsonify({'error': 'è¯·æ±‚ä¸­æ²¡æœ‰æä¾›æ•°æ®'}), 400

        # æ”¯æŒä¸¤ç§å‚æ•°æ ¼å¼ï¼š
        # 1. åŒ…å«template_nameå’Œtemplate_dataçš„ç»“æ„
        # 2. å®Œæ•´çš„æ ¼å¼æ•°æ®å¯¹è±¡
        
        if 'template_name' in data and 'template_data' in data:
            # æ ¼å¼1ï¼šä»template_dataä¸­æå–å®Œæ•´æ•°æ®
            template_name = data.get('template_name', '')
            template_data = data.get('template_data', {})
            
            if not template_name or not template_data:
                print(f"Error: Missing template name or data. Name: {template_name}, Data: {bool(template_data)}")
                return jsonify({'error': 'ç¼ºå°‘æ¨¡æ¿åç§°æˆ–æ•°æ®'}), 400
            
            print(f"Saving format template with name: {template_name}")
            result = format_coordinator.format_extractor.save_format_template({
                'template_name': template_name,
                'template_data': template_data
            })
        else:
            # æ ¼å¼2ï¼šç›´æ¥ä¼ é€’å®Œæ•´çš„æ ¼å¼æ•°æ®
            if not data:
                print("Error: No valid template data provided")
                return jsonify({'error': 'ç¼ºå°‘æœ‰æ•ˆçš„æ¨¡æ¿æ•°æ®'}), 400
            
            print(f"Saving format template with direct data")
            result = format_coordinator.format_extractor.save_format_template(data)

        if 'error' in result:
            print(f"Error in save_format_template result: {result['error']}")
            return jsonify(result), 500

        print(f"Format template saved successfully with ID: {result.get('template_id', 'N/A')}")
        return jsonify({
            'success': True,
            'template_id': result.get('template_id', ''),
            'message': 'æ ¼å¼æ¨¡æ¿ä¿å­˜æˆåŠŸ'
        })

    except Exception as e:
        print(f"Error saving format template: {str(e)}")
        print(f"Stack trace: {traceback.format_exc()}")
        return jsonify({'error': f'ä¿å­˜æ¨¡æ¿å¤±è´¥: {str(e)}'}), 500

@app.route('/api/format-templates/<template_id>/apply', methods=['POST'])
def apply_format_template(template_id):
    """åº”ç”¨æ ¼å¼æ¨¡æ¿åˆ°æ–‡æ¡£"""
    global format_coordinator

    try:
        if format_coordinator is None:
            format_coordinator = FormatAlignmentCoordinator()

        data = request.get_json()
        document_name = data.get('document_name', '')
        document_content = data.get('document_content', '')

        if not document_name or not document_content:
            return jsonify({'error': 'ç¼ºå°‘æ–‡æ¡£åç§°æˆ–å†…å®¹'}), 400

        # æ·»åŠ æ–‡æ¡£åˆ°ä¼šè¯
        format_coordinator.add_document(document_name, document_content)

        # åº”ç”¨æ¨¡æ¿
        result = format_coordinator.use_saved_template(template_id, document_name)

        return jsonify(result)

    except Exception as e:
        return jsonify({'error': f'åº”ç”¨æ¨¡æ¿å¤±è´¥: {str(e)}'}), 500

@app.route('/api/format-alignment/preview/<session_id>')
def preview_formatted_document(session_id):
    """é¢„è§ˆæ ¼å¼å¯¹é½åçš„æ–‡æ¡£"""
    try:
        # è·å–æ ¼å¼å¯¹é½ç»“æœ
        result = format_aligner.get_format_result(session_id)
        if not result:
            return "No content to preview", 404
        
        # ç”ŸæˆSVGå›¾ç‰‡å¹¶æ’å…¥æ–‡æ¡£
        if image_processor:
            # ä¸ºæ–‡æ¡£ç”ŸæˆAI SVG
            svg_result = image_processor.generate_ai_svg_for_document(
                document_type="general",
                content_description="æ ¼å¼å¯¹é½é¢„è§ˆæ–‡æ¡£",
                svg_size=(400, 300)
            )
            
            if svg_result.get("success"):
                # æ’å…¥SVGåˆ°æ–‡æ¡£ï¼ˆé¢„è§ˆæ¨¡å¼ï¼‰
                document_content = result.get("formatted_content", "")
                target_position = {"line_number": 1, "document_type": "general"}
                updated_content = image_processor.insert_svg_to_document(
                    document_content, svg_result, target_position, mode="preview"
                )
                result["formatted_content"] = updated_content
                result["svg_info"] = svg_result
        
        html_content = result.get("formatted_content", "")
        return html_content
        
    except Exception as e:
        return f"Preview error: {str(e)}", 500

@app.route('/api/models')
def get_available_models():
    """Get available models for each API type."""
    try:
        # è·å–å¤šAPIå®¢æˆ·ç«¯çš„å¯ç”¨æ¨¡å‹
        multi_client = MultiLLMClient()
        available_models = multi_client.get_available_models()
        
        models_by_api = {
            'xingcheng': ['x1', 'x2', 'x3'],
            'multi': available_models,
            'mock': ['mock-model']
        }
        
        return jsonify({
            'models': models_by_api,
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({
            'error': str(e),
            'models': {
                'xingcheng': ['x1'],
                'mock': ['mock-model']
            }
        }), 500

@app.route('/api/document-fill/start', methods=['POST'])
def document_fill_start():
    data = request.get_json()
    content = data.get('document_content')
    name = data.get('document_name')
    logger.info(f"[document-fill/start] æ”¶åˆ°å‚æ•°: document_name={name}, document_contentç±»å‹={type(content)}, é•¿åº¦={len(content) if content else 0}")
    if not content or not content.strip():
        logger.error("[document-fill/start] document_contentä¸ºç©º")
        return jsonify({'success': False, 'error': 'document_contentä¸ºç©º'}), 400
    with PerformanceTimer('document_fill_start') as timer:
        global fill_coordinator

        try:
            if fill_coordinator is None:
                fill_coordinator = DocumentFillCoordinator()

            result = fill_coordinator.start_document_fill(content, name)

            return jsonify(result)

        except Exception as e:
            return jsonify({'error': f'å¯åŠ¨æ–‡æ¡£å¡«å……å¤±è´¥: {str(e)}'}), 500

@app.route('/api/document-fill/respond', methods=['POST'])
def respond_to_fill_question():
    """å“åº”æ–‡æ¡£å¡«å……é—®é¢˜"""
    with PerformanceTimer('document_fill_respond') as timer:
        global fill_coordinator

        try:
            if fill_coordinator is None:
                return jsonify({'error': 'æ–‡æ¡£å¡«å……ä¼šè¯æœªåˆå§‹åŒ–'}), 400

            data = request.get_json()
            user_input = data.get('user_input', '')

            if not user_input:
                return jsonify({'error': 'ç¼ºå°‘ç”¨æˆ·è¾“å…¥'}), 400

            result = fill_coordinator.process_user_response(user_input)

            return jsonify(result)

        except Exception as e:
            return jsonify({'error': f'å¤„ç†ç”¨æˆ·å›å¤å¤±è´¥: {str(e)}'}), 500

@app.route('/api/document-fill/status', methods=['GET'])
def get_fill_status():
    """è·å–æ–‡æ¡£å¡«å……çŠ¶æ€"""
    global fill_coordinator

    try:
        if fill_coordinator is None:
            return jsonify({'error': 'æ–‡æ¡£å¡«å……ä¼šè¯æœªåˆå§‹åŒ–'}), 400

        status = fill_coordinator.get_session_status()

        return jsonify({
            'success': True,
            'status': status
        })

    except Exception as e:
        return jsonify({'error': f'è·å–çŠ¶æ€å¤±è´¥: {str(e)}'}), 500

@app.route('/api/document-fill/result', methods=['GET'])
def get_fill_result():
    """è·å–æ–‡æ¡£å¡«å……ç»“æœ"""
    global fill_coordinator

    try:
        if fill_coordinator is None:
            return jsonify({'error': 'æ–‡æ¡£å¡«å……ä¼šè¯æœªåˆå§‹åŒ–'}), 400

        result = fill_coordinator.get_fill_result()

        if not result:
            return jsonify({'error': 'å¡«å……ç»“æœä¸å¯ç”¨'}), 404

        return jsonify({
            'success': True,
            'result': result
        })

    except Exception as e:
        return jsonify({'error': f'è·å–å¡«å……ç»“æœå¤±è´¥: {str(e)}'}), 500

@app.route('/api/document-fill/download', methods=['GET'])
def download_filled_document():
    """ä¸‹è½½å¡«å……åçš„æ–‡æ¡£"""
    global fill_coordinator

    try:
        if fill_coordinator is None:
            return jsonify({'error': 'æ–‡æ¡£å¡«å……ä¼šè¯æœªåˆå§‹åŒ–'}), 400

        result = fill_coordinator.get_fill_result()

        if not result or not result.get('html_content'):
            return jsonify({'error': 'å¡«å……ç»“æœä¸å¯ç”¨'}), 404

        html_content = result['html_content']

        # åˆ›å»ºå“åº”
        from flask import make_response
        response = make_response(html_content)
        response.headers['Content-Type'] = 'text/html; charset=utf-8'
        response.headers['Content-Disposition'] = 'attachment; filename=filled_document.html'

        return response

    except Exception as e:
        return jsonify({'error': f'ä¸‹è½½å¤±è´¥: {str(e)}'}), 500

@app.route('/api/document-fill/add-material', methods=['POST'])
def add_supplementary_material():
    """æ·»åŠ è¡¥å……ææ–™"""
    global fill_coordinator

    try:
        if fill_coordinator is None:
            return jsonify({'error': 'æ–‡æ¡£å¡«å……ä¼šè¯æœªåˆå§‹åŒ–'}), 400

        data = request.get_json()
        material_name = data.get('material_name', '')
        material_content = data.get('material_content', '')

        if not material_name or not material_content:
            return jsonify({'error': 'ç¼ºå°‘ææ–™åç§°æˆ–å†…å®¹'}), 400

        result = fill_coordinator.add_supplementary_material(material_name, material_content)

        return jsonify(result)

    except Exception as e:
        return jsonify({'error': f'æ·»åŠ è¡¥å……ææ–™å¤±è´¥: {str(e)}'}), 500

@app.route('/api/writing-style/analyze', methods=['POST'])
def analyze_writing_style():
    """
    åˆ†ææ–‡æ¡£å†™ä½œé£æ ¼ã€‚
    æ”¯æŒmultipart/form-dataæ–‡ä»¶ä¸Šä¼ å’Œapplication/jsonä¸¤ç§æ–¹å¼ã€‚
    å‚æ•°ï¼š
        - file (file): æ–‡ä»¶ä¸Šä¼ æ–¹å¼ã€‚
        - document_content (str): JSONæ–¹å¼ï¼Œæ–‡æ¡£å†…å®¹ã€‚
        - document_name (str): JSONæ–¹å¼ï¼Œæ–‡æ¡£åç§°ã€‚
    è¿”å›ï¼šåˆ†æç»“æœæˆ–é”™è¯¯ã€‚
    """
    import traceback
    from flask import request, jsonify
    with PerformanceTimer('writing_style_analyze') as timer:
        global style_analyzer
        try:
            if style_analyzer is None:
                style_analyzer = WritingStyleAnalyzer()
            if request.content_type and request.content_type.startswith('multipart/form-data'):
                file = request.files.get('file')
                if not file:
                    return jsonify({'success': False, 'error': 'æœªä¸Šä¼ æ–‡ä»¶'}), 400
                try:
                    document_content = file.read().decode('utf-8', errors='ignore')
                except Exception as e:
                    return jsonify({'success': False, 'error': f'æ–‡ä»¶è§£ç å¤±è´¥: {str(e)}'}), 400
                document_name = file.filename or ''
            elif request.is_json:
                data = request.get_json()
                document_content = data.get('document_content') or data.get('content')
                document_name = data.get('document_name', '')
                if not document_content or not isinstance(document_content, str) or not document_content.strip():
                    return jsonify({'success': False, 'error': 'document_contentä¸èƒ½ä¸ºç©º'}), 400
            else:
                return jsonify({'success': False, 'error': 'ä»…æ”¯æŒæ–‡ä»¶ä¸Šä¼ (multipart/form-data)æˆ–JSON'}), 400
            result = style_analyzer.analyze_writing_style(document_content, document_name)
            if isinstance(result, dict) and 'error' in result:
                return jsonify({'success': False, 'error': result['error']}), 400
            if isinstance(result, dict):
                result['success'] = True
            return jsonify(result)
        except Exception as e:
            tb = traceback.format_exc()
            print(f"[ERROR] analyze_writing_style APIå¼‚å¸¸: {e}\n{tb}")
            return jsonify({'success': False, 'error': f'æ–‡é£åˆ†æå¤±è´¥: {str(e)}', 'traceback': tb}), 500

@app.route('/api/writing-style/save-template', methods=['POST'])
def save_writing_style_template():
    """ä¿å­˜æ–‡é£æ¨¡æ¿"""
    global style_analyzer, fill_coordinator

    try:
        if style_analyzer is None:
            style_analyzer = WritingStyleAnalyzer()

        data = request.get_json()
        if not data:
            return jsonify({'error': 'è¯·æ±‚ä¸­æ²¡æœ‰æä¾›æ•°æ®'}), 400

        # æ”¯æŒä¸¤ç§å‚æ•°æ ¼å¼ï¼š
        # 1. åŒ…å«reference_contentå’Œreference_nameçš„ç»“æ„
        # 2. å®Œæ•´çš„åˆ†æç»“æœæ•°æ®
        
        if 'reference_content' in data and 'reference_name' in data:
            # æ ¼å¼1ï¼šä»å‚è€ƒæ–‡æ¡£ç”Ÿæˆæ¨¡æ¿
            reference_content = data.get('reference_content', '')
            reference_name = data.get('reference_name', '')

            if not reference_content:
                return jsonify({'error': 'ç¼ºå°‘å‚è€ƒæ–‡æ¡£å†…å®¹'}), 400

            # å¦‚æœæœ‰æ´»è·ƒçš„å¡«å……ä¼šè¯ï¼Œä½¿ç”¨ä¼šè¯ä¸­çš„æ–¹æ³•
            if fill_coordinator is not None:
                result = fill_coordinator.analyze_and_save_writing_style(reference_content, reference_name)
            else:
                # ç›´æ¥ä½¿ç”¨åˆ†æå™¨
                analysis_result = style_analyzer.analyze_writing_style(reference_content, reference_name)
                if "error" in analysis_result:
                    return jsonify(analysis_result), 500

                result = style_analyzer.save_style_template(analysis_result)
        else:
            # æ ¼å¼2ï¼šç›´æ¥ä¿å­˜å®Œæ•´çš„åˆ†æç»“æœ
            if not data:
                return jsonify({'error': 'ç¼ºå°‘æœ‰æ•ˆçš„æ¨¡æ¿æ•°æ®'}), 400
            
            # éªŒè¯æ¨¡æ¿æ•°æ®
            from src.core.tools.template_schema import TemplateSchema
            validation_result = TemplateSchema.validate_style_template(data)
            if not validation_result["success"]:
                return jsonify({
                    'error': f'æ¨¡æ¿æ•°æ®éªŒè¯å¤±è´¥: {validation_result["error"]}',
                    'field': validation_result.get('field', ''),
                    'suggestions': [
                        'æ£€æŸ¥æ¨¡æ¿æ•°æ®æ ¼å¼',
                        'ç¡®ä¿æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å·²æä¾›',
                        'éªŒè¯æ–‡é£ç±»å‹æ˜¯å¦æ­£ç¡®'
                    ]
                }), 400
            
            # æ ‡å‡†åŒ–æ¨¡æ¿æ•°æ®
            normalized_data = TemplateSchema.normalize_style_template(data)
            result = style_analyzer.save_style_template(normalized_data)

        return jsonify(result)

    except Exception as e:
        # ä½¿ç”¨ç»Ÿä¸€çš„é”™è¯¯å¤„ç†
        from src.core.tools.error_handler import error_handler
        error_result = error_handler.handle_error(e, {
            'endpoint': '/api/writing-style/save-template',
            'request_data': data if 'data' in locals() else None
        })
        
        return jsonify(error_result), 500

@app.route('/api/writing-style/templates', methods=['GET'])
def list_writing_style_templates():
    global style_analyzer
    try:
        if style_analyzer is None:
            from src.core.tools.writing_style_analyzer import WritingStyleAnalyzer
            style_analyzer = WritingStyleAnalyzer()
        templates = style_analyzer.list_style_templates()
        return jsonify({'success': True, 'templates': templates})
    except Exception as e:
        return jsonify({'success': False, 'error': f'è·å–æ–‡é£æ¨¡æ¿åˆ—è¡¨å¤±è´¥: {str(e)}'}), 500

@app.route('/api/writing-style/templates/<template_id>', methods=['GET'])
def get_writing_style_template(template_id):
    global style_analyzer
    try:
        if style_analyzer is None:
            from src.core.tools.writing_style_analyzer import WritingStyleAnalyzer
            style_analyzer = WritingStyleAnalyzer()
        template = style_analyzer.load_style_template(template_id)
        if 'error' in template:
            return jsonify({'success': False, 'error': template['error']}), 404
        return jsonify({'success': True, 'template': template})
    except Exception as e:
        return jsonify({'success': False, 'error': f'è·å–æ–‡é£æ¨¡æ¿å¤±è´¥: {str(e)}'}), 500

@app.route('/api/image/batch-process', methods=['POST'])
def batch_process_images():
    """æ‰¹é‡å›¾ç‰‡å¤„ç†API"""
    global image_processor
    
    try:
        if image_processor is None:
            return jsonify({'error': 'å›¾ç‰‡å¤„ç†å™¨æœªåˆå§‹åŒ–'}), 400
        
        data = request.get_json()
        if not data:
            return jsonify({'error': 'è¯·æ±‚æ•°æ®ä¸ºç©º'}), 400
        
        image_list = data.get('image_list', [])
        document_content = data.get('document_content', '')
        
        if not image_list:
            return jsonify({'error': 'å›¾ç‰‡åˆ—è¡¨ä¸ºç©º'}), 400
        
        # æ‰¹é‡å¤„ç†å›¾ç‰‡
        result = image_processor.batch_process_images(image_list, document_content)
        
        if "error" in result:
            return jsonify(result), 400
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({'error': f'æ‰¹é‡å›¾ç‰‡å¤„ç†å¤±è´¥: {str(e)}'}), 500

@app.route('/api/image/statistics', methods=['GET'])
def get_image_statistics():
    """è·å–å›¾ç‰‡ç»Ÿè®¡ä¿¡æ¯API"""
    global image_processor
    
    try:
        if image_processor is None:
            return jsonify({'error': 'å›¾ç‰‡å¤„ç†å™¨æœªåˆå§‹åŒ–'}), 400
        
        statistics = image_processor.get_image_statistics()
        
        if "error" in statistics:
            return jsonify(statistics), 400
        
        return jsonify(statistics)
        
    except Exception as e:
        return jsonify({'error': f'è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}'}), 500

@app.route('/api/ai-fill-suggestions', methods=['POST'])
def get_ai_fill_suggestions():
    """è·å–AIå¡«å†™å»ºè®®API"""
    global patent_analyzer
    
    try:
        if patent_analyzer is None:
            return jsonify({'error': 'ä¸“åˆ©åˆ†æå™¨æœªåˆå§‹åŒ–'}), 400
        
        data = request.get_json()
        if not data:
            return jsonify({'error': 'è¯·æ±‚æ•°æ®ä¸ºç©º'}), 400
        
        analysis_result = data.get('analysis_result', {})
        
        if not analysis_result:
            return jsonify({'error': 'åˆ†æç»“æœä¸ºç©º'}), 400
        
        # ç”ŸæˆAIå¡«å†™å»ºè®®
        suggestions = patent_analyzer.generate_ai_fill_suggestions(analysis_result)
        
        if "error" in suggestions:
            return jsonify(suggestions), 400
        
        return jsonify(suggestions)
        
    except Exception as e:
        return jsonify({'error': f'ç”ŸæˆAIå»ºè®®å¤±è´¥: {str(e)}'}), 500

@app.route('/api/document/parse', methods=['POST'])
def api_document_parse():
    """
    æ–‡æ¡£è§£æAPIã€‚

    Args:
        file (FileStorage): ä¸Šä¼ çš„æ–‡æ¡£æ–‡ä»¶ï¼Œæ”¯æŒtxtã€pdfã€docxã€docã€‚

    Returns:
        JSON: åŒ…å«successã€document_idã€textã€tablesã€metadataç­‰ã€‚

    Raises:
        400: ç¼ºå°‘æ–‡ä»¶æˆ–æ–‡ä»¶ç±»å‹ä¸æ”¯æŒã€‚
        500: è§£æå¤±è´¥ã€‚

    Example:
        curl -F "file=@test.txt" http://localhost:5000/api/document/parse
    """
    try:
        if 'file' not in request.files:
            return jsonify({'success': False, 'error': 'æ²¡æœ‰æ–‡ä»¶'}), 400

        file = request.files['file']
        if file.filename == '':
            return jsonify({'success': False, 'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400

        allowed_extensions = {'txt', 'pdf', 'docx', 'doc'}
        file_ext = file.filename.rsplit('.', 1)[1].lower() if '.' in file.filename else ''
        if file_ext not in allowed_extensions:
            return jsonify({'success': False, 'error': f'ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}'}), 400

        content = file.read()
        try:
            text_content = content.decode('utf-8', errors='ignore')
        except:
            text_content = content.decode('gbk', errors='ignore')

        # æ¨¡æ‹Ÿè¡¨æ ¼æå–
        tables = []
        if 'è¡¨æ ¼' in text_content or 'table' in text_content.lower():
            tables.append({
                'columns': ['å§“å', 'å¹´é¾„', 'èŒä½'],
                'data': [['å¼ ä¸‰', '', ''], ['æå››', '', ''], ['ç‹äº”', '', '']]
            })

        return jsonify({
            'success': True,
            'document_id': f"doc_{int(time.time())}",
            'text': text_content,
            'tables': tables,
            'metadata': {
                'filename': file.filename,
                'size': len(content),
                'pages': 1
            }
        })
    except Exception as e:
        return jsonify({'success': False, 'error': f'æ–‡æ¡£è§£æå¤±è´¥: {str(e)}'}), 500

@app.route('/favicon.ico')
def favicon():
    import os
    from flask import send_from_directory, make_response
    favicon_path = os.path.join(app.root_path, 'static', 'favicon.ico')
    if os.path.exists(favicon_path):
        return send_from_directory(os.path.join(app.root_path, 'static'), 'favicon.ico', mimetype='image/vnd.microsoft.icon')
    else:
        return ('', 204)

@app.route('/api/performance/health')
def get_api_health():
    """
    MVP: è·å–APIå¥åº·çŠ¶æ€
    
    å½“å‰å®ç°èŒƒå›´ï¼š
    - LLMå®¢æˆ·ç«¯å¥åº·æ£€æŸ¥
    - æ•°æ®åº“è¿æ¥æ£€æŸ¥  
    - æ–‡ä»¶ç³»ç»Ÿæƒé™æ£€æŸ¥
    - ç¼“å­˜ç³»ç»Ÿæ£€æŸ¥
    - æ¨¡æ¿ç³»ç»Ÿæ£€æŸ¥
    
    åç»­æ‰©å±•ç‚¹ï¼š
    - æ·»åŠ æ›´å¤šç»„ä»¶å¥åº·æ£€æŸ¥ï¼ˆå¦‚Redisã€æ¶ˆæ¯é˜Ÿåˆ—ç­‰ï¼‰
    - å¢åŠ æ€§èƒ½æŒ‡æ ‡ç›‘æ§
    - æ”¯æŒè‡ªå®šä¹‰å¥åº·æ£€æŸ¥è§„åˆ™
    """
    try:
        health_data = {
            'endpoints': [],
            'overall_health': 'healthy',
            'last_check': datetime.now().isoformat()
        }
        
        # æ£€æŸ¥LLMå®¢æˆ·ç«¯å¥åº·çŠ¶æ€
        global orchestrator_instance
        if orchestrator_instance and hasattr(orchestrator_instance.llm_client, 'get_health_status'):
            llm_health = orchestrator_instance.llm_client.get_health_status()
            health_data['llm_client'] = llm_health
        else:
            health_data['llm_client'] = {'status': 'unknown'}
        
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥
        try:
            from src.core.database.database_manager import get_database_manager
            db_manager = get_database_manager()
            db_health = db_manager.check_connection()
            health_data['database'] = db_health
        except Exception as e:
            health_data['database'] = {'status': 'error', 'message': str(e)}
        
        # æ£€æŸ¥æ–‡ä»¶ç³»ç»Ÿ
        try:
            upload_dir = 'uploads'
            if os.path.exists(upload_dir) and os.access(upload_dir, os.W_OK):
                health_data['file_system'] = {'status': 'healthy'}
            else:
                health_data['file_system'] = {'status': 'error', 'message': 'Upload directory not writable'}
        except Exception as e:
            health_data['file_system'] = {'status': 'error', 'message': str(e)}
        
        # æ£€æŸ¥ç¼“å­˜ç³»ç»Ÿ
        try:
            cache_dir = 'src/core/knowledge_base/cache'
            if os.path.exists(cache_dir) and os.access(cache_dir, os.W_OK):
                health_data['cache_system'] = {'status': 'healthy'}
            else:
                health_data['cache_system'] = {'status': 'error', 'message': 'Cache directory not writable'}
        except Exception as e:
            health_data['cache_system'] = {'status': 'error', 'message': str(e)}
        
        # æ£€æŸ¥æ¨¡æ¿ç³»ç»Ÿ
        try:
            template_dir = 'src/core/knowledge_base/format_templates'
            if os.path.exists(template_dir) and os.access(template_dir, os.W_OK):
                health_data['template_system'] = {'status': 'healthy'}
            else:
                health_data['template_system'] = {'status': 'error', 'message': 'Template directory not writable'}
        except Exception as e:
            health_data['template_system'] = {'status': 'error', 'message': str(e)}
        
        # è®¡ç®—æ•´ä½“å¥åº·çŠ¶æ€
        healthy_count = sum(1 for component in health_data.values() 
                          if isinstance(component, dict) and component.get('status') == 'healthy')
        total_components = len([k for k, v in health_data.items() 
                              if isinstance(v, dict) and 'status' in v])
        
        if healthy_count == total_components:
            health_data['overall_health'] = 'healthy'
        elif healthy_count > 0:
            health_data['overall_health'] = 'degraded'
        else:
            health_data['overall_health'] = 'unhealthy'
        
        return jsonify({
            'success': True,
            'data': health_data
        })
    except Exception as e:
        print(f"Error getting API health: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/templates/<template_id>', methods=['GET'])
def get_template_details(template_id):
    """è·å–æ¨¡æ¿è¯¦ç»†ä¿¡æ¯"""
    try:
        global format_coordinator
        
        if format_coordinator is None:
            format_coordinator = FormatAlignmentCoordinator()
        
        template_data = format_coordinator.format_extractor.load_format_template(template_id)
        
        if 'error' in template_data:
            return jsonify({'success': False, 'error': f'æ¨¡æ¿ä¸å­˜åœ¨: {template_id}'}), 404
        
        return jsonify({'success': True, 'template': template_data})
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/templates/<template_id>/apply', methods=['POST'])
def apply_template(template_id):
    """åº”ç”¨æ¨¡æ¿åˆ°æ–‡æ¡£å†…å®¹"""
    try:
        global format_coordinator
        
        if format_coordinator is None:
            format_coordinator = FormatAlignmentCoordinator()
        
        data = request.get_json()
        content = data.get('content', '')
        
        if not content:
            return jsonify({'success': False, 'error': 'ç¼ºå°‘å†…å®¹å‚æ•°'}), 400
        
        result = format_coordinator.format_extractor.align_document_format(content, template_id)
        
        if 'error' in result:
            return jsonify({'success': False, 'error': result['error']}), 400
        
        return jsonify({'success': True, 'result': result})
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/templates/<template_id>/delete', methods=['DELETE'])
def delete_template(template_id):
    """åˆ é™¤æ¨¡æ¿"""
    try:
        global format_coordinator
        
        if format_coordinator is None:
            format_coordinator = FormatAlignmentCoordinator()
        
        # æ£€æŸ¥æ¨¡æ¿æ˜¯å¦å­˜åœ¨
        template_data = format_coordinator.format_extractor.load_format_template(template_id)
        
        if 'error' in template_data:
            return jsonify({
                'success': False,
                'error': f'æ¨¡æ¿ä¸å­˜åœ¨: {template_id}'
            }), 404
        
        # åˆ é™¤æ¨¡æ¿æ–‡ä»¶
        template_file = os.path.join(format_coordinator.format_extractor.storage_path, f"{template_id}.json")
        if os.path.exists(template_file):
            os.remove(template_file)
        
        # æ›´æ–°æ¨¡æ¿ç´¢å¼• - åˆ é™¤æ¡ç›®
        index_file = os.path.join(format_coordinator.format_extractor.storage_path, "template_index.json")
        if os.path.exists(index_file):
            with open(index_file, 'r', encoding='utf-8') as f:
                index_data = json.load(f)
            
            # åˆ é™¤æŒ‡å®šæ¨¡æ¿çš„ç´¢å¼•æ¡ç›®
            index_data["templates"] = [t for t in index_data["templates"] if t["template_id"] != template_id]
            
            # ä¿å­˜æ›´æ–°åçš„ç´¢å¼•
            with open(index_file, 'w', encoding='utf-8') as f:
                json.dump(index_data, f, ensure_ascii=False, indent=2)
        
        return jsonify({
            'success': True,
            'message': f'æ¨¡æ¿ {template_id} å·²åˆ é™¤'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/templates/upload', methods=['POST'])
def upload_template():
    """ä¸Šä¼ æ–°æ¨¡æ¿"""
    try:
        global format_coordinator
        
        if format_coordinator is None:
            format_coordinator = FormatAlignmentCoordinator()
        
        data = request.get_json()
        template_name = data.get('template_name', '')
        template_data = data.get('template_data', {})
        
        if not template_name:
            return jsonify({
                'success': False,
                'error': 'ç¼ºå°‘æ¨¡æ¿åç§°'
            }), 400
        
        # ä¿å­˜æ¨¡æ¿
        result = format_coordinator.format_extractor.save_format_template({
            'template_name': template_name,
            'template_data': template_data
        })
        
        if 'error' in result:
            return jsonify({
                'success': False,
                'error': result['error']
            }), 400
        
        return jsonify({
            'success': True,
            'result': result
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/test/cleanup', methods=['POST'])
def cleanup_test_resources():
    """æ¸…ç†æµ‹è¯•èµ„æº"""
    try:
        from src.core.resource_manager import resource_manager
        
        data = request.get_json() or {}
        test_session_id = data.get('test_session_id') if data.get('test_session_id') else None
        cleanup_type = data.get('cleanup_type', 'all')
        
        result = resource_manager.cleanup_test_resources(test_session_id, cleanup_type)
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/performance/history', methods=['GET'])
def get_processing_history():
    """
    MVP: è·å–å¤„ç†å†å²è®°å½•
    
    å½“å‰å®ç°èŒƒå›´ï¼š
    - åªè¿”å›æœ€è¿‘10æ¡è®°å½•
    - å­—æ®µç²¾ç®€ï¼šidã€æ—¶é—´ã€æ“ä½œç±»å‹ã€æˆåŠŸä¸å¦
    - ä¸æ”¯æŒåˆ†é¡µã€ç­›é€‰ç­‰å¤æ‚åŠŸèƒ½
    
    åç»­æ‰©å±•ç‚¹ï¼š
    - æ”¯æŒåˆ†é¡µæŸ¥è¯¢
    - æ”¯æŒæŒ‰æ—¶é—´èŒƒå›´ç­›é€‰
    - æ”¯æŒæŒ‰æ“ä½œç±»å‹ç­›é€‰
    - å¢åŠ æ›´å¤šå­—æ®µï¼ˆå¦‚å¤„ç†æ—¶é•¿ã€æ–‡ä»¶å¤§å°ç­‰ï¼‰
    """
    try:
        # TODO: MVPä»…å ä½ï¼Œåç»­å®Œå–„ - å½“å‰åªè¿”å›æœ€è¿‘10æ¡è®°å½•
        from src.core.database.repositories import DocumentRepository
        
        doc_repo = DocumentRepository()
        records = doc_repo.get_processing_history(limit=10)
        
        # æ ¼å¼åŒ–è®°å½•ä¸ºMVPç²¾ç®€æ ¼å¼
        formatted_records = []
        for record in records:
            formatted_records.append({
                'id': record.id,
                'timestamp': record.created_at.isoformat() if record.created_at else None,
                'operation': record.document_type or 'unknown',
                'success': record.processing_status == 'completed',
                'filename': record.original_filename
            })
        
        return jsonify({
            'success': True,
            'data': {
                'records': formatted_records,
                'total': len(formatted_records),
                'note': 'MVP: ä»…è¿”å›æœ€è¿‘10æ¡è®°å½•ï¼Œåç»­æ”¯æŒåˆ†é¡µå’Œç­›é€‰'
            }
        })
        
    except Exception as e:
        print(f"Error getting processing history: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/performance/export', methods=['POST'])
def export_performance_data():
    """å¯¼å‡ºæ€§èƒ½æ•°æ®"""
    try:
        data = request.get_json()
        export_type = data.get('type', 'all')
        
        # è¿™é‡Œå¯ä»¥å®ç°å…·ä½“çš„å¯¼å‡ºé€»è¾‘
        # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿæ•°æ®
        export_data = {
            'type': export_type,
            'timestamp': datetime.now().isoformat(),
            'data': {
                'performance_metrics': {
                    'total_requests': 100,
                    'average_response_time': 0.5,
                    'success_rate': 0.95
                },
                'operations': [
                    {
                        'id': 1,
                        'type': 'format_alignment',
                        'timestamp': datetime.now().isoformat(),
                        'status': 'completed',
                        'duration': 1.2
                    }
                ]
            }
        }
        
        return jsonify({
            'success': True,
            'data': export_data
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# æ·»åŠ ç¼ºå¤±çš„APIç«¯ç‚¹
@app.route('/api/documents/history', methods=['GET'])
def get_documents_history():
    """è·å–æ–‡æ¡£å¤„ç†å†å²ï¼ˆæ•°æ®åº“çœŸå®æ•°æ®ï¼‰"""
    try:
        from src.core.database.repositories import DocumentRepository
        repo = DocumentRepository()
        # æ”¯æŒåˆ†é¡µå‚æ•°
        limit = int(request.args.get('limit', 20))
        status = request.args.get('status', None)
        if status is not None:
            records = repo.get_processing_history(limit=limit, status=status)
        else:
            records = repo.get_processing_history(limit=limit)
        docs = []
        for r in records:
            docs.append({
                'id': r.id,
                'filename': r.original_filename,
                'type': r.document_type,
                'timestamp': r.created_at.isoformat() if r.created_at else '',
                'status': r.processing_status,
                'result_url': f"/api/format-alignment/preview/{r.id}",
                'confidence': r.confidence_score,
                'processing_time_ms': r.processing_time_ms,
                'error_message': r.error_message,
            })
        return jsonify({
            'success': True,
            'data': {
                'documents': docs,
                'total': len(docs),
                'page': 1,
                'per_page': limit
            }
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/performance/stats', methods=['GET'])
def get_performance_stats():
    """è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ•°æ®åº“çœŸå®æ•°æ®ï¼‰"""
    try:
        from src.core.database.repositories import PerformanceRepository
        from datetime import timedelta
        repo = PerformanceRepository()
        # æ”¯æŒæ—¶é—´çª—å£å‚æ•°
        hours = int(request.args.get('hours', 24))
        stats = repo.get_performance_stats(time_window=timedelta(hours=hours))
        return jsonify({'success': True, 'data': stats})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/performance/operations', methods=['GET'])
def get_performance_operations():
    """è·å–æ“ä½œæ€§èƒ½æ•°æ®ï¼ˆæ•°æ®åº“çœŸå®æ•°æ®ï¼‰"""
    try:
        from src.core.database.repositories import PerformanceRepository
        from datetime import timedelta
        repo = PerformanceRepository()
        hours = int(request.args.get('hours', 24))
        breakdown = repo.get_operation_breakdown(time_window=timedelta(hours=hours))
        return jsonify({'success': True, 'data': {'operations': breakdown}})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/style-alignment/preview', methods=['POST'])
def preview_style_alignment():
    """
    é¢„è§ˆæ–‡é£å¯¹é½ç»“æœã€‚
    æ”¯æŒå¤šç§å‚æ•°æ ¼å¼ï¼š
        - content/reference_content/reference_name
        - document_content/document_name/style_template_id
    è¿”å›ï¼šé£æ ¼å¯¹é½é¢„è§ˆç»“æœã€‚
    """
    try:
        from src.core.tools.comprehensive_style_processor import ComprehensiveStyleProcessor
        from src.llm_clients.xingcheng_llm import XingchengLLMClient
        data = request.get_json()
        # å…¼å®¹å¤šç§å‚æ•°å
        content = data.get('content') or data.get('document_content')
        reference_content = data.get('reference_content', '')
        reference_name = data.get('reference_name', data.get('document_name', 'ç›®æ ‡é£æ ¼'))
        style_template_id = data.get('style_template_id', '')
        if not content:
            return jsonify({'success': False, 'error': 'ç¼ºå°‘å†…å®¹å‚æ•°'}), 400
        # åˆå§‹åŒ–LLM client
        XINGCHENG_API_KEY = os.getenv("XINGCHENG_API_KEY")
        XINGCHENG_API_SECRET = os.getenv("XINGCHENG_API_SECRET")
        LLM_MODEL_NAME = os.getenv("LLM_MODEL_NAME", "x1")
        llm_client = None
        if XINGCHENG_API_KEY and XINGCHENG_API_SECRET:
            llm_client = XingchengLLMClient(
                api_key=XINGCHENG_API_KEY,
                api_secret=XINGCHENG_API_SECRET,
                model_name=LLM_MODEL_NAME
            )
        processor = ComprehensiveStyleProcessor(llm_client=llm_client)
        # 1. é£æ ¼å¯¹é½
        if reference_content:
            align_result = processor.align_text_style(
                source_text=reference_content,
                target_text=reference_content,
                content_to_align=content,
                source_name=reference_name,
                target_name=reference_name
            )
        elif style_template_id:
            # å¯æ ¹æ®æ¨¡æ¿IDåŠ è½½é£æ ¼ç‰¹å¾
            align_result = processor.align_text_style(
                source_text='',
                target_text='',
                content_to_align=content,
                source_name=reference_name,
                target_name=reference_name,
                style_template_id=style_template_id
            )
        else:
            align_result = {
                'alignment_id': None,
                'original_content': content,
                'aligned_content': content,
                'alignment_result': {},
                'quality_assessment': {},
                'success': True,
                'note': 'æœªæä¾›å‚è€ƒé£æ ¼ï¼Œä»…è¿”å›åŸæ–‡åŠé£æ ¼åˆ†æ'
            }
        aligned_content = align_result.get('aligned_content', content)
        style_analysis = processor.extract_comprehensive_style_features(aligned_content, document_name=reference_name)
        return jsonify({
            'success': True,
            'original_content': content,
            'aligned_content': aligned_content,
            'alignment_result': align_result,
            'aligned_style_analysis': style_analysis
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

# å…¨å±€è¯„å®¡ä¼šè¯å­˜å‚¨
review_sessions = {}

@app.route('/api/document-review/start', methods=['POST'])
def document_review_start():
    """
    å¯åŠ¨æ–‡æ¡£è¯„å®¡æµç¨‹ã€‚
    åŠŸèƒ½ï¼šå¤šè§’è‰²AIæ–‡æ¡£è¯„å®¡ï¼Œæ”¯æŒå‚æ•°æ ¡éªŒã€‚
    å‚æ•°ï¼š
        - document_content (str): å¿…å¡«ï¼Œæ–‡æ¡£å†…å®¹ã€‚
        - document_name (str): å¿…å¡«ï¼Œæ–‡æ¡£åç§°ã€‚
        - review_focus (str): å¯é€‰ï¼Œè¯„å®¡é‡ç‚¹ï¼ˆauto/academic/business/technical/legalï¼‰ã€‚
    è¿”å›ï¼š
        - success (bool)
        - review_session_id (str)
        - status (str)
        - error (str, å¯é€‰)
    ç¤ºä¾‹ï¼š
        POST /api/document-review/start
        {
            "document_content": "...",
            "document_name": "test.txt",
            "review_focus": "auto"
        }
    """
    try:
        data = request.get_json()
        if not data:
            return jsonify({'success': False, 'error': 'è¯·æ±‚ä½“å¿…é¡»ä¸ºJSON'}), 400
        content = data.get('document_content', '')
        name = data.get('document_name', '')
        review_focus = data.get('review_focus', 'auto')
        if not content or not isinstance(content, str) or not content.strip():
            return jsonify({'success': False, 'error': 'document_contentä¸èƒ½ä¸ºç©º'}), 400
        if not name or not isinstance(name, str):
            return jsonify({'success': False, 'error': 'document_nameä¸èƒ½ä¸ºç©º'}), 400
        # è¯„å®¡é‡ç‚¹æ ¡éªŒ
        valid_focuses = ["auto", "academic", "business", "technical", "legal"]
        if review_focus not in valid_focuses:
            review_focus = "auto"
        # è°ƒç”¨å¤šè§’è‰²è¯„å®¡é€»è¾‘
        from src.core.tools.virtual_reviewer import EnhancedVirtualReviewerTool
        # éœ€ä¼ é€’llm_clientå’Œknowledge_baseå‚æ•°ï¼Œè‹¥æ— åˆ™ç”¨None
        reviewer_tool = EnhancedVirtualReviewerTool(llm_client=None, knowledge_base={})
        # è¿™é‡Œå¯æ ¹æ®ä¸šåŠ¡éœ€è¦é€‰æ‹©å¤šè§’è‰²ï¼Œæš‚ç”¨å•è§’è‰²editor
        result = reviewer_tool.multi_reviewer_session(document_content=content, reviewer_roles=["editor"], review_focus=review_focus)
        if not result.get("success"):
            return jsonify({'success': False, 'error': result.get('error', 'è¯„å®¡å¤±è´¥')}), 500
        session_id = f"review_{uuid.uuid4().hex}"
        review_sessions[session_id] = result["session_results"]
        return jsonify({
            'success': True,
            'review_session_id': session_id,
            'status': 'started'
        })
    except Exception as e:
        return jsonify({'success': False, 'error': f'æ–‡æ¡£è¯„å®¡å¯åŠ¨å¤±è´¥: {str(e)}'}), 500

@app.route('/api/document-review/suggestions/<review_session_id>', methods=['GET'])
def get_review_suggestions(review_session_id):
    """
    è·å–æ–‡æ¡£è¯„å®¡å»ºè®®ã€‚
    å‚æ•°ï¼šreview_session_id (str)
    è¿”å›ï¼šsuccess, suggestions (list)
    """
    try:
        if review_session_id not in review_sessions:
            return jsonify({'success': False, 'error': 'æ— æ•ˆçš„è¯„å®¡ä¼šè¯ID'}), 404
        session = review_sessions[review_session_id]
        suggestions = []
        for reviewer in session.get('reviewer_results', []):
            comments = reviewer.get('review_comments', {}).get('comments', [])
            for c in comments:
                suggestions.append({
                    'id': str(uuid.uuid4()),
                    'type': c.get('category', 'general'),
                    'content': c.get('comment', ''),
                    'priority': c.get('severity', 'medium')
                })
        return jsonify({'success': True, 'suggestions': suggestions})
    except Exception as e:
        return jsonify({'success': False, 'error': f'è·å–è¯„å®¡å»ºè®®å¤±è´¥: {str(e)}'}), 500

def fill_tables(tables, fill_data):
    """
    æ™ºèƒ½è¡¨æ ¼å¡«å……é€»è¾‘ï¼ŒæŒ‰åˆ—ååŒ¹é…å¡«å……ã€‚
    :param tables: List[pd.DataFrame]
    :param fill_data: List[Dict[str, Any]]
    :return: List[pd.DataFrame]
    """
    import pandas as pd
    filled_tables = []
    for df in tables:
        if not isinstance(df, pd.DataFrame) or df.empty:
            filled_tables.append(df)
            continue
        df_copy = df.copy()
        table_columns = set(df_copy.columns)
        matching_fill_data = []
        for row in fill_data:
            row_columns = set(row.keys())
            if table_columns.intersection(row_columns):
                matching_fill_data.append(row)
        for i, row in enumerate(matching_fill_data):
            if i < len(df_copy):
                for col in df_copy.columns:
                    if col in row and row[col] is not None:
                        df_copy.at[i, col] = row[col]
        filled_tables.append(df_copy)
    return filled_tables

@app.route('/api/table-fill', methods=['POST'])
def api_table_fill():
    """
    æ™ºèƒ½è¡¨æ ¼æ‰¹é‡å¡«å……APIã€‚
    å‚æ•°ï¼š
        - tables (list): å¿…å¡«ï¼Œè¡¨æ ¼å®šä¹‰ï¼Œå«columnså’Œdataã€‚
        - fill_data (list): å¿…å¡«ï¼Œå¡«å……æ•°æ®ã€‚
    è¿”å›ï¼š
        - success (bool)
        - filled_tables (list)
        - error (str, å¯é€‰)
    """
    try:
        if not request.is_json:
            return jsonify({'success': False, 'error': 'è¯·æ±‚å¿…é¡»ä¸ºJSONæ ¼å¼'}), 400
        data = request.get_json()
        if not data:
            return jsonify({'success': False, 'error': 'æ— æ•ˆçš„JSONæ•°æ®'}), 400
        if 'tables' not in data:
            return jsonify({'success': False, 'error': 'ç¼ºå°‘å¿…éœ€å­—æ®µ: tables'}), 400
        if 'fill_data' not in data:
            return jsonify({'success': False, 'error': 'ç¼ºå°‘å¿…éœ€å­—æ®µ: fill_data'}), 400
        tables = data['tables']
        fill_data = data['fill_data']
        if not isinstance(tables, list):
            return jsonify({'success': False, 'error': 'tableså¿…é¡»æ˜¯æ•°ç»„'}), 400
        if not isinstance(fill_data, list):
            return jsonify({'success': False, 'error': 'fill_dataå¿…é¡»æ˜¯æ•°ç»„'}), 400
        import pandas as pd
        pd_tables = []
        for i, t in enumerate(tables):
            if not isinstance(t, dict):
                return jsonify({'success': False, 'error': f'è¡¨æ ¼{i+1}å¿…é¡»æ˜¯å¯¹è±¡'}), 400
            if 'columns' not in t or 'data' not in t:
                return jsonify({'success': False, 'error': f'è¡¨æ ¼{i+1}ç¼ºå°‘columnsæˆ–dataå­—æ®µ'}), 400
            if not isinstance(t['columns'], list) or not isinstance(t['data'], list):
                return jsonify({'success': False, 'error': f'è¡¨æ ¼{i+1}æ ¼å¼é”™è¯¯'}), 400
            try:
                columns = list(map(str, t['columns']))
                df = pd.DataFrame(t['data'], columns=columns)
                pd_tables.append(df)
            except Exception as e:
                return jsonify({'success': False, 'error': f'è¡¨æ ¼{i+1}æ•°æ®æ ¼å¼é”™è¯¯: {str(e)}'}), 400
        for i, item in enumerate(fill_data):
            if not isinstance(item, dict):
                return jsonify({'success': False, 'error': f'å¡«å……æ•°æ®{i+1}å¿…é¡»æ˜¯å¯¹è±¡'}), 400
        # ç›´æ¥è°ƒç”¨æœ¬åœ° fill_tables
        filled_tables = fill_tables(pd_tables, fill_data)
        result = []
        for df in filled_tables:
            result.append({
                'columns': list(df.columns),
                'data': df.values.tolist()
            })
        return jsonify({'success': True, 'filled_tables': result})
    except Exception as e:
        return jsonify({'success': False, 'error': f'è¡¨æ ¼å¡«å……å¤±è´¥: {str(e)}'}), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)
