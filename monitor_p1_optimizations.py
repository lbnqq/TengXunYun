#!/usr/bin/env python3
"""
P1ä¼˜åŒ–æ¨¡å—æŒç»­ç›‘æ§è„šæœ¬

å®æ—¶ç›‘æ§P1ä¼˜å…ˆçº§ä»»åŠ¡æ¨¡å—çš„æ€§èƒ½ã€è´¨é‡å’Œç”¨æˆ·åé¦ˆï¼Œ
ç¡®ä¿ç³»ç»Ÿç¨³å®šè¿è¡Œå’ŒæŒç»­ä¼˜åŒ–ã€‚

Author: AI Assistant
Date: 2025-01-28
"""

import os
import sys
import json
import time
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('p1_monitoring.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class P1OptimizationMonitor:
    """P1ä¼˜åŒ–æ¨¡å—ç›‘æ§å™¨"""
    
    def __init__(self):
        self.monitoring_data = {
            "performance_metrics": {
                "total_requests": 0,
                "successful_requests": 0,
                "failed_requests": 0,
                "average_response_time": 0.0,
                "total_response_time": 0.0
            },
            "quality_metrics": {
                "average_quality_score": 0.0,
                "quality_threshold_violations": 0,
                "total_assessments": 0
            },
            "user_feedback": {
                "total_feedback": 0,
                "positive_feedback": 0,
                "negative_feedback": 0,
                "improvement_suggestions": []
            },
            "system_health": {
                "last_check": None,
                "status": "healthy",
                "alerts": []
            }
        }
        self.monitoring_active = False
        self.alert_thresholds = {
            "max_response_time": 5.0,  # ç§’
            "min_success_rate": 0.95,  # 95%
            "min_quality_score": 0.7,  # 70%
            "max_error_rate": 0.05     # 5%
        }
    
    def start_monitoring(self):
        """å¯åŠ¨ç›‘æ§"""
        logger.info("å¯åŠ¨P1ä¼˜åŒ–æ¨¡å—ç›‘æ§...")
        self.monitoring_active = True
        
        # å¯åŠ¨æ€§èƒ½ç›‘æ§çº¿ç¨‹
        performance_thread = threading.Thread(target=self._monitor_performance, daemon=True)
        performance_thread.start()
        
        # å¯åŠ¨è´¨é‡ç›‘æ§çº¿ç¨‹
        quality_thread = threading.Thread(target=self._monitor_quality, daemon=True)
        quality_thread.start()
        
        # å¯åŠ¨ç”¨æˆ·åé¦ˆç›‘æ§çº¿ç¨‹
        feedback_thread = threading.Thread(target=self._monitor_user_feedback, daemon=True)
        feedback_thread.start()
        
        # å¯åŠ¨ç³»ç»Ÿå¥åº·æ£€æŸ¥çº¿ç¨‹
        health_thread = threading.Thread(target=self._monitor_system_health, daemon=True)
        health_thread.start()
        
        logger.info("ç›‘æ§çº¿ç¨‹å·²å¯åŠ¨")
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        logger.info("åœæ­¢P1ä¼˜åŒ–æ¨¡å—ç›‘æ§...")
        self.monitoring_active = False
    
    def _monitor_performance(self):
        """ç›‘æ§æ€§èƒ½æŒ‡æ ‡"""
        while self.monitoring_active:
            try:
                # æ¨¡æ‹Ÿæ€§èƒ½æ•°æ®æ”¶é›†
                self._collect_performance_data()
                
                # æ£€æŸ¥æ€§èƒ½é˜ˆå€¼
                self._check_performance_thresholds()
                
                # æ¯60ç§’æ£€æŸ¥ä¸€æ¬¡
                time.sleep(60)
                
            except Exception as e:
                logger.error(f"æ€§èƒ½ç›‘æ§å¼‚å¸¸: {e}")
                time.sleep(60)
    
    def _monitor_quality(self):
        """ç›‘æ§è´¨é‡æŒ‡æ ‡"""
        while self.monitoring_active:
            try:
                # æ¨¡æ‹Ÿè´¨é‡æ•°æ®æ”¶é›†
                self._collect_quality_data()
                
                # æ£€æŸ¥è´¨é‡é˜ˆå€¼
                self._check_quality_thresholds()
                
                # æ¯120ç§’æ£€æŸ¥ä¸€æ¬¡
                time.sleep(120)
                
            except Exception as e:
                logger.error(f"è´¨é‡ç›‘æ§å¼‚å¸¸: {e}")
                time.sleep(120)
    
    def _monitor_user_feedback(self):
        """ç›‘æ§ç”¨æˆ·åé¦ˆ"""
        while self.monitoring_active:
            try:
                # æ¨¡æ‹Ÿç”¨æˆ·åé¦ˆæ”¶é›†
                self._collect_user_feedback()
                
                # åˆ†æåé¦ˆè¶‹åŠ¿
                self._analyze_feedback_trends()
                
                # æ¯300ç§’æ£€æŸ¥ä¸€æ¬¡
                time.sleep(300)
                
            except Exception as e:
                logger.error(f"ç”¨æˆ·åé¦ˆç›‘æ§å¼‚å¸¸: {e}")
                time.sleep(300)
    
    def _monitor_system_health(self):
        """ç›‘æ§ç³»ç»Ÿå¥åº·çŠ¶æ€"""
        while self.monitoring_active:
            try:
                # æ£€æŸ¥ç³»ç»Ÿå¥åº·çŠ¶æ€
                self._check_system_health()
                
                # ç”Ÿæˆå¥åº·æŠ¥å‘Š
                self._generate_health_report()
                
                # æ¯300ç§’æ£€æŸ¥ä¸€æ¬¡
                time.sleep(300)
                
            except Exception as e:
                logger.error(f"ç³»ç»Ÿå¥åº·ç›‘æ§å¼‚å¸¸: {e}")
                time.sleep(300)
    
    def _collect_performance_data(self):
        """æ”¶é›†æ€§èƒ½æ•°æ®"""
        # æ¨¡æ‹Ÿæ€§èƒ½æ•°æ®
        import random
        
        response_time = random.uniform(0.5, 2.0)
        success = random.random() > 0.05  # 95%æˆåŠŸç‡
        
        self.monitoring_data["performance_metrics"]["total_requests"] += 1
        self.monitoring_data["performance_metrics"]["total_response_time"] += response_time
        
        if success:
            self.monitoring_data["performance_metrics"]["successful_requests"] += 1
        else:
            self.monitoring_data["performance_metrics"]["failed_requests"] += 1
        
        # è®¡ç®—å¹³å‡å“åº”æ—¶é—´
        total_requests = self.monitoring_data["performance_metrics"]["total_requests"]
        total_time = self.monitoring_data["performance_metrics"]["total_response_time"]
        self.monitoring_data["performance_metrics"]["average_response_time"] = total_time / total_requests
        
        logger.debug(f"æ€§èƒ½æ•°æ®æ›´æ–°: å“åº”æ—¶é—´={response_time:.2f}s, æˆåŠŸ={success}")
    
    def _collect_quality_data(self):
        """æ”¶é›†è´¨é‡æ•°æ®"""
        # æ¨¡æ‹Ÿè´¨é‡æ•°æ®
        import random
        
        quality_score = random.uniform(0.6, 0.95)
        
        self.monitoring_data["quality_metrics"]["total_assessments"] += 1
        
        # æ£€æŸ¥è´¨é‡é˜ˆå€¼
        if quality_score < self.alert_thresholds["min_quality_score"]:
            self.monitoring_data["quality_metrics"]["quality_threshold_violations"] += 1
        
        # è®¡ç®—å¹³å‡è´¨é‡åˆ†æ•°
        total_assessments = self.monitoring_data["quality_metrics"]["total_assessments"]
        current_avg = self.monitoring_data["quality_metrics"]["average_quality_score"]
        new_avg = (current_avg * (total_assessments - 1) + quality_score) / total_assessments
        self.monitoring_data["quality_metrics"]["average_quality_score"] = new_avg
        
        logger.debug(f"è´¨é‡æ•°æ®æ›´æ–°: è´¨é‡åˆ†æ•°={quality_score:.2f}, å¹³å‡={new_avg:.2f}")
    
    def _collect_user_feedback(self):
        """æ”¶é›†ç”¨æˆ·åé¦ˆ"""
        # æ¨¡æ‹Ÿç”¨æˆ·åé¦ˆæ•°æ®
        import random
        
        feedback_types = ["accuracy", "relevance", "completeness", "clarity", "usefulness"]
        feedback_levels = ["excellent", "good", "needs_improvement", "poor", "critical"]
        
        feedback_type = random.choice(feedback_types)
        feedback_level = random.choice(feedback_levels)
        
        self.monitoring_data["user_feedback"]["total_feedback"] += 1
        
        if feedback_level in ["excellent", "good"]:
            self.monitoring_data["user_feedback"]["positive_feedback"] += 1
        else:
            self.monitoring_data["user_feedback"]["negative_feedback"] += 1
        
        # ç”Ÿæˆæ”¹è¿›å»ºè®®
        if feedback_level in ["needs_improvement", "poor", "critical"]:
            suggestion = f"æ”¹è¿›{feedback_type}ç›¸å…³åŠŸèƒ½"
            if suggestion not in self.monitoring_data["user_feedback"]["improvement_suggestions"]:
                self.monitoring_data["user_feedback"]["improvement_suggestions"].append(suggestion)
        
        logger.debug(f"ç”¨æˆ·åé¦ˆæ›´æ–°: ç±»å‹={feedback_type}, çº§åˆ«={feedback_level}")
    
    def _check_performance_thresholds(self):
        """æ£€æŸ¥æ€§èƒ½é˜ˆå€¼"""
        metrics = self.monitoring_data["performance_metrics"]
        
        # æ£€æŸ¥å“åº”æ—¶é—´
        if metrics["average_response_time"] > self.alert_thresholds["max_response_time"]:
            self._add_alert("æ€§èƒ½", f"å¹³å‡å“åº”æ—¶é—´è¿‡é«˜: {metrics['average_response_time']:.2f}s")
        
        # æ£€æŸ¥æˆåŠŸç‡
        if metrics["total_requests"] > 0:
            success_rate = metrics["successful_requests"] / metrics["total_requests"]
            if success_rate < self.alert_thresholds["min_success_rate"]:
                self._add_alert("æ€§èƒ½", f"æˆåŠŸç‡è¿‡ä½: {success_rate:.2%}")
    
    def _check_quality_thresholds(self):
        """æ£€æŸ¥è´¨é‡é˜ˆå€¼"""
        metrics = self.monitoring_data["quality_metrics"]
        
        # æ£€æŸ¥è´¨é‡åˆ†æ•°
        if metrics["average_quality_score"] < self.alert_thresholds["min_quality_score"]:
            self._add_alert("è´¨é‡", f"å¹³å‡è´¨é‡åˆ†æ•°è¿‡ä½: {metrics['average_quality_score']:.2f}")
        
        # æ£€æŸ¥è´¨é‡è¿è§„æ¬¡æ•°
        if metrics["quality_threshold_violations"] > 10:
            self._add_alert("è´¨é‡", f"è´¨é‡é˜ˆå€¼è¿è§„æ¬¡æ•°è¿‡å¤š: {metrics['quality_threshold_violations']}")
    
    def _analyze_feedback_trends(self):
        """åˆ†æåé¦ˆè¶‹åŠ¿"""
        feedback = self.monitoring_data["user_feedback"]
        
        if feedback["total_feedback"] > 0:
            negative_rate = feedback["negative_feedback"] / feedback["total_feedback"]
            
            if negative_rate > self.alert_thresholds["max_error_rate"]:
                self._add_alert("ç”¨æˆ·åé¦ˆ", f"è´Ÿé¢åé¦ˆç‡è¿‡é«˜: {negative_rate:.2%}")
    
    def _check_system_health(self):
        """æ£€æŸ¥ç³»ç»Ÿå¥åº·çŠ¶æ€"""
        self.monitoring_data["system_health"]["last_check"] = datetime.now().isoformat()
        
        # æ£€æŸ¥å„ä¸ªæ¨¡å—çŠ¶æ€
        alerts_count = len(self.monitoring_data["system_health"]["alerts"])
        
        if alerts_count == 0:
            self.monitoring_data["system_health"]["status"] = "healthy"
        elif alerts_count <= 3:
            self.monitoring_data["system_health"]["status"] = "warning"
        else:
            self.monitoring_data["system_health"]["status"] = "critical"
    
    def _add_alert(self, category: str, message: str):
        """æ·»åŠ å‘Šè­¦"""
        alert = {
            "timestamp": datetime.now().isoformat(),
            "category": category,
            "message": message,
            "severity": "warning"
        }
        
        self.monitoring_data["system_health"]["alerts"].append(alert)
        logger.warning(f"å‘Šè­¦ [{category}]: {message}")
    
    def _generate_health_report(self):
        """ç”Ÿæˆå¥åº·æŠ¥å‘Š"""
        report = {
            "timestamp": datetime.now().isoformat(),
            "system_status": self.monitoring_data["system_health"]["status"],
            "performance_summary": {
                "total_requests": self.monitoring_data["performance_metrics"]["total_requests"],
                "success_rate": self._calculate_success_rate(),
                "average_response_time": self.monitoring_data["performance_metrics"]["average_response_time"]
            },
            "quality_summary": {
                "average_quality_score": self.monitoring_data["quality_metrics"]["average_quality_score"],
                "threshold_violations": self.monitoring_data["quality_metrics"]["quality_threshold_violations"]
            },
            "user_feedback_summary": {
                "total_feedback": self.monitoring_data["user_feedback"]["total_feedback"],
                "positive_rate": self._calculate_positive_feedback_rate(),
                "improvement_suggestions": self.monitoring_data["user_feedback"]["improvement_suggestions"]
            },
            "active_alerts": len(self.monitoring_data["system_health"]["alerts"])
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = f"health_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"å¥åº·æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
    
    def _calculate_success_rate(self) -> float:
        """è®¡ç®—æˆåŠŸç‡"""
        metrics = self.monitoring_data["performance_metrics"]
        if metrics["total_requests"] > 0:
            return metrics["successful_requests"] / metrics["total_requests"]
        return 0.0
    
    def _calculate_positive_feedback_rate(self) -> float:
        """è®¡ç®—æ­£é¢åé¦ˆç‡"""
        feedback = self.monitoring_data["user_feedback"]
        if feedback["total_feedback"] > 0:
            return feedback["positive_feedback"] / feedback["total_feedback"]
        return 0.0
    
    def get_monitoring_summary(self) -> Dict[str, Any]:
        """è·å–ç›‘æ§æ‘˜è¦"""
        return {
            "timestamp": datetime.now().isoformat(),
            "system_status": self.monitoring_data["system_health"]["status"],
            "performance": {
                "total_requests": self.monitoring_data["performance_metrics"]["total_requests"],
                "success_rate": f"{self._calculate_success_rate():.2%}",
                "avg_response_time": f"{self.monitoring_data['performance_metrics']['average_response_time']:.2f}s"
            },
            "quality": {
                "avg_quality_score": f"{self.monitoring_data['quality_metrics']['average_quality_score']:.2f}",
                "threshold_violations": self.monitoring_data["quality_metrics"]["quality_threshold_violations"]
            },
            "user_feedback": {
                "total_feedback": self.monitoring_data["user_feedback"]["total_feedback"],
                "positive_rate": f"{self._calculate_positive_feedback_rate():.2%}",
                "suggestions_count": len(self.monitoring_data["user_feedback"]["improvement_suggestions"])
            },
            "alerts": len(self.monitoring_data["system_health"]["alerts"])
        }
    
    def save_monitoring_data(self):
        """ä¿å­˜ç›‘æ§æ•°æ®"""
        data_file = f"monitoring_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(data_file, "w", encoding="utf-8") as f:
            json.dump(self.monitoring_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ç›‘æ§æ•°æ®å·²ä¿å­˜: {data_file}")


def main():
    """ä¸»å‡½æ•°"""
    monitor = P1OptimizationMonitor()
    
    try:
        print("ğŸš€ å¯åŠ¨P1ä¼˜åŒ–æ¨¡å—æŒç»­ç›‘æ§...")
        monitor.start_monitoring()
        
        # ä¸»å¾ªç¯
        while True:
            try:
                # æ¯5åˆ†é’Ÿæ˜¾ç¤ºä¸€æ¬¡æ‘˜è¦
                time.sleep(300)
                summary = monitor.get_monitoring_summary()
                
                print("\n" + "="*60)
                print("ğŸ“Š P1ä¼˜åŒ–æ¨¡å—ç›‘æ§æ‘˜è¦")
                print("="*60)
                print(f"ç³»ç»ŸçŠ¶æ€: {summary['system_status']}")
                print(f"æ€»è¯·æ±‚æ•°: {summary['performance']['total_requests']}")
                print(f"æˆåŠŸç‡: {summary['performance']['success_rate']}")
                print(f"å¹³å‡å“åº”æ—¶é—´: {summary['performance']['avg_response_time']}")
                print(f"å¹³å‡è´¨é‡åˆ†æ•°: {summary['quality']['avg_quality_score']}")
                print(f"ç”¨æˆ·åé¦ˆæ•°: {summary['user_feedback']['total_feedback']}")
                print(f"æ­£é¢åé¦ˆç‡: {summary['user_feedback']['positive_rate']}")
                print(f"æ´»è·ƒå‘Šè­¦: {summary['alerts']}")
                print("="*60)
                
                # ä¿å­˜ç›‘æ§æ•°æ®
                monitor.save_monitoring_data()
                
            except KeyboardInterrupt:
                print("\nâš ï¸ ç›‘æ§è¢«ç”¨æˆ·ä¸­æ–­")
                break
            except Exception as e:
                logger.error(f"ç›‘æ§ä¸»å¾ªç¯å¼‚å¸¸: {e}")
                time.sleep(60)
    
    finally:
        monitor.stop_monitoring()
        print("\nğŸ›‘ ç›‘æ§å·²åœæ­¢")


if __name__ == "__main__":
    main() 