#!/usr/bin/env python3
"""
æµ‹è¯•å¢å¼ºåœºæ™¯æ¨æ–­å¼•æ“çš„åŠŸèƒ½
Test script for the Enhanced Scenario Inference Engine
"""

import json
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.core.guidance.scenario_inference import EnhancedScenarioInferenceModule
from src.core.tools.document_parser import EnhancedDocumentParserTool

class MockLLMClient:
    """æ¨¡æ‹ŸLLMå®¢æˆ·ç«¯ç”¨äºæµ‹è¯•"""
    
    def generate(self, prompt: str) -> str:
        # æ ¹æ®æç¤ºå†…å®¹è¿”å›ä¸åŒçš„æ¨¡æ‹Ÿå“åº”
        if "äººå·¥æ™ºèƒ½" in prompt or "AI" in prompt or "æŠ€æœ¯æŠ¥å‘Š" in prompt:
            return json.dumps({
                "document_type": "technical_report",
                "scenario": "Technical Report",
                "author_role": "Technical Lead",
                "target_audience": "Technical Team",
                "document_purpose": "informational",
                "formality_level": "semi_formal",
                "confidence": 0.85,
                "supporting_evidence": ["technical terminology", "structured sections", "methodology discussion"],
                "key_topics": ["AI", "document processing", "system architecture"],
                "writing_style": "technical and structured",
                "complexity_level": "advanced"
            })
        elif "äº§å“" in prompt or "product" in prompt:
            return json.dumps({
                "document_type": "product_proposal",
                "scenario": "Product Proposal",
                "author_role": "Product Manager",
                "target_audience": "Development Team",
                "document_purpose": "persuasive",
                "formality_level": "semi_formal",
                "confidence": 0.78,
                "supporting_evidence": ["feature descriptions", "user stories", "business value"],
                "key_topics": ["product features", "user experience", "market fit"],
                "writing_style": "persuasive and structured",
                "complexity_level": "intermediate"
            })
        else:
            return json.dumps({
                "document_type": "general_document",
                "scenario": "General Document",
                "author_role": "General Author",
                "target_audience": "General Audience",
                "document_purpose": "informational",
                "formality_level": "neutral",
                "confidence": 0.6,
                "supporting_evidence": ["general content"],
                "key_topics": ["various topics"],
                "writing_style": "standard",
                "complexity_level": "intermediate"
            })

def test_enhanced_scenario_inference():
    """æµ‹è¯•å¢å¼ºåœºæ™¯æ¨æ–­å¼•æ“çš„å„ç§åŠŸèƒ½"""
    
    print("ğŸš€ æµ‹è¯•å¢å¼ºåœºæ™¯æ¨æ–­å¼•æ“")
    print("=" * 50)
    
    # åˆå§‹åŒ–æ¨¡æ‹ŸLLMå®¢æˆ·ç«¯å’Œæ¨æ–­å¼•æ“
    mock_llm = MockLLMClient()
    inference_engine = EnhancedScenarioInferenceModule(mock_llm)
    
    # æµ‹è¯•æ–‡æ¡£
    test_documents = [
        {
            "name": "æŠ€æœ¯æŠ¥å‘Š",
            "content": """
# äººå·¥æ™ºèƒ½æ–‡æ¡£å¤„ç†ç³»ç»ŸæŠ€æœ¯æŠ¥å‘Š

## 1. é¡¹ç›®æ¦‚è¿°
æœ¬é¡¹ç›®æ—¨åœ¨å¼€å‘ä¸€ä¸ªåŸºäºAIçš„æ™ºèƒ½æ–‡æ¡£å¤„ç†ç³»ç»Ÿï¼Œèƒ½å¤Ÿè‡ªåŠ¨åˆ†æã€ä¼˜åŒ–å’Œç”ŸæˆåŠå…¬æ–‡æ¡£ã€‚

## 2. æŠ€æœ¯æ–¹æ¡ˆ
### 2.1 ç³»ç»Ÿæ¶æ„
ç³»ç»Ÿé‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œä¸»è¦åŒ…æ‹¬ï¼š
- æ–‡æ¡£è§£ææ¨¡å—
- åœºæ™¯æ¨æ–­å¼•æ“
- å†…å®¹ç”Ÿæˆå™¨
- è™šæ‹Ÿå®¡ç¨¿ç³»ç»Ÿ

### 2.2 æ ¸å¿ƒç®—æ³•
æˆ‘ä»¬ä½¿ç”¨äº†ä»¥ä¸‹å…ˆè¿›æŠ€æœ¯ï¼š
- è‡ªç„¶è¯­è¨€å¤„ç† (NLP)
- æœºå™¨å­¦ä¹  (ML)
- æ·±åº¦å­¦ä¹  (DL)

## 3. å®éªŒç»“æœ
ç»è¿‡æµ‹è¯•ï¼Œç³»ç»Ÿåœ¨æ–‡æ¡£åˆ†ç±»æ–¹é¢è¾¾åˆ°äº†95.2%çš„å‡†ç¡®ç‡ã€‚

## 4. ç»“è®º
æœ¬ç³»ç»ŸæˆåŠŸå®ç°äº†æ™ºèƒ½åŒ–æ–‡æ¡£å¤„ç†çš„ç›®æ ‡ã€‚
            """
        },
        {
            "name": "äº§å“ææ¡ˆ",
            "content": """
# æ™ºèƒ½åŠå…¬åŠ©æ‰‹äº§å“ææ¡ˆ

## äº§å“æ¦‚è¿°
æˆ‘ä»¬è®¡åˆ’å¼€å‘ä¸€æ¬¾é©å‘½æ€§çš„æ™ºèƒ½åŠå…¬åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·æé«˜å·¥ä½œæ•ˆç‡ã€‚

## æ ¸å¿ƒåŠŸèƒ½
1. æ™ºèƒ½æ–‡æ¡£å¤„ç†
2. è‡ªåŠ¨åŒ–å·¥ä½œæµ
3. æ™ºèƒ½æ—¥ç¨‹ç®¡ç†
4. å›¢é˜Ÿåä½œå·¥å…·

## ç”¨æˆ·æ•…äº‹
ä½œä¸ºä¸€ååŠå…¬å®¤å·¥ä½œäººå‘˜ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿå¿«é€Ÿå¤„ç†å¤§é‡æ–‡æ¡£ï¼Œä»¥ä¾¿èŠ‚çœæ—¶é—´ä¸“æ³¨äºæ›´é‡è¦çš„å·¥ä½œã€‚

## å•†ä¸šä»·å€¼
- æé«˜å·¥ä½œæ•ˆç‡30%
- å‡å°‘äººå·¥é”™è¯¯
- é™ä½è¿è¥æˆæœ¬

## å¼€å‘è®¡åˆ’
ç¬¬ä¸€é˜¶æ®µï¼šæ ¸å¿ƒåŠŸèƒ½å¼€å‘ï¼ˆ3ä¸ªæœˆï¼‰
ç¬¬äºŒé˜¶æ®µï¼šç”¨æˆ·æµ‹è¯•å’Œä¼˜åŒ–ï¼ˆ2ä¸ªæœˆï¼‰
ç¬¬ä¸‰é˜¶æ®µï¼šæ­£å¼å‘å¸ƒï¼ˆ1ä¸ªæœˆï¼‰
            """
        },
        {
            "name": "ä¼šè®®çºªè¦",
            "content": """
# äº§å“è¯„å®¡ä¼šè®®çºªè¦

**ä¼šè®®æ—¶é—´**: 2024å¹´1æœˆ15æ—¥ 14:00-16:00
**å‚ä¼šäººå‘˜**: å¼ ä¸‰(äº§å“ç»ç†)ã€æå››(æŠ€æœ¯è´Ÿè´£äºº)ã€ç‹äº”(è®¾è®¡å¸ˆ)

## ä¼šè®®è®®ç¨‹
1. äº§å“åŠŸèƒ½è¯„å®¡
2. æŠ€æœ¯æ–¹æ¡ˆè®¨è®º
3. è®¾è®¡ç¨¿ç¡®è®¤
4. ä¸‹ä¸€æ­¥è®¡åˆ’

## è®¨è®ºè¦ç‚¹
- ç”¨æˆ·ç•Œé¢éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–
- åç«¯APIæ€§èƒ½éœ€è¦æå‡
- ç§»åŠ¨ç«¯é€‚é…é—®é¢˜

## å†³ç­–äº‹é¡¹
1. é‡‡ç”¨æ–°çš„UIè®¾è®¡æ–¹æ¡ˆ
2. ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½
3. å¢åŠ ç§»åŠ¨ç«¯æ”¯æŒ

## è¡ŒåŠ¨é¡¹
- å¼ ä¸‰ï¼šæ›´æ–°äº§å“éœ€æ±‚æ–‡æ¡£ (æˆªæ­¢æ—¥æœŸï¼š1æœˆ20æ—¥)
- æå››ï¼šä¼˜åŒ–APIæ€§èƒ½ (æˆªæ­¢æ—¥æœŸï¼š1æœˆ25æ—¥)
- ç‹äº”ï¼šå®Œæˆç§»åŠ¨ç«¯è®¾è®¡ (æˆªæ­¢æ—¥æœŸï¼š1æœˆ22æ—¥)
            """
        }
    ]
    
    # æµ‹è¯•æ¯ä¸ªæ–‡æ¡£
    for i, doc in enumerate(test_documents, 1):
        print(f"\nğŸ“„ æµ‹è¯•æ–‡æ¡£ {i}: {doc['name']}")
        print("-" * 40)
        
        try:
            # æ‰§è¡Œåœºæ™¯æ¨æ–­
            result = inference_engine.infer_scenario_and_roles(doc['content'])
            
            if "error" in result:
                print(f"âŒ æ¨æ–­å¤±è´¥: {result['error']}")
                continue
            
            print(f"âœ… æ¨æ–­å®Œæˆ")
            print(f"ğŸ“‹ æ–‡æ¡£ç±»å‹: {result.get('document_type', 'Unknown')}")
            print(f"ğŸ¯ åº”ç”¨åœºæ™¯: {result.get('scenario', 'Unknown')}")
            print(f"ğŸ‘¤ ä½œè€…è§’è‰²: {result.get('author_role', 'Unknown')}")
            print(f"ğŸ‘¥ ç›®æ ‡è¯»è€…: {result.get('target_audience', 'Unknown')}")
            print(f"ğŸ¨ æ–‡æ¡£ç›®çš„: {result.get('document_purpose', 'Unknown')}")
            print(f"ğŸ“ æ­£å¼ç¨‹åº¦: {result.get('formality_level', 'Unknown')}")
            
            # æ˜¾ç¤ºç½®ä¿¡åº¦åˆ†æ•°
            confidence_scores = result.get('confidence_scores', {})
            if confidence_scores:
                print(f"ğŸ“Š ç½®ä¿¡åº¦åˆ†æ•°:")
                for metric, score in confidence_scores.items():
                    print(f"   - {metric}: {score:.2%}")
            
            # æ˜¾ç¤ºæ”¯æŒè¯æ®
            evidence = result.get('supporting_evidence', [])
            if evidence:
                print(f"ğŸ” æ”¯æŒè¯æ®:")
                for ev in evidence[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    print(f"   - {ev}")
                if len(evidence) > 3:
                    print(f"   - ... è¿˜æœ‰ {len(evidence) - 3} ä¸ªè¯æ®")
            
            # æ˜¾ç¤ºå¤‡é€‰åœºæ™¯
            alternatives = result.get('alternative_scenarios', [])
            if alternatives:
                print(f"ğŸ”„ å¤‡é€‰åœºæ™¯:")
                for alt in alternatives:
                    print(f"   - {alt['scenario']} (ç½®ä¿¡åº¦: {alt['confidence']:.2%})")
            
            # ç”Ÿæˆç”¨æˆ·ç¡®è®¤æç¤º
            print(f"\nğŸ’¬ ç”¨æˆ·ç¡®è®¤æç¤º:")
            confirmation_prompt = inference_engine.generate_enhanced_confirmation_prompt(result)
            print(confirmation_prompt)
            
            # éªŒè¯æ¨æ–­è´¨é‡
            quality_report = inference_engine.validate_inference_quality(result)
            print(f"ğŸ” è´¨é‡è¯„ä¼°:")
            print(f"   - æ•´ä½“è´¨é‡: {quality_report['overall_quality']}")
            print(f"   - ç½®ä¿¡åº¦è¯„ä¼°: {quality_report['confidence_assessment']}")
            print(f"   - è¯æ®å¼ºåº¦: {quality_report['evidence_strength']}")
            print(f"   - ä¸€è‡´æ€§æ£€æŸ¥: {quality_report['consistency_check']}")
            
            if quality_report['improvement_suggestions']:
                print(f"   ğŸ’¡ æ”¹è¿›å»ºè®®:")
                for suggestion in quality_report['improvement_suggestions']:
                    print(f"      - {suggestion}")
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    
    print(f"\nğŸ‰ æµ‹è¯•å®Œæˆ!")

def test_scenario_recommendations():
    """æµ‹è¯•åœºæ™¯æ¨èåŠŸèƒ½"""
    
    print(f"\nğŸ”§ æµ‹è¯•åœºæ™¯æ¨èåŠŸèƒ½")
    print("-" * 30)
    
    mock_llm = MockLLMClient()
    inference_engine = EnhancedScenarioInferenceModule(mock_llm)
    
    # æµ‹è¯•å·²çŸ¥åœºæ™¯
    test_scenarios = ["Product Proposal", "Technical Report", "Market Analysis"]
    
    for scenario in test_scenarios:
        print(f"\nğŸ“‹ åœºæ™¯: {scenario}")
        recommendations = inference_engine.get_scenario_recommendations(scenario)
        
        if "error" in recommendations:
            print(f"âŒ {recommendations['error']}")
        else:
            print(f"âœ… æ¨èçš„å®¡é˜…è§’è‰²: {recommendations.get('recommended_reviewer_roles', [])}")
            print(f"ğŸ¯ é»˜è®¤å®¡é˜…é‡ç‚¹: {recommendations.get('default_review_focus', [])}")

if __name__ == "__main__":
    test_enhanced_scenario_inference()
    test_scenario_recommendations()
