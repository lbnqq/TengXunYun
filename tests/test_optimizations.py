#!/usr/bin/env python3
"""
æµ‹è¯•ä¼˜åŒ–åŠŸèƒ½çš„ç»¼åˆæµ‹è¯•è„šæœ¬
éªŒè¯LLMæ•ˆç‡ã€ç”¨æˆ·ç•Œé¢ã€æ‰¹é‡å¤„ç†å’Œæ€§èƒ½ç›‘æ§åŠŸèƒ½
"""

import os
import sys
import time
import json
import requests
import threading
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.core.monitoring import get_performance_monitor, PerformanceTimer
from src.core.tools.batch_processor import get_batch_processor
from src.llm_clients.multi_llm import EnhancedMultiLLMClient
from src.core.database import get_database_manager, PerformanceRepository

class OptimizationTester:
    """ä¼˜åŒ–åŠŸèƒ½æµ‹è¯•å™¨"""
    
    def __init__(self, base_url="http://localhost:5000"):
        self.base_url = base_url
        self.session = requests.Session()
        self.test_results = {}
        
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹è¿è¡Œä¼˜åŒ–åŠŸèƒ½æµ‹è¯•...")
        print("=" * 60)
        
        # æµ‹è¯•1: LLMå®¢æˆ·ç«¯ä¼˜åŒ–
        self.test_llm_optimizations()
        
        # æµ‹è¯•2: æ€§èƒ½ç›‘æ§
        self.test_performance_monitoring()
        
        # æµ‹è¯•3: æ‰¹é‡å¤„ç†
        self.test_batch_processing()
        
        # æµ‹è¯•4: ç”¨æˆ·ç•Œé¢API
        self.test_ui_apis()
        
        # æµ‹è¯•5: æ•°æ®åº“æ€§èƒ½
        self.test_database_performance()
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        self.generate_report()
    
    def test_llm_optimizations(self):
        """æµ‹è¯•LLMå®¢æˆ·ç«¯ä¼˜åŒ–"""
        print("ğŸ“Š æµ‹è¯•LLMå®¢æˆ·ç«¯ä¼˜åŒ–...")
        
        try:
            # åˆ›å»ºå¢å¼ºçš„LLMå®¢æˆ·ç«¯
            llm_client = EnhancedMultiLLMClient()
            
            # æµ‹è¯•ç¼“å­˜åŠŸèƒ½
            print("  - æµ‹è¯•ç¼“å­˜åŠŸèƒ½...")
            prompt = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æç¤º"
            
            # ç¬¬ä¸€æ¬¡è°ƒç”¨
            start_time = time.time()
            response1 = llm_client.generate(prompt)
            first_call_time = time.time() - start_time
            
            # ç¬¬äºŒæ¬¡è°ƒç”¨ï¼ˆåº”è¯¥ä½¿ç”¨ç¼“å­˜ï¼‰
            start_time = time.time()
            response2 = llm_client.generate(prompt)
            second_call_time = time.time() - start_time
            
            cache_effective = second_call_time < first_call_time * 0.5
            
            # æµ‹è¯•æ€§èƒ½æŠ¥å‘Š
            print("  - æµ‹è¯•æ€§èƒ½æŠ¥å‘Š...")
            performance_report = llm_client.get_performance_report()
            
            # æµ‹è¯•å¥åº·çŠ¶æ€
            print("  - æµ‹è¯•å¥åº·çŠ¶æ€...")
            health_status = llm_client.get_health_status()
            
            self.test_results['llm_optimizations'] = {
                'cache_effective': cache_effective,
                'first_call_time': first_call_time,
                'second_call_time': second_call_time,
                'performance_report_available': bool(performance_report),
                'health_status_available': bool(health_status),
                'healthy_endpoints': len(health_status.get('healthy_endpoints', [])),
                'total_endpoints': health_status.get('total_endpoints', 0)
            }
            
            print(f"    âœ… ç¼“å­˜æ•ˆæœ: {'æœ‰æ•ˆ' if cache_effective else 'æ— æ•ˆ'}")
            print(f"    âœ… å¥åº·ç«¯ç‚¹: {len(health_status.get('healthy_endpoints', []))}/{health_status.get('total_endpoints', 0)}")
            
        except Exception as e:
            print(f"    âŒ LLMä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}")
            self.test_results['llm_optimizations'] = {'error': str(e)}
    
    def test_performance_monitoring(self):
        """æµ‹è¯•æ€§èƒ½ç›‘æ§"""
        print("ğŸ“ˆ æµ‹è¯•æ€§èƒ½ç›‘æ§...")
        
        try:
            # è·å–æ€§èƒ½ç›‘æ§å™¨
            monitor = get_performance_monitor()
            
            # æµ‹è¯•æ€§èƒ½è®°å½•
            print("  - æµ‹è¯•æ€§èƒ½è®°å½•...")
            with PerformanceTimer('test_operation') as timer:
                time.sleep(0.1)  # æ¨¡æ‹Ÿæ“ä½œ
            
            # æµ‹è¯•ç»Ÿè®¡è·å–
            print("  - æµ‹è¯•ç»Ÿè®¡è·å–...")
            current_stats = monitor.get_current_stats()
            operation_stats = monitor.get_operation_stats()
            
            # æµ‹è¯•æ—¶é—´åºåˆ—æ•°æ®
            print("  - æµ‹è¯•æ—¶é—´åºåˆ—æ•°æ®...")
            time_series = monitor.get_time_series_data()
            
            # æµ‹è¯•æ€§èƒ½æ‘˜è¦
            print("  - æµ‹è¯•æ€§èƒ½æ‘˜è¦...")
            summary = monitor.get_performance_summary()
            
            self.test_results['performance_monitoring'] = {
                'current_stats_available': bool(current_stats),
                'operation_stats_available': bool(operation_stats),
                'time_series_available': bool(time_series),
                'summary_available': bool(summary),
                'total_operations': summary.get('total_operations', 0),
                'success_rate': summary.get('success_rate', 0.0)
            }
            
            print(f"    âœ… æ€»æ“ä½œæ•°: {summary.get('total_operations', 0)}")
            print(f"    âœ… æˆåŠŸç‡: {summary.get('success_rate', 0.0):.2%}")
            
        except Exception as e:
            print(f"    âŒ æ€§èƒ½ç›‘æ§æµ‹è¯•å¤±è´¥: {e}")
            self.test_results['performance_monitoring'] = {'error': str(e)}
    
    def test_batch_processing(self):
        """æµ‹è¯•æ‰¹é‡å¤„ç†"""
        print("ğŸ”„ æµ‹è¯•æ‰¹é‡å¤„ç†...")
        
        try:
            # è·å–æ‰¹é‡å¤„ç†å™¨
            batch_processor = get_batch_processor()
            
            # æ³¨å†Œæµ‹è¯•å¤„ç†å™¨
            def test_processor(file_path, config):
                time.sleep(0.5)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
                return {'success': True, 'message': f'å¤„ç†å®Œæˆ: {file_path}'}
            
            batch_processor.register_processor('test_operation', test_processor)
            
            # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
            test_files = []
            for i in range(3):
                test_file = f"test_file_{i}.txt"
                with open(test_file, 'w') as f:
                    f.write(f"æµ‹è¯•æ–‡ä»¶å†…å®¹ {i}")
                test_files.append(test_file)
            
            # åˆ›å»ºæ‰¹é‡ä½œä¸š
            print("  - åˆ›å»ºæ‰¹é‡ä½œä¸š...")
            job_id = batch_processor.create_batch_job(
                "æµ‹è¯•æ‰¹é‡ä½œä¸š",
                test_files,
                {'operation': 'test_operation'}
            )
            
            # å¯åŠ¨ä½œä¸š
            print("  - å¯åŠ¨æ‰¹é‡ä½œä¸š...")
            success = batch_processor.start_batch_job(job_id)
            
            if success:
                # ç­‰å¾…ä½œä¸šå®Œæˆ
                print("  - ç­‰å¾…ä½œä¸šå®Œæˆ...")
                max_wait = 30  # æœ€å¤šç­‰å¾…30ç§’
                start_wait = time.time()
                
                while time.time() - start_wait < max_wait:
                    status = batch_processor.get_job_status(job_id)
                    if status and status['status'] in ['completed', 'failed']:
                        break
                    time.sleep(1)
                
                final_status = batch_processor.get_job_status(job_id)
                
                self.test_results['batch_processing'] = {
                    'job_created': bool(job_id),
                    'job_started': success,
                    'final_status': final_status['status'] if final_status else 'unknown',
                    'total_files': final_status['total_files'] if final_status else 0,
                    'processed_files': final_status['progress']['processed'] if final_status else 0,
                    'successful_files': final_status['progress']['successful'] if final_status else 0
                }
                
                print(f"    âœ… ä½œä¸šçŠ¶æ€: {final_status['status'] if final_status else 'unknown'}")
                print(f"    âœ… å¤„ç†æ–‡ä»¶: {final_status['progress']['processed'] if final_status else 0}/{final_status['total_files'] if final_status else 0}")
            
            # æ¸…ç†æµ‹è¯•æ–‡ä»¶
            for test_file in test_files:
                if os.path.exists(test_file):
                    os.remove(test_file)
                    
        except Exception as e:
            print(f"    âŒ æ‰¹é‡å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
            self.test_results['batch_processing'] = {'error': str(e)}
    
    def test_ui_apis(self):
        """æµ‹è¯•ç”¨æˆ·ç•Œé¢API"""
        print("ğŸ–¥ï¸ æµ‹è¯•ç”¨æˆ·ç•Œé¢API...")
        
        try:
            # æµ‹è¯•æ€§èƒ½ç»Ÿè®¡API
            print("  - æµ‹è¯•æ€§èƒ½ç»Ÿè®¡API...")
            response = self.session.get(f"{self.base_url}/api/performance/stats")
            stats_available = response.status_code == 200
            
            # æµ‹è¯•APIå¥åº·çŠ¶æ€
            print("  - æµ‹è¯•APIå¥åº·çŠ¶æ€...")
            response = self.session.get(f"{self.base_url}/api/performance/health")
            health_available = response.status_code == 200
            
            # æµ‹è¯•æ“ä½œåˆ†è§£ç»Ÿè®¡
            print("  - æµ‹è¯•æ“ä½œåˆ†è§£ç»Ÿè®¡...")
            response = self.session.get(f"{self.base_url}/api/performance/operations")
            operations_available = response.status_code == 200
            
            # æµ‹è¯•æ‰¹é‡ä½œä¸šåˆ—è¡¨
            print("  - æµ‹è¯•æ‰¹é‡ä½œä¸šåˆ—è¡¨...")
            response = self.session.get(f"{self.base_url}/api/batch/jobs")
            batch_jobs_available = response.status_code == 200
            
            self.test_results['ui_apis'] = {
                'performance_stats_api': stats_available,
                'health_api': health_available,
                'operations_api': operations_available,
                'batch_jobs_api': batch_jobs_available,
                'all_apis_working': all([stats_available, health_available, operations_available, batch_jobs_available])
            }
            
            working_apis = sum([stats_available, health_available, operations_available, batch_jobs_available])
            print(f"    âœ… å¯ç”¨API: {working_apis}/4")
            
        except Exception as e:
            print(f"    âŒ UI APIæµ‹è¯•å¤±è´¥: {e}")
            self.test_results['ui_apis'] = {'error': str(e)}
    
    def test_database_performance(self):
        """æµ‹è¯•æ•°æ®åº“æ€§èƒ½"""
        print("ğŸ’¾ æµ‹è¯•æ•°æ®åº“æ€§èƒ½...")
        
        try:
            # è·å–æ•°æ®åº“ç®¡ç†å™¨
            db_manager = get_database_manager()
            
            # æµ‹è¯•æ•°æ®åº“è¿æ¥
            print("  - æµ‹è¯•æ•°æ®åº“è¿æ¥...")
            with db_manager.get_connection() as conn:
                result = conn.execute("SELECT 1").fetchone()
                db_connected = result[0] == 1
            
            # æµ‹è¯•æ€§èƒ½ä»“åº“
            print("  - æµ‹è¯•æ€§èƒ½ä»“åº“...")
            perf_repo = PerformanceRepository()
            stats = perf_repo.get_performance_stats()
            
            # æµ‹è¯•æ•°æ®åº“ç»Ÿè®¡
            print("  - æµ‹è¯•æ•°æ®åº“ç»Ÿè®¡...")
            db_stats = db_manager.get_database_stats()
            
            self.test_results['database_performance'] = {
                'connection_working': db_connected,
                'performance_repo_working': bool(stats),
                'database_stats_available': bool(db_stats),
                'total_tables': len([k for k in db_stats.keys() if k.endswith('_count')]) if db_stats else 0
            }
            
            print(f"    âœ… æ•°æ®åº“è¿æ¥: {'æ­£å¸¸' if db_connected else 'å¼‚å¸¸'}")
            print(f"    âœ… æ•°æ®è¡¨æ•°é‡: {len([k for k in db_stats.keys() if k.endswith('_count')]) if db_stats else 0}")
            
        except Exception as e:
            print(f"    âŒ æ•°æ®åº“æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
            self.test_results['database_performance'] = {'error': str(e)}
    
    def generate_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ“‹ æµ‹è¯•æŠ¥å‘Š")
        print("=" * 60)
        
        total_tests = len(self.test_results)
        passed_tests = sum(1 for result in self.test_results.values() if 'error' not in result)
        
        print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
        print(f"é€šè¿‡æµ‹è¯•: {passed_tests}")
        print(f"å¤±è´¥æµ‹è¯•: {total_tests - passed_tests}")
        print(f"æˆåŠŸç‡: {passed_tests/total_tests:.1%}")
        
        print("\nè¯¦ç»†ç»“æœ:")
        for test_name, result in self.test_results.items():
            status = "âŒ å¤±è´¥" if 'error' in result else "âœ… é€šè¿‡"
            print(f"  {test_name}: {status}")
            if 'error' in result:
                print(f"    é”™è¯¯: {result['error']}")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Šåˆ°æ–‡ä»¶
        report_file = f"test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump({
                'timestamp': datetime.now().isoformat(),
                'summary': {
                    'total_tests': total_tests,
                    'passed_tests': passed_tests,
                    'failed_tests': total_tests - passed_tests,
                    'success_rate': passed_tests/total_tests
                },
                'detailed_results': self.test_results
            }, f, indent=2, ensure_ascii=False)
        
        print(f"\nè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ Office-Doc-Agent ä¼˜åŒ–åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦å¯åŠ¨WebæœåŠ¡å™¨
    try:
        response = requests.get("http://localhost:5000/api/config", timeout=5)
        server_running = response.status_code == 200
    except:
        server_running = False
    
    if not server_running:
        print("âš ï¸  WebæœåŠ¡å™¨æœªè¿è¡Œï¼Œè¯·å…ˆå¯åŠ¨æœåŠ¡å™¨:")
        print("   python src/web_app.py")
        print("\nç»§ç»­è¿›è¡Œç¦»çº¿æµ‹è¯•...")
    
    # è¿è¡Œæµ‹è¯•
    tester = OptimizationTester()
    tester.run_all_tests()

if __name__ == "__main__":
    main()
